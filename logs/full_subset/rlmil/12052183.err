wandb: Agent Starting Run: 0av4n0j5 with config:
wandb: 	actor_learning_rate: 0.0010362966803983986
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.16375186012102327
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5860160536548121
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_220838-0av4n0j5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0av4n0j5
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▅▃▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▃▃▃▃▃▃▆▆▆▆▆▆▆▆███████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▆▆▆▆▆███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▂▂▄▂▄▄▂▁▄▁▂▄▂▃▃▅▄▄▃▃▄▅▄▄▅▅▄▄▇▄▇▅▅▄▅▇█▅
wandb:      train/ensemble_f1 ▃▄▅▅▄▁▃▂▄▄▃▅▇▅▅▇▆▆▆▄▅▄▆▅▅▄▆▅▇▅▆▃▆▇▅▆▆▇█▆
wandb:         train/mil_loss ▇▅▄▅▇█▇▄▄▆▆▇▇▅▅▄▅▃▄▄▄▄▅▃▆▅▃▁▄▅▅▃▂▃▃▄▃▃▄▄
wandb:      train/policy_loss ██████████████▂▄▁▂▁▄▂▂▂▁▂▁▁█████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████▄▁▄▂▂▂▁▄▁▂███████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.62637
wandb: best/eval_avg_mil_loss 0.51689
wandb:  best/eval_ensemble_f1 0.62637
wandb:            eval/avg_f1 0.62637
wandb:      eval/avg_mil_loss 0.49377
wandb:       eval/ensemble_f1 0.62637
wandb:            test/avg_f1 0.61129
wandb:      test/avg_mil_loss 0.52601
wandb:       test/ensemble_f1 0.61129
wandb:           train/avg_f1 0.6148
wandb:      train/ensemble_f1 0.6148
wandb:         train/mil_loss 0.65072
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run charmed-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0av4n0j5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_220838-0av4n0j5/logs
wandb: Agent Starting Run: iq3unz7o with config:
wandb: 	actor_learning_rate: 0.0006168253973555009
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.30047422720539396
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08067269528189647
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_221149-iq3unz7o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iq3unz7o
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁
wandb:       eval/ensemble_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▃▆▃▅▅▄▆▅▅▇▅▃▃▃▃▂█▃▂▇▆▃▅▆▅▇▆▃▆▄▁▆▃▁▆▃█▄▅
wandb:      train/ensemble_f1 █▅▅█▆▅▆▃▄█▅▅▅▆▄▅▃▄█▇▅▅▆▇▄▁▇▆▅▄▆▅▅▂▄▆▃▃▆▅
wandb:         train/mil_loss ▆▆▄▅▅▅▅▇▆▆▅▆▄▃▅▅▆▆▄▆▄█▄▃▄▅▅▄▄▅▄▂▄▅▄▄▄▁▃▄
wandb:      train/policy_loss ▆▆▄▅▆▅▄▄▃▄▆▅▆▄▅▃▃▁▃▅▁▆▇▆▅▃▂▅▆▂▅▅▃▃▄▄▇▃█▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▆▁▃▇▆▆▅▄▃▄▆▆▅▆▄▃▅▃▁▅▁▁▆▆▆█▃▅▆▄▅▄▆▃▆▇▅▃▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.40476
wandb: best/eval_avg_mil_loss 1.36201
wandb:  best/eval_ensemble_f1 0.40476
wandb:            eval/avg_f1 0.38558
wandb:      eval/avg_mil_loss 1.26802
wandb:       eval/ensemble_f1 0.38558
wandb:            test/avg_f1 0.41725
wandb:      test/avg_mil_loss 0.92098
wandb:       test/ensemble_f1 0.41725
wandb:           train/avg_f1 0.44422
wandb:      train/ensemble_f1 0.44422
wandb:         train/mil_loss 1.14114
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run resilient-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iq3unz7o
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_221149-iq3unz7o/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 03vtjweo with config:
wandb: 	actor_learning_rate: 0.0011887082429261964
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.19683456443196343
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5703307524199318
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_221317-03vtjweo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/03vtjweo
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ████████████▇▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁▁▆▇▇█████████████████████████
wandb:       eval/ensemble_f1 █████████▇▇▇▇▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ███████▆▇▆▆▆▅▂▂▁▁▁▁▁▁▁▁▁▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁
wandb:      train/ensemble_f1 ▇█▇█▇▇▇██▇▇▇▆▄▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁
wandb:         train/mil_loss ▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▅▆█▇▇▇▇▇▇█▇▇▆▇▆█▆▆▇▆▇▆▆▇▇
wandb:      train/policy_loss ██████████▁█████▃███████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████▁████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71591
wandb: best/eval_avg_mil_loss 0.53067
wandb:  best/eval_ensemble_f1 0.71591
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 6.9767
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.618
wandb:      test/avg_mil_loss 0.73179
wandb:       test/ensemble_f1 0.618
wandb:           train/avg_f1 0.34048
wandb:      train/ensemble_f1 0.34048
wandb:         train/mil_loss 6.39169
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run comic-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/03vtjweo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_221317-03vtjweo/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: s5lvdq3q with config:
wandb: 	actor_learning_rate: 2.1433564565603332e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2869610103057625
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.25418908939310403
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_221505-s5lvdq3q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s5lvdq3q
wandb: uploading history steps 103-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▃▃▃▂▂▂▂▁▁▃▃▃▃▂▆▅▅▅▅▄▄███▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▆█▅▅▃▃▅▆▃▅▃▃▆▆▁▅▅█▆▆▅▄▃▆▃▄▂▇▅▅▆▅▆▃▄▆▅▄
wandb:      train/ensemble_f1 ▅▇▅▄▅▇▃▄▅▆▆▆▅▅▄▅▅▄▄▅▃▅▁▆▅▅▄▆▇▃▄▄▆▆▅▄█▅▄▅
wandb:         train/mil_loss ▁▄▂▅▅▆▆▃▂▅▂▅▂▂▃▂▆▁▃▃▃▇▃▃▃▃▅▅▄▆▅▃▄▄▃█▂▄▃▄
wandb:      train/policy_loss ▄▆▅▁▆▃▃▂▄▆█▅▆▅▆▄▅▆▃▅▇▆▄▅▆▃▅▇▂▁▃▅▄▅▂▅▄▅█▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄█▁▄▄▅▃▃▃▅▃▇▂▅▆▅▅▅▄▃▅▄▄▅▃▅▆▅▂▄▁▃▄▆▁▅▅▄▇▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.92591
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.92905
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.02913
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33166
wandb:      train/ensemble_f1 0.33166
wandb:         train/mil_loss 0.82481
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rich-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s5lvdq3q
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_221505-s5lvdq3q/logs
wandb: Agent Starting Run: q3y4kj7t with config:
wandb: 	actor_learning_rate: 0.0001433957672172099
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8806780191834721
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8182739573282632
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_221627-q3y4kj7t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q3y4kj7t
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇▇▇▇███▇▁▂▂▁▁▁▂▂▂▂▂▄▅▅▄▇▆▇▇▇▇▇▇▇▇▇▆▆▆▆▇█
wandb:       eval/ensemble_f1 ███████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅▆▁▅▄▃▆▃▅▃▄▇▅█▃▄▄▅▄▄▇▁▅▇▄▅▅▄▅▃▄▇▅█▁▅▅▆▄
wandb:      train/ensemble_f1 ▆▃▆▅▅▄▅▆▅▆▁▄▇▂▄▆▂▄▆▄▅▄▆▅▄▅▃▆▃▇▅█▃▅▇▃▆▅▅▅
wandb:         train/mil_loss ▄▇▅▆▂▁▂▅▅▆▅▃▃▅▃▂▄▃▂▆▃▆▇█▃▅▅▇▆▃▆▄▃▃▃▃▂▃▁▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.63535
wandb: best/eval_avg_mil_loss 0.56103
wandb:  best/eval_ensemble_f1 0.63535
wandb:            eval/avg_f1 0.62248
wandb:      eval/avg_mil_loss 0.5613
wandb:       eval/ensemble_f1 0.62248
wandb:            test/avg_f1 0.6108
wandb:      test/avg_mil_loss 0.58705
wandb:       test/ensemble_f1 0.6108
wandb:           train/avg_f1 0.58998
wandb:      train/ensemble_f1 0.58998
wandb:         train/mil_loss 0.5645
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run solar-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q3y4kj7t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_221627-q3y4kj7t/logs
wandb: Agent Starting Run: v4nfhfnm with config:
wandb: 	actor_learning_rate: 0.0008510360550126428
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7163179940300829
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2578875061091317
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_221749-v4nfhfnm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v4nfhfnm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▅▂▅▂▃▄▃▄▄▃▅▃▂▄▃█▅▄▃▅▆▂▂▁▂▃▄▄▁▄▂▅▃▂▅▅▅▃
wandb:      train/ensemble_f1 ▅▆▄▅▄▄▃▅▃▃▄▄▆▅▄▃▄▄▄█▄▅▆▅▅▅▇▄▄▃▂▄▄▄▃▁▃▆▃▄
wandb:         train/mil_loss ▂▅▆▄▆█▅▅▆▅▆▄▆▃▄▆▇▂▅▅▆▆▆▂▆▇▆▅▆▄▁▇▄▆▆▅▃▅▁▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 0.94288
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.91371
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 0.7691
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.37692
wandb:      train/ensemble_f1 0.37692
wandb:         train/mil_loss 0.68104
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vague-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v4nfhfnm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_221749-v4nfhfnm/logs
wandb: Agent Starting Run: 94he5iov with config:
wandb: 	actor_learning_rate: 0.00025270871620180547
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5922394642178007
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.27709215780073526
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_221912-94he5iov
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/94he5iov
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▂█▅▅▅▆▃▄▁▁▃▆▄▄▃▃▄▅▄▄▄▃▅▁▁▇▅▅▃▅▅▃▇▄▄▆▄▂
wandb:      train/ensemble_f1 ▆▄▄█▁▅▅▁▃▆▄▃▅▆▅▆▂▅▂▄▃▂▃▄▄▅▂▂▄▁▃▃▃▇▃▅▆▅▃▄
wandb:         train/mil_loss ▁▇▂▂▃▆▅▄█▄▃▇▆▅▁▄▄▆▃▆▇▄▄▅▆▅▅▃▅▅▃▆▃▃▄▅▂▅▁▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.04147
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.99847
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 0.83448
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.38711
wandb:      train/ensemble_f1 0.38711
wandb:         train/mil_loss 0.74282
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run comfy-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/94he5iov
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_221912-94he5iov/logs
wandb: Agent Starting Run: wl3ewxw1 with config:
wandb: 	actor_learning_rate: 1.0102391738787118e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9215612837761914
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4482663211268828
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_222035-wl3ewxw1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wl3ewxw1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▆▆▆▆▆▆▆▆▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▁▂▅▆▆█▅▄▂█▅▃▃▄▆▅▇▂▄▆▃▂▅▆▅▄▄▄▅▂▅▂▄▄▄▃▄▅
wandb:      train/ensemble_f1 ▄▅▁▅▂▃▅▆▄█▃▄▅▁▅▄▃▅▄▂▆▇▇▁▃▂▃▄▅▃▅▅▅▁▄▃▂▄▃▁
wandb:         train/mil_loss ▅▅▇▂▅▆▃▄▅▅▄▃▂▄▂▅█▄▃▂▅▄▄▄▅▂▆▄▃▄▂▄▁▂▅▃▃▇▃▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 0.92577
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.91562
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.76399
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.40221
wandb:      train/ensemble_f1 0.40221
wandb:         train/mil_loss 0.63217
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run scarlet-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wl3ewxw1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_222035-wl3ewxw1/logs
wandb: Agent Starting Run: xh5fisbu with config:
wandb: 	actor_learning_rate: 2.8007187799977868e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.093276849346541
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.21569308631706088
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_222158-xh5fisbu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xh5fisbu
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▄▂▃▄▃▂▃▃▄▄▆▅▃▄▄▄▄▄▄▃▃▅▃▅▅▃▄▁▅▆▄▄▂▄▄█▄▂
wandb:      train/ensemble_f1 ▅▅▄▁▁▄▅▄▃▃▂▄▃▄▂▄▁▄▃▄▄▅▅▃▅▃▅▃▆▅▄▃█▄▂▄▄▅▂▆
wandb:         train/mil_loss █▅▆▁▄▇▅▄▇▅▆▃▅▆▆▅▅▅▃▅▅▄▆▅▄▆▆▅▆▆▆▆▇▁▆▃▅▃▆▆
wandb:      train/policy_loss ▂▃▆▆▃▂▁▂▃▆▂▂▄▆▃█▂▃▅▃▃▅▅▃▁▃▃▄▃▇▄▃▂▄▂▂▄▁▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▄▆▆▂▆▆▂▂▆▂▄▄▃▂▆█▃▃▅▃▃▆▅▃▄▇▇▃▃▂▄▂▇▂▆▁▃█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.85749
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.83312
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.93189
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34979
wandb:      train/ensemble_f1 0.34979
wandb:         train/mil_loss 0.7553
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earthy-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xh5fisbu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_222158-xh5fisbu/logs
wandb: Agent Starting Run: zxuzobup with config:
wandb: 	actor_learning_rate: 2.6250985506114697e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4433114328377624
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3856852969836865
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_222320-zxuzobup
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zxuzobup
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▆▅▃▇▆▃▃▄▂▅▄▃▅▄█▆▂▅▄▆▁▂▂▄▃▃▆▄▅▄▃▃▂▄▂▅▄
wandb:      train/ensemble_f1 ▄▆▄▅▁▃▅▃▅▃▆▅▂▆▆▄▄▆▇▆▄▇▅▆▄▂▄▄▂▄█▆█▄▃▅▃▇▃▇
wandb:         train/mil_loss ▆▄▄▂▂▆▄▆▄▄▅▆▆▇█▄▃▆▆▇█▄▃▅█▁▃▆▆▆▇▄▆▃▆▄▄▁▅▅
wandb:      train/policy_loss ▅▇▁▇▆█▄▇▇▄▃▄▅▆▅▄▂▄▁▂▅▆▃▅▂▆▃▇▅▇▇▅▅▅▂▅█▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆▃▆▄▅▄▃▃▆▆▅▃▂▄▃▂▄▁▄█▇▂▅▃▅▅▂▃▅▅▅▂▂▄▅▇▅▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.97934
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.96198
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.09099
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34156
wandb:      train/ensemble_f1 0.34156
wandb:         train/mil_loss 0.77058
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run super-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zxuzobup
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_222320-zxuzobup/logs
wandb: Agent Starting Run: g59hatrw with config:
wandb: 	actor_learning_rate: 4.079477050327447e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7121070242581035
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6838721847248098
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_222443-g59hatrw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g59hatrw
wandb: uploading history steps 423-437, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▄▅▅▆▇█
wandb: best/eval_avg_mil_loss █▇▇▆▅▃▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▃▄▅▅▆▇█
wandb:            eval/avg_f1 ▂▂▂▁▁▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▇▇▇▇▇█████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▂▁▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▇▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▂▁▃▂▂▂▂▃▂▅▄▄▄▄▅▃▃▄▃▄▆▅▅▆█▇▅▆▇▇█▇▆██▇▆█
wandb:      train/ensemble_f1 ▁▂▂▂▂▃▂▁▂▃▃▄▄▅▃▄▆▄▄▆▆▄▅▅▄▆▇▇▆▇▇▇█▆▇▆▇█▇█
wandb:         train/mil_loss ▃▄▅▆▅▅▆█▄▃▄▄▅▆▇█▂█▄▇▄▃▄▂▅▅▄▄▅▄▃▃▃▅▂▁▅▄▃▃
wandb:      train/policy_loss ██████████████████████████████▁█████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▅▅▅▅▅▅█▇███▇▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▃▅▁▃▅▃▃▃▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.76139
wandb: best/eval_avg_mil_loss 0.66988
wandb:  best/eval_ensemble_f1 0.76139
wandb:            eval/avg_f1 0.76139
wandb:      eval/avg_mil_loss 0.60125
wandb:       eval/ensemble_f1 0.76139
wandb:            test/avg_f1 0.74287
wandb:      test/avg_mil_loss 0.53042
wandb:       test/ensemble_f1 0.74287
wandb:           train/avg_f1 0.76523
wandb:      train/ensemble_f1 0.76523
wandb:         train/mil_loss 0.68736
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run winter-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/g59hatrw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_222443-g59hatrw/logs
wandb: Agent Starting Run: jblx6i7a with config:
wandb: 	actor_learning_rate: 7.84726295451976e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4212510873974492
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.966085415108714
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_223012-jblx6i7a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jblx6i7a
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▃▄▄▄▅▅▆▆▇▇▇▇██
wandb: best/eval_avg_mil_loss ███▇▆▆▆▆▆▅▅▄▃▃▂▂▂▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▃▄▄▄▅▅▆▆▇▇▇▇██
wandb:            eval/avg_f1 ▁▂▂▂▂▁▁▂▁▃▃▃▄▄▄▆▆▅▆▆▆▆▆▆▇█▇▇█████▇▆▇▆▆▅▅
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▄▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▃▃▃▃▃▄▄▅▆▅▇▆▆▆▇▇▇▇▆▆███████████▇▇▇▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▁▁▁▂▂▂▂▂▃▂▃▃▃▃▄▄▄▄▄▅▅▅▅▄▅▅▆▆▆▅▇▇▇▇██▇▇
wandb:      train/ensemble_f1 ▁▁▂▁▃▃▄▄▃▄▃▄▄▄▄▅▄▅▄▄▅▅▄▅▅▅▆▆▆▇▇▇▇▇▇▇██▇▇
wandb:         train/mil_loss █▇▆▅▆▄▆▆▅▅▅▄▂▅▅▃▃▄▄▄▃▂▂▃▃▃▃▁▃▃▄▁▂▂▁▁▂▂▂▂
wandb:      train/policy_loss ████████████████▁███████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▆▆▆▆▆▃▆▆█▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.6568
wandb: best/eval_avg_mil_loss 1.14463
wandb:  best/eval_ensemble_f1 0.6568
wandb:            eval/avg_f1 0.53846
wandb:      eval/avg_mil_loss 1.35522
wandb:       eval/ensemble_f1 0.53846
wandb:            test/avg_f1 0.63636
wandb:      test/avg_mil_loss 1.57981
wandb:       test/ensemble_f1 0.63636
wandb:           train/avg_f1 0.62623
wandb:      train/ensemble_f1 0.62623
wandb:         train/mil_loss 0.97098
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dashing-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jblx6i7a
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_223012-jblx6i7a/logs
wandb: Agent Starting Run: 4wicfilg with config:
wandb: 	actor_learning_rate: 0.00018424337692172357
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4593838269950672
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1452908051440318
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_223623-4wicfilg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4wicfilg
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▆▄▂▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆█████████▇
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▅▅▅▅▅▅▅▅▅▆▆▆▆▆██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▂▃▂▂▃▂▄▃▂▂▄▁▃▃▁▂▄▄▄▄▆▄▆▅▆▇▆▆▇▇▇██▆▆▆▇▇
wandb:      train/ensemble_f1 ▄▃▁▃▃▂▂▂▃▄▃▂▃▄▂▅▄▄▃▄▃▄▅█▆▇▇▇█▇▇▇██▇█▇▆▇▇
wandb:         train/mil_loss █▇▆▇▆▅█▅▆▇▄▆▆▆▄▄▄▄▃▃▂▃▄▅▅▂▃▄▅▅▃▂▅▃▂▂▁▃▂▄
wandb:      train/policy_loss ▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▅▇▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77263
wandb: best/eval_avg_mil_loss 0.64869
wandb:  best/eval_ensemble_f1 0.77263
wandb:            eval/avg_f1 0.76316
wandb:      eval/avg_mil_loss 0.56416
wandb:       eval/ensemble_f1 0.76316
wandb:            test/avg_f1 0.78348
wandb:      test/avg_mil_loss 0.50191
wandb:       test/ensemble_f1 0.78348
wandb:           train/avg_f1 0.78169
wandb:      train/ensemble_f1 0.78169
wandb:         train/mil_loss 0.58482
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clear-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4wicfilg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_223623-4wicfilg/logs
wandb: Agent Starting Run: da19oq23 with config:
wandb: 	actor_learning_rate: 0.00517745461342718
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6058113736041344
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.295215701517748
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_224010-da19oq23
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/da19oq23
wandb: uploading history steps 222-226, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▅▃▁▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▅▆██▇▇▇▇▇▇▅▅▅▅▆
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▅▅▅▅▅▅▆██▇▅▇▇▇▇▇▇▅▅▅▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▁▄▄▃▄▄▅▃▆▅▂▅▇▆▆▄▆▅▅▆▄▆▆▇▆▄▇▅▆▆█▆▅▆▆▅▇▆
wandb:      train/ensemble_f1 ▄▃▄▃▂▄▃▂▄▂▄▄▁▆▃▃▅▃▄▂▅▅▄▄▅▆▃▄▄▇▅▅█▆▅▃▅▄▆▆
wandb:         train/mil_loss ▅▄▂▃▆▄▇▅▄▃▅█▁▄▅▃▄▄▆▂▆▅▃▄▂▃▅▁▅▅▂▃▂▆▄▂▃▅▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▄▆▆▅▅▄▅▃▅▄▄▅▄▄▄▆▅▁▂▅▃▃▃▃▁▅▂▁▃█▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70289
wandb: best/eval_avg_mil_loss 0.56175
wandb:  best/eval_ensemble_f1 0.70289
wandb:            eval/avg_f1 0.69067
wandb:      eval/avg_mil_loss 0.52272
wandb:       eval/ensemble_f1 0.69067
wandb:            test/avg_f1 0.67831
wandb:      test/avg_mil_loss 0.56444
wandb:       test/ensemble_f1 0.67831
wandb:           train/avg_f1 0.67906
wandb:      train/ensemble_f1 0.67906
wandb:         train/mil_loss 0.6947
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run grateful-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/da19oq23
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_224010-da19oq23/logs
wandb: Agent Starting Run: hyb764kz with config:
wandb: 	actor_learning_rate: 0.0002095088873812679
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8952734504273595
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4640413184521214
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_224306-hyb764kz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hyb764kz
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▁▆▇▇▂▄▅▅▃█▃▅▆█▆▄▅▅▅▅▄▆▄▇▄▅▃▆▄▅▇▇▆▄▅▅▄▅▄
wandb:      train/ensemble_f1 █▁▇▂▃▄▅██▃▅▄▄▆▅▅▅▁▆▃▅▆▆▆▅▃▇▇█▃▅▅▃▅▃▄▅▃▃▄
wandb:         train/mil_loss ▅▁▂▄▄█▂▅▆▃▇▄█▃▅▅▆▆▅▅█▂▄▄▄▃▇▃▆▁▇▃▃▄▇▃▄▇▇▄
wandb:      train/policy_loss ▇▇▇▇██▇▆▇▆▆▆██▆▄▆▄██▃▂▇▇█▆▆█▇▆▄▄▄▇▃▄▁▂▇▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▆▅▅▆▃▆▂▆▃▅▆█▅▇▄▅▆▄▇▃▂▆▆▇▅▄▅▅▆▅▄▅▆▆▆▄▁▆▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.98198
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.97496
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.09305
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32546
wandb:      train/ensemble_f1 0.32546
wandb:         train/mil_loss 0.58463
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fast-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hyb764kz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_224306-hyb764kz/logs
wandb: Agent Starting Run: bonqocag with config:
wandb: 	actor_learning_rate: 0.006777499021248434
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4035016444547428
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6698968884018304
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_224429-bonqocag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bonqocag
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▅▆▇▆▆▃▃▄▅▄▇▅▅▄▃▇▄▄▇▁▅▅▆▇▄▆▆▅▆▄▆▄▃▆▇▅▆▇
wandb:      train/ensemble_f1 █▅▁▅▄▇▆▆▂▆▄▆█▆▄▂▃▆▇▃▇▆▇▃▅▃▅▃▇▄▄▄▄▆▇▂▅▂▅▂
wandb:         train/mil_loss ▇▂▄▅▁█▂▄▃▅▅▄▅▅▁▃▃▅▄▃▆▄▃▂▃▅▄▂▃▇▄▃▁▄▃▂▅▂▂▅
wandb:      train/policy_loss ▅▃▆▃▃▄▅▄▄▄▁▅█▁▃▃▃▆▄▅▅▄▄▅▂▅▄▅▃▆▂▄▅▄▄▅▅▇▂▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▅▅▄▇▁▆▇▆▅▃▅▇▄▆▄▄▃▅▃▅▃▄▅▄▆▃▃▄▃▄▄▆█▅▃▆▆█▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.97702
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.95805
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.08408
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34587
wandb:      train/ensemble_f1 0.34587
wandb:         train/mil_loss 0.79886
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fluent-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bonqocag
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_224429-bonqocag/logs
wandb: Agent Starting Run: jx1wm0k9 with config:
wandb: 	actor_learning_rate: 3.481405109725298e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.41662276781061947
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8214125866239519
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_224551-jx1wm0k9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jx1wm0k9
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅▆█
wandb: best/eval_avg_mil_loss █▅▃▁
wandb:  best/eval_ensemble_f1 ▁▅▆█
wandb:            eval/avg_f1 ▁▁▅▆▆██▆▆▄▄▆▆▆▆▆▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss █▇▆▆▆▅▅▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▅▇▇██▆▆▆▆▆▆▆▆▆▆▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▇▅▄▅▅▄▆▅▄▄▄▅▅█▃▃▄▂▆▂▄▃▃▁▃▃▂▆▂▄▅▃▅▅▆▅▄▅▇
wandb:      train/ensemble_f1 ▄▇▅▅▄▄▂▃▂▁█▆▃▃▃▄▂▄▆▃▆▃▇▂▆▃▃▆▅▃▆▇▆▂▅▄▆▄▆▃
wandb:         train/mil_loss ▅▅▅▃▅▆▅█▄▃▃▁▅▅▃▄▅▄▃▅▇▄▂▅▁▂▃▅▅▄▂▆▇▃▃▄▃▃▅▄
wandb:      train/policy_loss ██▇████▄███▁███████▁████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7278
wandb: best/eval_avg_mil_loss 0.50667
wandb:  best/eval_ensemble_f1 0.7278
wandb:            eval/avg_f1 0.68286
wandb:      eval/avg_mil_loss 0.48331
wandb:       eval/ensemble_f1 0.68286
wandb:            test/avg_f1 0.56897
wandb:      test/avg_mil_loss 0.67648
wandb:       test/ensemble_f1 0.56897
wandb:           train/avg_f1 0.62436
wandb:      train/ensemble_f1 0.62436
wandb:         train/mil_loss 0.69218
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run whole-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jx1wm0k9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_224551-jx1wm0k9/logs
wandb: Agent Starting Run: 6p8wxbdq with config:
wandb: 	actor_learning_rate: 1.060493150983951e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7060157631916582
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0018245531252364389
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_224718-6p8wxbdq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6p8wxbdq
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▆▄▆▄▄▄▇▂▆▅▅▅▃▅▇▄▅▁▁▆▂█▁▄▅▃▃▂▂▆▆▄▄▄▅▃▇▅
wandb:      train/ensemble_f1 ▄▆▅▄▄▁▅▄▇▁▄▄▆▃▄▃▆▄▃▄▅▁█▄▆▃▄▃▃▁▃▄▃▄▆▄▃▅▅▅
wandb:         train/mil_loss ▇▆▂▆▅▁▆▄█▃▆▂▅▄▃▂▆▄▂▂▃▇▅▄▃▅█▃▅▂▂▅▇▄▁▂▅▂▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 0.88405
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.85447
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.71464
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.43315
wandb:      train/ensemble_f1 0.43315
wandb:         train/mil_loss 0.68044
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crisp-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6p8wxbdq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_224718-6p8wxbdq/logs
wandb: Agent Starting Run: vvqwtzy5 with config:
wandb: 	actor_learning_rate: 0.005959931817392306
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7667892265965227
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9268455142090078
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_224842-vvqwtzy5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vvqwtzy5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▅█▆▃▃▃▆▄▅▄▅▆▆▄▅▄▄▄▃▇▅▄▁▆▂▆▇▄▅▃▆▆▄▄▃▄▄▅
wandb:      train/ensemble_f1 ▇▆▄▅▆▆▂▆▃▂▄▄▅▄▅▆▄▇▅▆▄▁▆▄▆▅▃▁▃▄▇▄▄█▅▄▅▄▃▃
wandb:         train/mil_loss ▃█▅▅▆▄▃▅▅▃▄▃▃▃▆▅▅▂▅▅▅▃▆▁▇▄▅▅▃▆▂▄▁▃▃▅▄▇▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 0.96031
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.9301
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.77416
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.4088
wandb:      train/ensemble_f1 0.4088
wandb:         train/mil_loss 0.70628
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gentle-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vvqwtzy5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_224842-vvqwtzy5/logs
wandb: Agent Starting Run: 8zj25yfh with config:
wandb: 	actor_learning_rate: 3.92411644806607e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.19799654734434713
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4059605757538632
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_225005-8zj25yfh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8zj25yfh
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆█▆▃▁█▃▅▄▆▁▅▃▄▃▅▂▅▄▅▃▃▅▁▅▃▂▅▅▆▅█▆▅▇▄▅▃▆▄
wandb:      train/ensemble_f1 ▇▃▁▇▇▅▅▃▄▄▇▇▅▅█▅▅▅▅▃▇▃▅▄█▇▅▅▄▅▅▄█▇▇▃▃▄▄▄
wandb:         train/mil_loss ▄▄▄▁▂▅▄▁▄▄▆▃▂█▁▅▁▃▄▅▅▄▃▃▂▄▃▅▅▃▃▂▃▅▁▄▃▅▃▂
wandb:      train/policy_loss ▂▆▅█▇▃▅█▄▅▇▄▂▂▅▅▄▄▆▃▁▃█▅▄▇▆▇▅▄█▅▅▃▆▅█▇▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▅▅▃▄▆▅▅▄▆▄▄▅▄▃▃▃▃▂▁▆▄▅▂▂▄█▆▃▅▄▄▅▄▂▃▂▃▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.82149
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.80578
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.91838
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33389
wandb:      train/ensemble_f1 0.33389
wandb:         train/mil_loss 0.77196
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run amber-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/8zj25yfh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_225005-8zj25yfh/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: t0sn6ie5 with config:
wandb: 	actor_learning_rate: 3.538291737355888e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.15744758729405206
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3496300903974916
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_225202-t0sn6ie5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t0sn6ie5
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▄▄▆▃▅▃▃█▅▂▆▁▆▃▅▄▄▆▅▃▄▄▄▅▄▃▇▄▃▆▇▅▇▄▇▅▄▅
wandb:      train/ensemble_f1 ▁▂▃▂▅▂▆█▇▇▄▅▂▁▆▆▃▃▄▃▃▃▂▄▂▆▁▂▇▃▁▄▇▄▅▆▃▂▃▅
wandb:         train/mil_loss ▆▆█▄▁▅█▆█▇▆▄▆▁▅▁▅▄▁▃▆▄▃▃▁▅▃▆▄█▂▄▅▂▄▁▂▃▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58478
wandb: best/eval_avg_mil_loss 0.65443
wandb:  best/eval_ensemble_f1 0.58478
wandb:            eval/avg_f1 0.58478
wandb:      eval/avg_mil_loss 0.61088
wandb:       eval/ensemble_f1 0.58478
wandb:            test/avg_f1 0.52696
wandb:      test/avg_mil_loss 0.6117
wandb:       test/ensemble_f1 0.52696
wandb:           train/avg_f1 0.56067
wandb:      train/ensemble_f1 0.56067
wandb:         train/mil_loss 0.70838
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run chocolate-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/t0sn6ie5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_225202-t0sn6ie5/logs
wandb: Agent Starting Run: ps4354v1 with config:
wandb: 	actor_learning_rate: 0.0015864683457659104
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4530229638672998
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.44834629960755934
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_225325-ps4354v1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ps4354v1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃█▅▃▅▅▄▃▄▅▄▃▅▅▂▇▇▂▅▂▆▄▅▆▅▃▁▁▅▄▃▆▄▆▅▂▂▃▅▂
wandb:      train/ensemble_f1 ▇▇▆▆▄▄▃▆▅▆▇▄▅▂▄▅▆▆█▆▅▄▆▇▆▅▅▂▁▂▆▄▅▅▇▅▄▄▆▅
wandb:         train/mil_loss ▅▄▃▃▄▁▄▅▄▅▂▄▂▁▂▅▆▃▄▃▄▃▄▃▅█▅▁▄▅▄▁▆▅▅▆▃▅▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61985
wandb: best/eval_avg_mil_loss 0.67519
wandb:  best/eval_ensemble_f1 0.61985
wandb:            eval/avg_f1 0.61985
wandb:      eval/avg_mil_loss 0.6718
wandb:       eval/ensemble_f1 0.61985
wandb:            test/avg_f1 0.68847
wandb:      test/avg_mil_loss 0.63851
wandb:       test/ensemble_f1 0.68847
wandb:           train/avg_f1 0.70168
wandb:      train/ensemble_f1 0.70168
wandb:         train/mil_loss 0.56246
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run kind-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ps4354v1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_225325-ps4354v1/logs
wandb: Agent Starting Run: y4079mr1 with config:
wandb: 	actor_learning_rate: 8.872819840444456e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.69460803205483
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5678027339669592
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_225448-y4079mr1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y4079mr1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▄█▇▅▂▅▂▅▆▇▆▅▆▅▅▁▇▄█▇▇▆▂▆▂▂▆▇▇▆▃▄▇▇█▄▇█
wandb:      train/ensemble_f1 ▅█▄▄▃▃▃▂▆▂▅▃▂█▁▂▆▅▃▃▇▅▅▅▂▆▂▆▁▃▃▃▃▅▅▄▃▃▄▆
wandb:         train/mil_loss ▅▄▄▇▆▄▄█▅▄▆▅▄▅▄▆▅▂▄▁▄▂▄▄▄▅▂▇▃▇▅▁▅▇▄▄▅▅▁▆
wandb:      train/policy_loss ▆▇▆█▄█▃▅▆▆▄▅▁▆▆▆▆▄▇▅▅█▇█▃▆█▅▇██▆▅▃▆▆▆▆▅▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▅▅▄▆▆▆▅▁▄▅▂▂▆▇▇█▇▄▅▇▅▅▆▇▇▆▅▇▄▅▇▅▂▄▄▅▇▆▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.01017
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.99579
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.12173
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32146
wandb:      train/ensemble_f1 0.32146
wandb:         train/mil_loss 0.67457
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rare-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y4079mr1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_225448-y4079mr1/logs
wandb: Agent Starting Run: 6t4zdznj with config:
wandb: 	actor_learning_rate: 0.002747873311897147
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.33906705620264477
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.23834527110085543
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_225610-6t4zdznj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6t4zdznj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▆▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 █████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▄▃▁▄▄▁▃▆▄▃▅▅▃▂▆▂▆▅▆▅▄▆▅▅▆▆▅▆▅▆▇█▆█▅▆█▆
wandb:      train/ensemble_f1 ▃▃▃▂▂▂▁▂▁▂▁▂▂▃▁▃▃▁▂▄▃▂▃▃▄▃▄▄▃▅▆▄▆▇▇▃█▆▆▄
wandb:         train/mil_loss ██▇▇▆▆▄▄▄▄▃▅▃▄▄▄▃▄▃▅▃▄▄▃▄▇▄▂▅▂▄▄▂▂▂▃▂▃▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.63108
wandb: best/eval_avg_mil_loss 0.79289
wandb:  best/eval_ensemble_f1 0.63108
wandb:            eval/avg_f1 0.62637
wandb:      eval/avg_mil_loss 0.54726
wandb:       eval/ensemble_f1 0.62637
wandb:            test/avg_f1 0.66875
wandb:      test/avg_mil_loss 0.58447
wandb:       test/ensemble_f1 0.66875
wandb:           train/avg_f1 0.65716
wandb:      train/ensemble_f1 0.65716
wandb:         train/mil_loss 0.71738
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run exalted-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6t4zdznj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_225610-6t4zdznj/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: y704op9m with config:
wandb: 	actor_learning_rate: 0.0001675019983089004
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.14510365299369332
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7405859357663215
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_225739-y704op9m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y704op9m
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▃▅▃▆▅▁▄▄▄▄▇▆▆▅▄▇▅▅▄▅▃▇▂▅▅▆▄█▅▄▅▆▃▇▅▅▆▅
wandb:      train/ensemble_f1 ▆▅▄▆▃▆▅▁▅▆▄▆▇▇▆▄▅▇▅▄▆▃▄▅▅▅▆▆█▃▄▄▆▄▅▄▅▆▆▅
wandb:         train/mil_loss ▅▅▄▅▅▄▇▅█▄▂▃▆▃▄▃▄▄▄▄▃▃▄▆▄▅▄▂▃▂▅▅▄▅▃▃▅▁▂▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.00471
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.93228
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.81437
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.39926
wandb:      train/ensemble_f1 0.39926
wandb:         train/mil_loss 0.98128
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stoic-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y704op9m
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_225739-y704op9m/logs
wandb: Agent Starting Run: btvqpze7 with config:
wandb: 	actor_learning_rate: 0.000285420666745629
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5925008888613252
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7580219209160727
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_225902-btvqpze7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/btvqpze7
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▄▄▄▃▅▃▆▅▅▆▂▇▇▂▅▂▃▅▁▅▆▅▇▃▆▃▇▆▂▅█▅▃▅▆▇▇▃
wandb:      train/ensemble_f1 ▂▄▅▅▅▃▆▅▅▂▇▅▄▆▆▁▂▃▃▁▂▅▄▃▃▆▅▃▆▄▇█▄▆▃▆▇▅▄▃
wandb:         train/mil_loss ▆▁▇▅▅▅▁██▄▃▅▆▅▅▅▄▆▇█▅▄▃▃▇▃▁▂▃▅▄▆█▄▂▅▅▇▆▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58478
wandb: best/eval_avg_mil_loss 0.62789
wandb:  best/eval_ensemble_f1 0.58478
wandb:            eval/avg_f1 0.58478
wandb:      eval/avg_mil_loss 0.59277
wandb:       eval/ensemble_f1 0.58478
wandb:            test/avg_f1 0.53222
wandb:      test/avg_mil_loss 0.56227
wandb:       test/ensemble_f1 0.53222
wandb:           train/avg_f1 0.54039
wandb:      train/ensemble_f1 0.54039
wandb:         train/mil_loss 0.69186
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run radiant-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/btvqpze7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_225902-btvqpze7/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: dmls18u8 with config:
wandb: 	actor_learning_rate: 1.561046206627349e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8915746057264078
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9655000840162592
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_230031-dmls18u8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dmls18u8
wandb: uploading history steps 82-101, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅█▇▆▃▄▆▄▃▃▄▃▄▁▅▆▃▄▆▄▅▅▄▃▅▂▆▃▅▅▄▄▃▆▆▂▁▅▅▃
wandb:      train/ensemble_f1 ▆▇▃▁▄▃▄▆▄▄▅▇▂▄▄▇▆▅█▆▆▅▇▄▃▇▇▅▄▆▂▇▇▃▃▅▄▃▆▄
wandb:         train/mil_loss ▂▂▃▃▃▅▆▁▃▃▄▄▄▂▃▅▂▃▂▃▃▁▃▇▂▅▅▅▁▄▆▃▂▅▁█▃▂▆▂
wandb:      train/policy_loss ▆▆▄▅▆▇▄▆▅▅▇▄▅▆▄▁▅▆▆▇▄▆▆▇█▄▆▃▇▅▄▅▆▅▂▆▇▂▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▅▄▇▆▄▆▆▇▆█▄▆▄▅██▄▁▆▇▁█▅▃▃▆▇▇▆▃▆█▆▆▇██▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.97692
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.96986
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.08813
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32886
wandb:      train/ensemble_f1 0.32886
wandb:         train/mil_loss 0.57625
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dmls18u8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_230031-dmls18u8/logs
wandb: Agent Starting Run: h27wvn9z with config:
wandb: 	actor_learning_rate: 2.477964988465331e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.00682068259940849
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5141751682148796
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_230255-h27wvn9z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h27wvn9z
wandb: uploading history steps 82-103, summary
wandb: uploading summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▄▃▅▂▃▅▇▂▃▂▂▄▅▃▂▁▃▅▂▅▃▁▅▁▆▆▄▅▄█▄▂▄▃▅▅▅▂
wandb:      train/ensemble_f1 ▃▂▃▃▂▇▃▄▄▃▂▄▆█▅▄▂▅▄▂▅▄▃▅▃▂▅▄▁▃▃▃▄▆▄▄▃▂▅▂
wandb:         train/mil_loss ▇█▆▅▆▇▅▅▄▅▅▃▆▃▂▃▅▄▅▁▄▃▁▃▃▃▄▃▅▄▃▃▄▃▂▅▃▃▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 0.97036
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.89486
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 0.80697
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.38188
wandb:      train/ensemble_f1 0.38188
wandb:         train/mil_loss 0.96282
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run comic-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h27wvn9z
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_230255-h27wvn9z/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: gvlue6q1 with config:
wandb: 	actor_learning_rate: 2.3483579872274643e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7946933227738783
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.573665256931455
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_230428-gvlue6q1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gvlue6q1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃▃▆▃▄▁▅▅▄▃▄▃▃▂▄▅▃▅▂▅▃▃▃▅▅▄▄█▄▆▂▇▄▄▆▅▃▄
wandb:      train/ensemble_f1 ▅▄▁▂▃▃▂▁▄▄▂▃▃▃▄▄▁▅▅▃▅▅▅▃▄▃▇▃▁▄▄█▆▇▃▃▃▂▄▄
wandb:         train/mil_loss ▅▆▄▃▅▃▆▅▄▄▆▃▃▇▄▃▄▃▃▅▃█▅▄▆▆▄▅▄▄▄▄▅▅▆▃▁▄▆▇
wandb:      train/policy_loss ▄▅▃▃█▄▆▃▃▁▃▃█▂▅▃▃▁▅▂▅▄▃▆▅▂▄▃▆▅▃▃▇▄▃▃▃▃▄▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▅▃▃▆█▄▃▃▅▃▆▃▃▃▆▂▃▅▆▁▂▇▅▅▅▃▆▅▄▃▃▄▇▃▃▃▃▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78517
wandb: best/eval_avg_mil_loss 0.47765
wandb:  best/eval_ensemble_f1 0.78517
wandb:            eval/avg_f1 0.78517
wandb:      eval/avg_mil_loss 0.45543
wandb:       eval/ensemble_f1 0.78517
wandb:            test/avg_f1 0.76068
wandb:      test/avg_mil_loss 0.50162
wandb:       test/ensemble_f1 0.76068
wandb:           train/avg_f1 0.75389
wandb:      train/ensemble_f1 0.75389
wandb:         train/mil_loss 0.61021
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sleek-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gvlue6q1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_230428-gvlue6q1/logs
wandb: Agent Starting Run: drdxs4r6 with config:
wandb: 	actor_learning_rate: 0.006765969495559222
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3563525197944055
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7229306457254973
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_230551-drdxs4r6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/drdxs4r6
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▁▃█▄▅▆▇█▆▅▄▅▅▃▄▁▂▁▃▇▅▅▃▂▄█▄▆▂▇▁▄▆█▅▄▆▄
wandb:      train/ensemble_f1 ▅▆▅▂█▃▃▄▇▆▅▂▄▄▄▂▁▆▅▆▄█▅▆▄▄▃▃▇▂▃▁█▅▄▂▆▇▅▄
wandb:         train/mil_loss ▃▆▂▇▃▆▂▄▅▅▄▃▅▅▄▄▅▃▄▄▇▃▇█▆▂▃█▅▅▂█▃▄▃▁▆▄▅▁
wandb:      train/policy_loss ▄▄▃▄▄▄█▄▂▄▄▄▄▄▄▅▅▁▂▆▄▂▄▄▇▄▂▅▇▄▄▆▃▄▆▆▄▄▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▅▇▂▄▁▃▄▄▃▅▄▃▂▁▂▂▅▅▇▄▃▂▄▂▆▂▆█▅▅▃▄▇▆▅▅▃▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.98187
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.96315
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.09285
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33166
wandb:      train/ensemble_f1 0.33166
wandb:         train/mil_loss 0.72273
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run magic-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/drdxs4r6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_230551-drdxs4r6/logs
wandb: Agent Starting Run: 2wr31gu8 with config:
wandb: 	actor_learning_rate: 0.0030811414304221236
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2826399037739322
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.009707448699849077
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_230714-2wr31gu8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2wr31gu8
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▄▁▅▅▆▅▆▅▆▆▆▅▅▅▅▃▆▄▅▅▇▃█▆▅▇▇▅▆▅▅▅▅▁▁▆▅▅
wandb:      train/ensemble_f1 ▅▄▁▅▅▆▇▅▄▆▇▄▃▃▄▅▅▃▇▄▆▆▅▄▆▇▇▄█▇▅▇▇▄▄▅▆▁▆▃
wandb:         train/mil_loss █▄▄▄▅▁▅▅█▄▂▆▇▄▂▃▇▂▆▃▅▅▆▁▅▄▃▃▅▄▁▃▆▃▆▅▁▂▃▅
wandb:      train/policy_loss ▃▅▅▅▇▃▁▃▂█▄▅▄▃▅▃▆▅▄▄▃▅▆▄▄▄█▄▅▅▅▆▄█▆▅▅█▅▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆▅▃▅▄▅▄▅▂▁█▅▇▄▄▂▄▅▃▂▄▃▃▃▆▄▇▇▃▃▅▄▂▇▅▄▄▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 7.29591
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 6.98933
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 9.11982
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33389
wandb:      train/ensemble_f1 0.33389
wandb:         train/mil_loss 6.20252
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dazzling-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2wr31gu8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_230714-2wr31gu8/logs
wandb: Agent Starting Run: zdoewdjy with config:
wandb: 	actor_learning_rate: 5.86318513041789e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.14936054400851795
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7636922524832905
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_230836-zdoewdjy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zdoewdjy
wandb: uploading history steps 122-124, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▁▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▅██████████████████▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▅██████████████████▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▃▇▆▄▂▅▆█▄▅▄▁▅▇▂▅▅▆▃▃▂▃▃▅▄▆▃▅▂▃▄▂▄▅▄▃▅▇
wandb:      train/ensemble_f1 ▅█▂▆▅█▂▄▆▆▃▅▅▃▂▃▄▅▃▆▂▅▃▄▂▄▅▃▃▄▁▂▄▃▃▄▄▁▁▆
wandb:         train/mil_loss █▅█▅▆▁▇▆▃▆▃▅▅▁▂▅▅▇▅▆▂▅▄▄▅▅▄▄▃▄▃▂▃▅▅▃▅▄▃▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▂▁▂▃▂▂▁▂███████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68286
wandb: best/eval_avg_mil_loss 0.54092
wandb:  best/eval_ensemble_f1 0.68286
wandb:            eval/avg_f1 0.67159
wandb:      eval/avg_mil_loss 0.52449
wandb:       eval/ensemble_f1 0.67159
wandb:            test/avg_f1 0.55433
wandb:      test/avg_mil_loss 0.71906
wandb:       test/ensemble_f1 0.55433
wandb:           train/avg_f1 0.62284
wandb:      train/ensemble_f1 0.62284
wandb:         train/mil_loss 0.72061
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fancy-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zdoewdjy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_230836-zdoewdjy/logs
wandb: Agent Starting Run: uc9usjk8 with config:
wandb: 	actor_learning_rate: 0.00014250513251566876
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.31049233323517167
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9034695430045376
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_231015-uc9usjk8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uc9usjk8
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▇▃▅▇▃▆▅▄▅▇▃▁▆▇▆▅▆▇▃▄▅▃▂▄██▃▄█▄▄▂▂▆▅▆▆▄▆
wandb:      train/ensemble_f1 ▅▂▂▄▄▃▅▆▆▇▄▆▃▁▅▇▅▄▆▃▇▄▃▇▅▆▅▆▂▃▂▄▆▆▅▅▆▇▃█
wandb:         train/mil_loss ▃█▆▁▇▄▄▄▅▄▅▃▅▅▆▅▅▃▃▂▆▃▂▄▄▅▂▅▄▄▄▄▄▃▃▃▅▄▆▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 0.94937
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.88537
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 0.76119
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.40574
wandb:      train/ensemble_f1 0.40574
wandb:         train/mil_loss 0.77092
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run twilight-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uc9usjk8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_231015-uc9usjk8/logs
wandb: Agent Starting Run: eot6fu05 with config:
wandb: 	actor_learning_rate: 0.0026393305010779513
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6642575712211667
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.00705150437729074
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_231138-eot6fu05
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eot6fu05
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▁▇
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅████████████████████
wandb:      eval/avg_mil_loss ▇▇▇▇▇▆▆▆▆▅▅▅▅▅▆██▇▇▆▅▅▅▅▅▅▅▄▄▄▃▃▃▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▂▅▃▅▄▄▄▃▇▂▂▅▂▆▃▅▂▂▃▅█▃▁▄▃▂▄▄▄▆▅▃▇▂▃▄▅▄▄
wandb:      train/ensemble_f1 ▆▇▆▅▅▅▆▅▃▇▆▄█▅▄▅▄▅▅▆▄▇▆▂▆▃▅▇▆▃▆█▇▄▄▆▄▃▄▁
wandb:         train/mil_loss ▆▄▆▃▅▆▃▅▆▆▆▂▂▄▂█▅▅▄▅▄▇▄▁▆▇▅▃▆█▆▃█▇▄▅▂▇▆▇
wandb:      train/policy_loss ████████████████▁███████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████▁█████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.52497
wandb: best/eval_avg_mil_loss 1.33281
wandb:  best/eval_ensemble_f1 0.52497
wandb:            eval/avg_f1 0.52497
wandb:      eval/avg_mil_loss 1.26919
wandb:       eval/ensemble_f1 0.52497
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.99689
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.56657
wandb:      train/ensemble_f1 0.56657
wandb:         train/mil_loss 1.0208
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rare-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eot6fu05
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_231138-eot6fu05/logs
wandb: Agent Starting Run: bq1xvpaj with config:
wandb: 	actor_learning_rate: 0.00025145782221163657
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.081842664633896
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.48546842216222175
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_231331-bq1xvpaj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bq1xvpaj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▁▆▅▂▄▃▄▆▇▅▇▆▅▄▅▆▅▄▅▇▂█▂▃▄▄█▅▆▅▆▄▇▁▃▄▃
wandb:      train/ensemble_f1 ▄▃▅▇▆▃▂▃▂▅▆▆▃▆▇▅▇▇▆▆▅▆▅█▃▂▄█▄▆▅▆▆▅▆▅▁▅▇▃
wandb:         train/mil_loss ▇▆▇▂▅█▃▆▆▆▇▄▇▅▅▅▅▆▆▆▁▅▆▅▄▆▅▆▅▄▅▅██▃▄▄▆▆▄
wandb:      train/policy_loss ▄▅▅▄▄▆▁▄▃▅▃▁▆▆▃▆▃▆▆▃▅▄▄▃▁▅█▅▃▁█▄▅▃▃▃▆▅▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▄▂▅▂▄▂▅▅▅▅▂▅▅▁▅▅▄▅▂▄▂▂▅▇▄▁▅▅▇▄▄▂█▄▅▅▄▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 7.7937
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 7.4651
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 9.59549
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32773
wandb:      train/ensemble_f1 0.32773
wandb:         train/mil_loss 6.22129
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run prime-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bq1xvpaj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_231331-bq1xvpaj/logs
wandb: Agent Starting Run: s7ridn9x with config:
wandb: 	actor_learning_rate: 1.0145820864340953e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.23807667578568648
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8845374377365863
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_231454-s7ridn9x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s7ridn9x
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁███████████████████████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁██████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▆█▂▁▃▃▂▆▂▅▄▄▄▂▆▄▄▆▁▄▄▂▃▄▅▄▁▄▃▃▂▆▄▆▅▃█▂
wandb:      train/ensemble_f1 ▅▅▇█▅▅▅▇▃▅▁▅▇▅▆▄▅▆▄▅▄▆▃▅▅▅▇▅▆▆▇▆▆▆▄▄▅▅▅▅
wandb:         train/mil_loss ▄▅█▆▆▄▇▆▃▄▅█▆▆▄▂▃▃▂▃▆▄▅▄▅▅▂▅▁▄▃▂▇▂▁▃▄▃▅▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▅█▄▆▇▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49286
wandb: best/eval_avg_mil_loss 0.81092
wandb:  best/eval_ensemble_f1 0.49286
wandb:            eval/avg_f1 0.49286
wandb:      eval/avg_mil_loss 0.76121
wandb:       eval/ensemble_f1 0.49286
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.6714
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.54415
wandb:      train/ensemble_f1 0.54415
wandb:         train/mil_loss 0.8151
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/s7ridn9x
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_231454-s7ridn9x/logs
wandb: Agent Starting Run: 330bcuu3 with config:
wandb: 	actor_learning_rate: 0.0021375243838405514
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.84725095283321
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.18954063531453305
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_231633-330bcuu3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/330bcuu3
wandb: uploading history steps 182-197, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▄▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅████████████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅███████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▄▄▆▁▇▅▅▅▆▅▆▇▄▄▂▂▄█▅█▆▄▂▃▃▆▅▅▂▅▄▅▅▇▅▄▅▄
wandb:      train/ensemble_f1 ▅▁▅▂▅▃▂▄▆▅▆▁▅▃▄▆▆▅▆▄▂▄▂▄▆▄▅▄▂▂▇▅▆▇▁▅██▃▄
wandb:         train/mil_loss ▄▃▃▅▄▁▁▅▄▃▂▃▂▅▄▂▂▃▅▃▂▃▅▂▄▄█▄▄▁▂█▃▁▃▃▃▃▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58478
wandb: best/eval_avg_mil_loss 1.09869
wandb:  best/eval_ensemble_f1 0.58478
wandb:            eval/avg_f1 0.58478
wandb:      eval/avg_mil_loss 1.03902
wandb:       eval/ensemble_f1 0.58478
wandb:            test/avg_f1 0.5842
wandb:      test/avg_mil_loss 0.84987
wandb:       test/ensemble_f1 0.5842
wandb:           train/avg_f1 0.58178
wandb:      train/ensemble_f1 0.58178
wandb:         train/mil_loss 0.6926
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run copper-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/330bcuu3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_231633-330bcuu3/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wvmnvuru with config:
wandb: 	actor_learning_rate: 0.0007802821225781047
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.42466977682360374
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.18166063646356267
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_231913-wvmnvuru
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wvmnvuru
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▃▅▄▃▄▅▃▃▁▇▃▃▂▃▅▄▃▃▅█▁▄▁▄▃▂▃▅▄▄▅▄▅▆▅▃▄▄
wandb:      train/ensemble_f1 ▁▅▃▄▃▃▆▆▆▃▅▁▇▇▃▂▂▃▄▃▇▅█▃▁▅▃▄▄▃▄▅▄▅▅▅▆▆▅▄
wandb:         train/mil_loss ▃▃▄▄▄█▄▅█▆▁▂▄▅▆▅▄▆▄▂▃▆▁▇▅▄▇▃▄▄▂▄▃▄▆▅▆▂▄▆
wandb:      train/policy_loss ▂▅█▄▃▇▃▅▆▃▆▆▅▅█▆█▆▆▃▃▁▃▆▁▂▄▂▄▃▆▆▅▅▃▆▅▆▁▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▅▂▆▆▃▆▅▃▅▅▂▆▃▂▆▃▂▃▂▇▃▂▁▁▂█▅▄▅▆▄▅▄▃▂▄▄▃▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.38558
wandb: best/eval_avg_mil_loss 0.71922
wandb:  best/eval_ensemble_f1 0.38558
wandb:            eval/avg_f1 0.38558
wandb:      eval/avg_mil_loss 0.68742
wandb:       eval/ensemble_f1 0.38558
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.60397
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.45099
wandb:      train/ensemble_f1 0.45099
wandb:         train/mil_loss 0.73521
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ethereal-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wvmnvuru
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_231913-wvmnvuru/logs
wandb: Agent Starting Run: iewv9kym with config:
wandb: 	actor_learning_rate: 4.443632370121209e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.16058798999544344
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6412330410017182
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_232035-iewv9kym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iewv9kym
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▇▃▄▆▁▄▄▄▄▃▄▅▃█▄▅▃▄▂▂▄▃▄▃▄▃▃▇▄▄▆▄█▅▄▇▅▇
wandb:      train/ensemble_f1 ▅▅▂▄▂▄▄▄▄▃▃▆▄▁▅▂▄▃▂▁▃▄▄▄▄▃▃▆▅▄▄▃▄▅█▄▃▄▃▇
wandb:         train/mil_loss ▃██▆▇█▅▆▄▇▆▄▅▃▅▃▃▆▃▄▃▆▄▅▆▂▂▅▃▂▃▄▂▄▁▁▅▃▄▄
wandb:      train/policy_loss ██▅▄▃▆▄▆▆▄▅█▆▃▆▆▃▅▄▂▅▃█▅▅▅▃▄█▇▁▃█▄▁▅▂█▃▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▃▅▂▂▃▂▅▃▆▅▁▂▃▄▅▄▄▂█▄▃▆▂▆▄▃▄▆▂▅▅▄▆▆▄▂▄▃▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.40476
wandb: best/eval_avg_mil_loss 0.68609
wandb:  best/eval_ensemble_f1 0.40476
wandb:            eval/avg_f1 0.40476
wandb:      eval/avg_mil_loss 0.66416
wandb:       eval/ensemble_f1 0.40476
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.58565
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.48564
wandb:      train/ensemble_f1 0.48564
wandb:         train/mil_loss 0.70382
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lively-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iewv9kym
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_232035-iewv9kym/logs
wandb: Agent Starting Run: nu0lleh2 with config:
wandb: 	actor_learning_rate: 0.0017952916005527977
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9346707202958924
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3404514279071662
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_232305-nu0lleh2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nu0lleh2
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▆▆▆▅▅▅▅▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▅▃▄▆▃▂▂▂▃▄▆▅▃▃▄▂▂▄▄█▅▄▃▄▄▅▅▆▃▃▇▂▅▆▅▁▆█
wandb:      train/ensemble_f1 ▂▇▃▄▅▃▂▂▅█▃▆▂▁▄▄▆▂▄▅▆▄▃▄▅▄▄▆▃▄▆▅▃▄▂▅▃▄▇▁
wandb:         train/mil_loss ▂▃▁▁▃▃▂▃▅▄▄██▂▁▃▂▅▄▄▂▁▂▂▃▁▄▃▃▃▂▅▃▂▄▄▃▄▂▃
wandb:      train/policy_loss ▁▃▆█▆▆▃▅▄▆▆█▃▆▄▃▁▄▆█▆█▆▃▄▆▆█▆▆▆█▆▄▄▃▁▆▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆██▆▆▅▆▆▁▇▇▄▇▇▇▅▅▇▆█▆█▇▅██▇▇█▇▇▃▆▆▅▅▇▅▇▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 7.55289
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 7.46062
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 9.3563
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.35118
wandb:      train/ensemble_f1 0.35118
wandb:         train/mil_loss 1.26183
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run denim-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nu0lleh2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_232305-nu0lleh2/logs
wandb: Agent Starting Run: 2itl20s3 with config:
wandb: 	actor_learning_rate: 5.585535565300954e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8514130363266681
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5308553199076156
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_232428-2itl20s3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2itl20s3
wandb: uploading history steps 101-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄█▂▄▅▃▄▃▄▃▂▂▃▆▁▅▆▅▅▅▄▆▄▄▅▄▅▄▄▄▅▂▆▄▃▄▇▃▄▄
wandb:      train/ensemble_f1 █▂▅▆▆▅▅▃▄▅▃▂▆▂▆▆▆▆▅▄▃▅▄▄▅▄▁▅▆█▇▆▄▄▄▄▃▃▅▆
wandb:         train/mil_loss ▅▅▇▄▃▆▃▂▃▆▄▂█▃▅▄▆▃▁▅▇▂▂▅▄▃▄▂▄▃▃▄▄▄▆▇▄▅▄▇
wandb:      train/policy_loss ▄▆▃▅▃▃▄▂▂▄▆▄▄▁█▄▅▆▆▃▇▄▅▄▂▇▅█▅▃▄▃▆▃▃▂▆▅▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▂▄▄▃▃▅▇▆▃▆▁▅▂▅▅▆▅▆▄▂▇▅▅▄▆▅█▄▅▄▄▄▆█▄▃▅▅▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 2.66278
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 2.60943
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 3.40472
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3372
wandb:      train/ensemble_f1 0.3372
wandb:         train/mil_loss 1.04346
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run winter-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2itl20s3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_232428-2itl20s3/logs
wandb: Agent Starting Run: e57szdhk with config:
wandb: 	actor_learning_rate: 5.874867531556729e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.257368562621751
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6056431750972749
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_232550-e57szdhk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e57szdhk
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▅▅▄▄▃▄▃▂▂▃▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▄▃▆▆▂▂▄▂▆▄▂▂▂▁▂▃▂▃▆▃▅▅▄▆▆▄▃▄▄▅▄▃▃▅█▆▅
wandb:      train/ensemble_f1 ▄▃▃▅▃▂▃▅▅▇▂▆▄▁▇▃▂▃▃▄█▇▅▆▆▆▄▇▁▃▅▅█▆▅▅▆▇▅▄
wandb:         train/mil_loss ▄▆█▇█▄▄▃▆▃▆▄▆▄▆▅▆▇█▆▂▄▆▁▇▃▅█▅▇▄▇▂▇▇▄▄▁▆▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.33277
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.23397
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 1.15598
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.39389
wandb:      train/ensemble_f1 0.39389
wandb:         train/mil_loss 1.25363
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run proud-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e57szdhk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_232550-e57szdhk/logs
wandb: Agent Starting Run: sc8vlbe3 with config:
wandb: 	actor_learning_rate: 4.406891979862583e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.14253525837296854
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5573976189354976
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_232714-sc8vlbe3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sc8vlbe3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▆▅▂▃▆▆▆▁▆▄▁█▇▅▇▆▅▅▅▅▅▆▁▆▇▅▅▄▆▅▃▃▅█▄▄▆▇
wandb:      train/ensemble_f1 ▄▃▆▄▃▃▅▅▆▅▂▄▄▃▄▅▆▆▄▅▃▄▄▅▆▁▆▁▄▅▆▆▄█▇▃▅▄▆▇
wandb:         train/mil_loss ▃▇█▇▆▄▄▆█▄▅▅▆▆▂▅▅▆▆▄▄▅▅▅▆▆▅▄▂▄▅▄▃▅▄▇▄▅▅▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.24221
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.11925
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.88049
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.43328
wandb:      train/ensemble_f1 0.43328
wandb:         train/mil_loss 0.94841
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run denim-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/sc8vlbe3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_232714-sc8vlbe3/logs
wandb: Agent Starting Run: d1g46prh with config:
wandb: 	actor_learning_rate: 0.0003477947233551837
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9178806512150418
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.934469494534487
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_232836-d1g46prh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d1g46prh
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████▇▆▆▆▅▅▅▅▆▅▄▄▅▅▄▄▃▃▅▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▅▄▄▅▂▄▂▆▆▄▅▅▂▅▇█▇▃▅▅▆█▅▄▅▄▅▄▄▅▃▆▂▆▂▇▁▂
wandb:      train/ensemble_f1 ▄▁▄▃▅▃▄▆▅▄▄█▂▅▅█▆▅▄▅▆▃▂█▆▆▆▃▅▆▃▅▆▄▄▄▃▂▆▂
wandb:         train/mil_loss ▂▃▅▂▃█▄▅▄▅▅▅▃▃▅▃▂▃▁▃▄▅▅▄▃▄▃▄▂▆▅▆▄▃▃▄▃▅▆▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79475
wandb: best/eval_avg_mil_loss 0.59845
wandb:  best/eval_ensemble_f1 0.79475
wandb:            eval/avg_f1 0.79475
wandb:      eval/avg_mil_loss 0.59265
wandb:       eval/ensemble_f1 0.79475
wandb:            test/avg_f1 0.82175
wandb:      test/avg_mil_loss 0.45048
wandb:       test/ensemble_f1 0.82175
wandb:           train/avg_f1 0.76252
wandb:      train/ensemble_f1 0.76252
wandb:         train/mil_loss 0.52053
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run floral-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/d1g46prh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_232836-d1g46prh/logs
wandb: Agent Starting Run: vby60h53 with config:
wandb: 	actor_learning_rate: 0.0021313271993532944
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4554017195980785
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3510352373305369
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_232959-vby60h53
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vby60h53
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▄▆▆▅▆▂▄▅▅▇▅▇▇▅▆▄▄▄▅▄▄▄▁▄▃▄▆▅▂▄▆▅▅▆██▆▅
wandb:      train/ensemble_f1 ▄▄▆▄▆▅▅▄▅▅▆▇▆▄▆▂▅▂▆▂▄█▆▁▁▃▅▄▃▅▅▆▂▆▃▆█▃▇▄
wandb:         train/mil_loss ▆▃▄▅▃▅▂▄▄█▅▃▃▁▄▅▆▃▄▂▃▂▃▃▁▃▃▄▃▅▄▃▃▃▁▃▁▂▄▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55556
wandb: best/eval_avg_mil_loss 0.618
wandb:  best/eval_ensemble_f1 0.55556
wandb:            eval/avg_f1 0.55556
wandb:      eval/avg_mil_loss 0.59505
wandb:       eval/ensemble_f1 0.55556
wandb:            test/avg_f1 0.49993
wandb:      test/avg_mil_loss 0.56333
wandb:       test/ensemble_f1 0.49993
wandb:           train/avg_f1 0.53327
wandb:      train/ensemble_f1 0.53327
wandb:         train/mil_loss 0.61615
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run comic-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vby60h53
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_232959-vby60h53/logs
wandb: Agent Starting Run: 4wuwess1 with config:
wandb: 	actor_learning_rate: 0.003828617352530638
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7801026208753095
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8597226457134629
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_233123-4wuwess1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4wuwess1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▄▄▂▇▂▂▃▄▅▃▂▄▅▆▅▄▃▇▅▃▅▁▅▅▇▅▆▄▅▄█▄▅▃▃▃▅█
wandb:      train/ensemble_f1 ▂▁▄▅▄▄▃▄▄▃▂▄▄▃█▃▄▅▂▁▃▅▅▁▄▆▆▅▁▃▅▅▄▁▄▅▃▂▃▂
wandb:         train/mil_loss ▅▄▄▄▃▇▂▄▄▅▇▃█▇▄▅▄▄▄▄▃▂█▁█▄▃▂█▃▅█▂▅▂▆▅▆▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.73065
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.6536
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 1.28304
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.4268
wandb:      train/ensemble_f1 0.4268
wandb:         train/mil_loss 0.85333
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fancy-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4wuwess1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_233123-4wuwess1/logs
wandb: Agent Starting Run: yllt5cz7 with config:
wandb: 	actor_learning_rate: 0.004691409482370068
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4535192877418076
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8609720886921098
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_233245-yllt5cz7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yllt5cz7
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▇▅▄█▄▆▅▂▄▄▅▆▄▄▆▆▄▆▃▅▆▅▅▆▆▁▂▇▃█▂▂▄▆▃▅▇█
wandb:      train/ensemble_f1 ▃▅▄▃▁▅▄▃▆▃▅▅▄▁▄▂▃▄▅▃▂▅▄█▄▄▅▆▃▃▆▃▅▆▂▄▂▃▄▆
wandb:         train/mil_loss ▆█▅▆▇▅▂▃▃▇▂▄▃█▄▄▇▅█▄█▇▃▂▃▆▄▃▅▄▆▇▆▃▁▃▅▅▆▇
wandb:      train/policy_loss ▃▄▅▂▆▆▅▅▃▄▄▃▄▅▆█▅▂▄▅▃▁▄▆▃▅▃▄▅▅▄▄▅▅▅▃▃▆▃▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▄▄▇▅▇▃█▄▇▄▆▄▅▆█▃▂▅▆▄▄▆▅▃▁█▇▃▇▄▆▃▆▇▄▇▂▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.78862
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.77744
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.87543
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34426
wandb:      train/ensemble_f1 0.34426
wandb:         train/mil_loss 0.6999
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zesty-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yllt5cz7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_233245-yllt5cz7/logs
wandb: Agent Starting Run: 5gaaz02t with config:
wandb: 	actor_learning_rate: 0.0033285620429210692
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.28421950344757096
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.17326431062281877
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_233407-5gaaz02t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5gaaz02t
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▆▅▂▃▆▄▅▄▄▆▃▄▅▂▃▄▆▄▃▃▄▃█▆▂▅█▄▆▄▇▇▂▂▄▆▄▃
wandb:      train/ensemble_f1 ▁▅▃▃▇▅▃▆▄▅▄▆▂▅█▆▃▅▆▁▃▂▅▄▃▇▇▄▅▃▆▆▅▃▄▇▃▃▂▃
wandb:         train/mil_loss ▇▆▆▄▄▇▇▃▅▄▆▆▅▄▇▅▆▂▃▇▄▅▆▁▆▅▇▃▃▆▄▇▆▅▄▅█▃▆▆
wandb:      train/policy_loss ▅▃▅▄▄▃▄▂▂▅▃▄▂▅▄▄▃▇█▄▃▄▃▂▄▇▄▃▃▆▅▅▇▇▄▁▅▇▂▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▃▅▄▅▄▅▃▃▅▃▃▅▆▄▄▃▆▃▇▇▆▅█▆▂▅▅▃▃▆▅▄▃▅▄▅▂▃▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.9302
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.91205
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.02224
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33333
wandb:      train/ensemble_f1 0.33333
wandb:         train/mil_loss 0.79981
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ancient-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5gaaz02t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_233407-5gaaz02t/logs
wandb: Agent Starting Run: kge3cmhu with config:
wandb: 	actor_learning_rate: 0.0011814953533748102
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.33700994478280377
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8992347008794016
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_233531-kge3cmhu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kge3cmhu
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▆▃▅▅▄▅▄▁▂▂▆▇▆▄▆▆▆▃▄▆▁▄▅▃▁▇▆▂▄█▅▃▄▇▇▄▅▁
wandb:      train/ensemble_f1 ▆▆▅▄▅▅▇▅▆▃▆▄▇▇▆▆▂▁▇▇▅▄▃▅▅▄▆▇▆▄█▆▇▇▄▄▄▇▅▆
wandb:         train/mil_loss ▂▂▅▆▆▄▅▃▅▇██▆▁▃█▄▆▄▆█▄▅▅▇▅▇▆▁▂▆▇▆▆▄▅▄▆▄▄
wandb:      train/policy_loss ▃▅▆▃▆▆▁▅▃▄▃▂▃▂▆▆▆▄▄▆▄▂█▆▆▅▆▃█▅▄▄▃▄▃▅▆▁▆▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▃▇▄▅▃▅▁▂▄▃▄▄▄▅▄▄▇▂▄▂▁▅▂▄▅▅▇▅▄▃▄▇▄█▂▅▅▄▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 7.65216
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 7.37314
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 9.48662
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.31973
wandb:      train/ensemble_f1 0.31973
wandb:         train/mil_loss 4.75947
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eternal-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kge3cmhu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_233531-kge3cmhu/logs
wandb: Agent Starting Run: aykgv7r1 with config:
wandb: 	actor_learning_rate: 0.002396015740625909
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8482816161993557
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.060098675685098635
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_233654-aykgv7r1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/ml0hiobq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aykgv7r1
wandb: uploading history steps 101-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▃▄▄▆▁▄▅▅▃▄▅▄▄▇▇▄▄▅▄▆▄▅▄▄▅▄▄▄█▃▆▆▄▆▄▃▄▅
wandb:      train/ensemble_f1 ▁▃▆▄▄▂▆▅▅▄▅▆▆▇▅█▇▅▆▅▇▅▄▃▄▄▅▄▅▆▅▄█▅▄▅▆▄▄▅
wandb:         train/mil_loss ▆▅▂▆▃▆▆▇▄▄▅▃▄▄▇▆▄█▃▄█▄▇▇█▆▅▃▇▅█▄▇▅▅▆▄▂▇▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.50912
wandb: best/eval_avg_mil_loss 0.80024
wandb:  best/eval_ensemble_f1 0.50912
wandb:            eval/avg_f1 0.50912
wandb:      eval/avg_mil_loss 0.77575
wandb:       eval/ensemble_f1 0.50912
wandb:            test/avg_f1 0.52696
wandb:      test/avg_mil_loss 0.61332
wandb:       test/ensemble_f1 0.52696
wandb:           train/avg_f1 0.52565
wandb:      train/ensemble_f1 0.52565
wandb:         train/mil_loss 0.52634
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wobbly-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aykgv7r1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_233654-aykgv7r1/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: 4tzkuomb with config:
wandb: 	actor_learning_rate: 0.00041963255857551394
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5444020924774958
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4788872374162707
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_233901-4tzkuomb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4tzkuomb
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅████████████████████▅▅▅▅
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅████████████████████▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▁▃▂▃▂▄▃▃▄▂▅▃▅▄▄▅▆▃▇▃▅▆▃█▇▅▅▆▆▅▇▅▆▆▅▇▇▇
wandb:      train/ensemble_f1 ▁▁▂▂▃▅▄▂▄▂▅▄▃▅▆▃▄▄▄▄▅▃▄▃▆▆▂▃▅▄█▃▆▆▅▆▇▆▇▆
wandb:         train/mil_loss ▃▇▃▆▃▇▃▄▅▅▇▅█▅▆▄▅▃▄▅▄▄▃▅▅▄▄▃▃▄▄▄▅▃▃▄▆▄▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.796
wandb: best/eval_avg_mil_loss 0.59078
wandb:  best/eval_ensemble_f1 0.796
wandb:            eval/avg_f1 0.78639
wandb:      eval/avg_mil_loss 0.53441
wandb:       eval/ensemble_f1 0.78639
wandb:            test/avg_f1 0.81439
wandb:      test/avg_mil_loss 0.46652
wandb:       test/ensemble_f1 0.81439
wandb:           train/avg_f1 0.80337
wandb:      train/ensemble_f1 0.80337
wandb:         train/mil_loss 0.56102
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run denim-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4tzkuomb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_233901-4tzkuomb/logs
wandb: Agent Starting Run: jscvcs7y with config:
wandb: 	actor_learning_rate: 0.00040204506212888994
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.46869556663617296
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08231070184808364
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_234126-jscvcs7y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jscvcs7y
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████████
wandb:      eval/avg_mil_loss ███████▇██▆▆▆▆▅▄▄▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁█████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▄▇▆▇▂▆▅▄▆▅▂▇▃▅▅▂▃▆▂▆█▅▇█▆▃▇▄▃▅▆▆▅▄▇█▅▇
wandb:      train/ensemble_f1 ▁▃▄▆▂▃▅▃▁▄▇▇▃▃▅▆▂▆██▄▇█▅▅█▄▆▃▆▃▅▅▆▅▅▄▃▄▄
wandb:         train/mil_loss ▅▄▃▂▁▅▂▂▄█▃▇▆▄▃▇▅▅▄▃▅▄▆▂▅▆▆▅▃▅▄▃▂█▂▃▅▃▅▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.62667
wandb: best/eval_avg_mil_loss 0.53099
wandb:  best/eval_ensemble_f1 0.62667
wandb:            eval/avg_f1 0.62667
wandb:      eval/avg_mil_loss 0.52524
wandb:       eval/ensemble_f1 0.62667
wandb:            test/avg_f1 0.56234
wandb:      test/avg_mil_loss 0.62013
wandb:       test/ensemble_f1 0.56234
wandb:           train/avg_f1 0.58114
wandb:      train/ensemble_f1 0.58114
wandb:         train/mil_loss 0.68964
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run firm-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jscvcs7y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_234126-jscvcs7y/logs
wandb: Agent Starting Run: 9g0uzufh with config:
wandb: 	actor_learning_rate: 1.2091072293301084e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9588099667049648
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4117942927623251
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_234324-9g0uzufh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9g0uzufh
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▂▆▅▂▆▅█▄▇▃▅▅▄▄▂▂▂▃▄▅▂▅▂▅▆▁▃▃▃▂▄▂▆▄▃▄▄▃▄
wandb:      train/ensemble_f1 ▆▃▇▃▇▅▄▂▄█▃▃▆▄▃▅▅▇▄▃▅▂▄▅▆▅▇▆▁▅▄▅▅▃▅▂▄▅▃▇
wandb:         train/mil_loss ▆▄▃▁▃▂▃▂▆▁▂▂▄▂▂▁▄█▄▆▆▅▄▄▄▆▂▃▂▅▅▁▄▃▄▇▂▅▁▆
wandb:      train/policy_loss ▆██▆████▆▅▆▆█▁█▁█▆▆▅▃▁▆▃▆▄▆█▆█▆▃▆▃▄▄▆▆█▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄█▅▆▆▆▆████▆▆▆▆▆█▆███▃▃▁▄▄▆▆▆▆▄█▄▃▆▄█▄█▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 3.98468
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 3.93722
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 5.48968
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.35118
wandb:      train/ensemble_f1 0.35118
wandb:         train/mil_loss 0.79843
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run true-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9g0uzufh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_234324-9g0uzufh/logs
wandb: Agent Starting Run: rz10bd56 with config:
wandb: 	actor_learning_rate: 0.0004690169453555175
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3920696403052172
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.33010637609340654
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_234453-rz10bd56
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rz10bd56
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃█▅▅▆▃▂▇▄▆▇▆▇▆▁▄▄▄▆▅▄▆▄█▂▆█▇▄▆▄▆▅▃▅▅█▄▆▆
wandb:      train/ensemble_f1 ▃█▄▅▆▄▆▆▄▃▇▇▅▇▅▄▇▇█▅▃▄▅▄▄▅▆▄▄▅▁▅▅▄█▆▅▃▆▆
wandb:         train/mil_loss ▄▃▃▁▅▅█▆▅▃▅▄▄▅▆▆▆▂▆▅▄▅▇▁▄▅▅▁▃▆▄▆▅▃▄▂▃▆▂▄
wandb:      train/policy_loss ▆█▅▂▂▅▅▂▁▄▆▄▅▅▄▄▃▄▆▄▇▃▇▅▄█▅▄▅▅▅▄▅▃▅▇▄▅▇▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▆▅▁▇▄▄▄▂▄▅▅▅▃▇▃▂▄▅▁▇▇▅▄▄▇▅██▃▂▄▅▃▂▇▆▄▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 7.49393
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 7.21523
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 9.32574
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.31741
wandb:      train/ensemble_f1 0.31741
wandb:         train/mil_loss 4.40199
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stoic-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rz10bd56
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_234453-rz10bd56/logs
wandb: Agent Starting Run: i4uk9djo with config:
wandb: 	actor_learning_rate: 1.7530113553093296e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7250319956508149
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4399097322582993
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_234620-i4uk9djo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i4uk9djo
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▄▇▅▄▆▇▅▆▅▁▃▃▅▄▆▆▃▆▆▁▆▆▇▆▃▄▅▇▇▆▇█▂█▃▆▂▃
wandb:      train/ensemble_f1 ▅▅▄▄▂▇▇▆▃▄▃▄▃▄▄▆▅▃▅▅▅▅▄▅▆▃▄██▇▆▃▇▇▅▆▇▃▅▁
wandb:         train/mil_loss ▃▂▄▆▂▅▇▇▅▅▄▇▅▃█▅▃▆█▁▄▃▃▄▄▅▄▄▅▆▆▃▃▅▄▆▄▃▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.6044
wandb: best/eval_avg_mil_loss 0.56954
wandb:  best/eval_ensemble_f1 0.6044
wandb:            eval/avg_f1 0.59603
wandb:      eval/avg_mil_loss 0.5505
wandb:       eval/ensemble_f1 0.59603
wandb:            test/avg_f1 0.55076
wandb:      test/avg_mil_loss 0.51083
wandb:       test/ensemble_f1 0.55076
wandb:           train/avg_f1 0.57795
wandb:      train/ensemble_f1 0.57795
wandb:         train/mil_loss 0.59345
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run balmy-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/i4uk9djo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_234620-i4uk9djo/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pvrbyfag with config:
wandb: 	actor_learning_rate: 0.0027700878428688048
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.028279096872773746
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.16056963755245335
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_234755-pvrbyfag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pvrbyfag
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃█▅▇▅▆▄▆▇▆▆▄▁▇▄▆▄▅▃▆▇▆▇▂▆▆▆▅▇▆▅▃▄▅▄▇▅▆▄█
wandb:      train/ensemble_f1 ▃▅▆▅█▅▂▅▇▆▄▅▁▆▅▅▆▅▆▃▄▅▆▅▄▅▅█▄▃▆▄▃▄▆▃▅▅▄▂
wandb:         train/mil_loss ▄▆▇▄█▅▃▂▄▃▄▅▄▄▆▄▇▄▆▅▇▅▅▅▁▇▂▄▂▃▂▆▂▅▃▅▄▅▂▄
wandb:      train/policy_loss ▄▄▁▄▄▁██▁▄▄▁▄▁▁▁▄▄▁▄▁▁███▅▁▅▅▁▅█▁▁▅▁▁▅▅▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▆▁▁▆▁▃▆▃▁▁▆▁▁▃▃▃▁▁▆▁▁▁▆▃▁▃▃▁█▆▁▁▁▃▁▆▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.98157
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.95865
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.09243
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34534
wandb:      train/ensemble_f1 0.34534
wandb:         train/mil_loss 0.93932
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zany-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pvrbyfag
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_234755-pvrbyfag/logs
wandb: Agent Starting Run: m1gtpazb with config:
wandb: 	actor_learning_rate: 0.0017640203842659535
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1508621658566821
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6279025709921102
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_234923-m1gtpazb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m1gtpazb
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▂▂▂▂▂▂▄▅▅▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:      eval/avg_mil_loss █▅▅▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 █▁▁▂▂▂▂▂▄▄▅▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▂▁▃▇▂▃▄▁▂▂▄▂▁▆▃▇▃▅▄▅▆▄▆▇▆▅▆▇▇▄▅▇▆▄▆█▅▅▇
wandb:      train/ensemble_f1 ▂▃▂▃▂▃▁▂▂▂▂▃▂▄▄▃▄▄▄▅▆▅▆▆▁▅▆▅▄▆▆▅█▅▄█▆█▇▇
wandb:         train/mil_loss ▇▄▇▅▆▄█▅▆█▇▆▄▄▆▆▅▅▆▃▄▄▅▆█▄▆▂▁▅▅▅▃▃▄▃▄▄▄▁
wandb:      train/policy_loss █▄▄▁▂▃▂▄▄▄▄▄▄▄▄▄▄▄▄▂▁▂▂▁▂▂▁▂▃▃▂▂▁▁▇▆▆▆▄▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▃▆▆▆▆▂▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66562
wandb: best/eval_avg_mil_loss 0.7741
wandb:  best/eval_ensemble_f1 0.66562
wandb:            eval/avg_f1 0.66562
wandb:      eval/avg_mil_loss 0.61192
wandb:       eval/ensemble_f1 0.66562
wandb:            test/avg_f1 0.68431
wandb:      test/avg_mil_loss 0.53679
wandb:       test/ensemble_f1 0.68431
wandb:           train/avg_f1 0.67641
wandb:      train/ensemble_f1 0.67641
wandb:         train/mil_loss 0.72911
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polished-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m1gtpazb
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_234923-m1gtpazb/logs
wandb: Agent Starting Run: y1yu499i with config:
wandb: 	actor_learning_rate: 3.3951466459924506e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4173748644410358
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9900195467169646
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_235051-y1yu499i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y1yu499i
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▃▃▃▁▂▂▅▃▂▄▄▅▄▄▃▄▄▄▃▃▂▅▄▄▃▂▄▃▃▂█▆▃▄▅▃▅▁▄
wandb:      train/ensemble_f1 ▅▂▁▅▃▄▅▅▅▃▄▃▆▄▅▄▄▅▃▄▅▄▆▅▅▃▄▂▅▃█▆▄▅▁▆▅▂▄▅
wandb:         train/mil_loss █▂▆▃▄▂▅▄▂▆▃▁█▃▃▂▄▂▅▅▅▄▂▃▂▅▄▅▆▃▂▆▅▃▄▁▃▅▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 0.92794
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.87834
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.78562
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.41191
wandb:      train/ensemble_f1 0.41191
wandb:         train/mil_loss 0.80743
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run balmy-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y1yu499i
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_235051-y1yu499i/logs
wandb: Agent Starting Run: h6y4o8kw with config:
wandb: 	actor_learning_rate: 0.0007657897420884269
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2915968390474861
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2344327069007516
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_235219-h6y4o8kw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h6y4o8kw
wandb: uploading history steps 94-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▃▆█▇▅▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:      eval/avg_mil_loss ▁▂▄▆▇█████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       eval/ensemble_f1 ▃█▄▄▄▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▇█▆▇▅▆▂▁▃▃▃▁▄▂▂▄▃▃▃▄▁▃▃▂▄▄▃▃▄▃▄▂▃▃▄▄▄▃▄
wandb:      train/ensemble_f1 ▅██▅▆▅▃▂▁▂▃▂▃▄▄▃▂▄▁▃▃▂▂▂▃▄▄▃▄▅▄▂▃▂▄▂▄▄▃▃
wandb:         train/mil_loss ▂▄▅▆█▆▇▄█▅▆▃▄▅▅▄▆▄▅▆▄▅▅▁▃▄▃▃▇▅▄▆▂▅▅▆▅▄▄▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▆▃▅▆▆▅▆▅▄▇█▅▂▂▆▇▆▅▇▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79798
wandb: best/eval_avg_mil_loss 0.43403
wandb:  best/eval_ensemble_f1 0.79798
wandb:            eval/avg_f1 0.70833
wandb:      eval/avg_mil_loss 0.45373
wandb:       eval/ensemble_f1 0.70833
wandb:            test/avg_f1 0.70833
wandb:      test/avg_mil_loss 0.5422
wandb:       test/ensemble_f1 0.70833
wandb:           train/avg_f1 0.69153
wandb:      train/ensemble_f1 0.69153
wandb:         train/mil_loss 0.62293
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run bright-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h6y4o8kw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_235219-h6y4o8kw/logs
wandb: Agent Starting Run: enu51mjh with config:
wandb: 	actor_learning_rate: 2.6693083887116644e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6069320774756715
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.757086979258048
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_235347-enu51mjh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/enu51mjh
wandb: uploading history steps 356-371, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▄▄▅▆▆▇▇█
wandb: best/eval_avg_mil_loss █▆▆▆▅▅▄▄▄▃▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▄▄▅▆▆▇▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▂▂▂▃▃▃▃▃▃▃▃▄▅▅▆▆▇▇▇▇▇▇▇█████▇▇▇▇▇
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇███████▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▁▃▂▃▃▃▃▄▄▃▃▅▃▄▃▄▅▆▄▅▆▅▅▇▆▆▇▆█▇▇▇█▇█▇█▇
wandb:      train/ensemble_f1 ▁▂▂▃▂▃▃▃▅▃▃▄▃▄▅▆▅▆▅▄▆▆▆▆▇▆▆▆▆▇▆▅▆▇▆▇▆██▇
wandb:         train/mil_loss ▇▅▅█▆▃▅▃▆▄▃▂▅▁▄▂▃▃▂▂▂▃▄▅▂▂▄▂▂▂▂▂▂▁▂▂▄▄▂▁
wandb:      train/policy_loss ██████████████████▁███████████▁█████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77422
wandb: best/eval_avg_mil_loss 0.49512
wandb:  best/eval_ensemble_f1 0.77422
wandb:            eval/avg_f1 0.75369
wandb:      eval/avg_mil_loss 0.45114
wandb:       eval/ensemble_f1 0.75369
wandb:            test/avg_f1 0.79947
wandb:      test/avg_mil_loss 0.36498
wandb:       test/ensemble_f1 0.79947
wandb:           train/avg_f1 0.78494
wandb:      train/ensemble_f1 0.78494
wandb:         train/mil_loss 0.59346
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vocal-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/enu51mjh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_235347-enu51mjh/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wwhbzxzj with config:
wandb: 	actor_learning_rate: 1.9974547472697177e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6302696024968192
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3572148961446483
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250528_235857-wwhbzxzj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wwhbzxzj
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▇███▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▃▃▆▆▄▇▅▃▆▃▅▇▆▄▆▄▆▅▄▄▅▅█▄▃▅▁█▅▄▃▆▅▇▆▄▅▆
wandb:      train/ensemble_f1 ▄▇▆▆▆▄▆▅▄▇▇▆▃▇▆▃▄▅▄▄▄█▄▄▆█▄▆▅▆▅▆▅▄▄▆▁▆█▁
wandb:         train/mil_loss ▇▁▃▇█▆▆▄▅▅▄▆▆▆▅▇▃▇▆▇▄▆▅▅▇▂█▃▇▄▅▄▄▆▆▃█▄▇▅
wandb:      train/policy_loss ▅▅▅▄█▅▅▇▄▅▅▇▅▇▅▅▄▅▅▄▄▅▆▂▄▃▂▃▃▅▄▁▁▅▅▄▅▇▅█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▃▇▆▅▅▄▄▅▃▄▅▆▁▅▃█▃▄▄▄▇▅▄▂▆▄▁▄▁▄▆█▅▆▄▃▇▃▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.92551
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.91398
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.96258
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32146
wandb:      train/ensemble_f1 0.32146
wandb:         train/mil_loss 0.65329
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run logical-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wwhbzxzj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250528_235857-wwhbzxzj/logs
wandb: Agent Starting Run: yyhpad0l with config:
wandb: 	actor_learning_rate: 7.059710579048765e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0871885957753924
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9814158751914798
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_000025-yyhpad0l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yyhpad0l
wandb: uploading summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▄▅▅▅▆▆▆▇▇███
wandb: best/eval_avg_mil_loss █▇▇▇▆▆▅▅▄▄▃▂▂▂▁
wandb:  best/eval_ensemble_f1 ▁▃▄▄▅▅▅▆▆▆▇▇███
wandb:            eval/avg_f1 ▁▃▄▄▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇█▇▇▇▇▇██████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇███▇▇█████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▁▂▂▂▃▄▃▂▄▄▅▄▄▅▅▅▅▄▆▆▆▆▆▆▆▆▆▇██▇▇▆▇█▇▇█
wandb:      train/ensemble_f1 ▂▂▁▁▂▁▄▂▃▄▃▄▄▆▆▄▅▆▅▅▅▆▆▇▆▆▇▇▇▆▇▇▇█▇▇▇▇▇▇
wandb:         train/mil_loss █▆▅▆█▇▆▆▄▅▅▅▄▄▅▄▃▄▄▃▂▄▃▃▂▄▂▂▂▃▁▂▂▁▂▂▁▁▂▁
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄████▇▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇██▁▁▁▁▁▇██▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.796
wandb: best/eval_avg_mil_loss 0.51097
wandb:  best/eval_ensemble_f1 0.796
wandb:            eval/avg_f1 0.796
wandb:      eval/avg_mil_loss 0.44657
wandb:       eval/ensemble_f1 0.796
wandb:            test/avg_f1 0.77718
wandb:      test/avg_mil_loss 0.44363
wandb:       test/ensemble_f1 0.77718
wandb:           train/avg_f1 0.78651
wandb:      train/ensemble_f1 0.78651
wandb:         train/mil_loss 0.51341
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yyhpad0l
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_000025-yyhpad0l/logs
wandb: Agent Starting Run: zp2b04b2 with config:
wandb: 	actor_learning_rate: 0.0009795335398012875
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7138807006441571
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10630601900732696
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_000600-zp2b04b2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zp2b04b2
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄▅▄▄▅▁▇▅▅▄▃█▃▄▇▃▁▂▆▂▄▃▄▄▅▂▄▅▃▃▄▃▄▅▄▄▆▂▄
wandb:      train/ensemble_f1 ▅█▇▄▅▅▃▇▆▁▄▆██▅▄▂▅▃▃▇▃▅▆▄▅▄▅▆▆▄▆▄▅▄▆▇▅▄▄
wandb:         train/mil_loss █▆▅▂▅▅█▃▃▆▃▁▄▄▁▆▃▅▄▅▃▃▂▂▄▃▄▃▃▃▅▅▇▂▂▂▂▃▇▂
wandb:      train/policy_loss ▁▄▆▅▄███▇▆▄▇▃█▂▄▆▅▅▂▅▇▄▆▇▃█▆▄▇▇█▃▃▅▇▃▆▃▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▁▃▆▃▅▆▃▃▃▆▅█▃▆▂▅▆▆▅▆▆▃▇▅▆▆▅▅▆▄▄▆▆▄▃█▅▄▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 4.30821
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 4.20731
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 5.3456
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33555
wandb:      train/ensemble_f1 0.33555
wandb:         train/mil_loss 2.14406
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run magic-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zp2b04b2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_000600-zp2b04b2/logs
wandb: Agent Starting Run: j2fghfhv with config:
wandb: 	actor_learning_rate: 0.0015955470356954105
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.05424770984863958
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9526679308199516
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_000727-j2fghfhv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j2fghfhv
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▆▃▄▅▄▂▄▂█▄▄▃▁▃▂▅▄▅▆█▃▆▅▂▃▆▄▄▅▆▃▁▅▃▃▂▇▆
wandb:      train/ensemble_f1 ▄▄▃▆▃▅▇▄▄▅▄▃▄█▁▇▄▃▄▄▄▄▃▃▄▄▄▃▂▄▆▅▅▃▅▇▅▃▄▃
wandb:         train/mil_loss ▆▆▅██▆▇▇▆▅▄▇▇▆▃▄▅▆▄▃▄▅▁▄▆▃▄▂▆▂▄▃▃▄▂▃▃▃▃▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.46031
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.25425
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 1.02925
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.38098
wandb:      train/ensemble_f1 0.38098
wandb:         train/mil_loss 1.28311
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run grateful-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j2fghfhv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_000727-j2fghfhv/logs
wandb: Agent Starting Run: lowc3ncq with config:
wandb: 	actor_learning_rate: 0.0031153869737245965
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8037279215724021
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9252540736529103
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_000855-lowc3ncq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lowc3ncq
wandb: uploading history steps 94-105, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss ▁█
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁█████████████████████████████████████
wandb:       eval/ensemble_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▆█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/ensemble_f1 ▇██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/mil_loss ▁▂▅█▄▄▆▆▄▄▅▇▃▃▅▄▄▄▁▇▆▃▁▄▆▄▃▅▃▄▅▂▆▄▇▃▆▅▂▃
wandb:      train/policy_loss █▁██████████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▁█████████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.7756
wandb: best/eval_avg_mil_loss 0.89108
wandb:  best/eval_ensemble_f1 0.7756
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.97224
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.8
wandb:      test/avg_mil_loss 2.62593
wandb:       test/ensemble_f1 0.8
wandb:           train/avg_f1 0.32942
wandb:      train/ensemble_f1 0.32942
wandb:         train/mil_loss 0.6022
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run elated-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lowc3ncq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_000855-lowc3ncq/logs
wandb: Agent Starting Run: 524y0sdt with config:
wandb: 	actor_learning_rate: 0.0028992486728616363
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2923845430479537
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.35264760161317743
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_001023-524y0sdt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/524y0sdt
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▄▆▆▆▃▇▄▅▃▆▇▅▅▇▄▃▂▃▇▃▅▅▁▆▅▂▁▇▄▅▅▇▄▅█▄▆▆
wandb:      train/ensemble_f1 █▅▆▃▂▄▅▃▄▂▅▅▃▇▄▆▅▄▄▃▄▅▄▅▇▃▁▄▄▃▂▁▅▄█▅▅▄▇▆
wandb:         train/mil_loss ▅▅▅▆▃▃▃█▄▁▂▄▄▄▄▄▃▅▄▄▅▅▇▄▃▃▄▅▇▃▅▅▅▃▃▆▅▅▄▄
wandb:      train/policy_loss ▃▃▃▇▃▁▆▁▄▃▄▇▃▃▆▆▄▃▆▃▄▄▃▂▄▃▃▃▅█▃▃▆▅▄▂▃▃▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄█▄▇▃▂▆▁▅▆▄▆▄▄▄▅▇▃▄▄▅▅▅▅▄▄▂▃▄▅▅▂▅▂▅▄▄▅▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 7.95249
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 7.67951
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 9.76846
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34211
wandb:      train/ensemble_f1 0.34211
wandb:         train/mil_loss 5.61283
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run vivid-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/524y0sdt
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_001023-524y0sdt/logs
wandb: Agent Starting Run: j8ocbpni with config:
wandb: 	actor_learning_rate: 0.0018102794725356895
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.710836968718248
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3907725212689578
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_001150-j8ocbpni
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j8ocbpni
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▂▃█▅▂▄▅▅▃▂▃▆▄▄▅▄▄▆▃▆▄▆▃▁▅▁▄▇▂▄▄▄▆▃▆▃▂▃
wandb:      train/ensemble_f1 ▄▅▃▂▂▄▁▂▄▃▅▅▃▆▇█▅▄█▄▆▄▇▄▃▄▃▁▃▆▅▄█▂▂▅▄▄▃▃
wandb:         train/mil_loss ▁▃▄▆▅▃▅▆▅▂▄█▃▆▅▂▆▂▃▅▆▅▅▆▃▃▄▅█▃▃▃▄▇▂▂▇▃▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59245
wandb: best/eval_avg_mil_loss 0.64872
wandb:  best/eval_ensemble_f1 0.59245
wandb:            eval/avg_f1 0.59245
wandb:      eval/avg_mil_loss 0.64228
wandb:       eval/ensemble_f1 0.59245
wandb:            test/avg_f1 0.53249
wandb:      test/avg_mil_loss 0.70184
wandb:       test/ensemble_f1 0.53249
wandb:           train/avg_f1 0.54458
wandb:      train/ensemble_f1 0.54458
wandb:         train/mil_loss 0.6244
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dry-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j8ocbpni
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_001150-j8ocbpni/logs
wandb: Agent Starting Run: miu26yfg with config:
wandb: 	actor_learning_rate: 0.00020183859588186856
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.14983819682781307
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3539079479805438
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_001319-miu26yfg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/miu26yfg
wandb: uploading history steps 76-93, summary
wandb: uploading data
wandb: uploading data; updating run config
wandb: uploading history steps 94-103, summary; updating run config
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▃▄▇▅▄▃█▂▃▆▃▅▅▃▇▄▇▄▄▆▅▃▆▄▃▂▂▆█▇▁▄▅▇▆▃▂▁
wandb:      train/ensemble_f1 ▂▄▃▇▂▃▅█▃▃▁▆▄▅▃▄▇▃▆▄▅▄▂▄▃▂▅█▅▃▇▆▄█▇▃▄▃▃▆
wandb:         train/mil_loss ▄▄▇▅▅▆▅▄▆▅█▅▅▅▅▃▄▃▃▅▇▇▄▄▄▃▄▅▃▅▂▆▁▄▁▃▃▄▃▆
wandb:      train/policy_loss ▃▂▄▄▂▇▅▄▅▄▃▄▃▂▂▅▅▂▅▆█▂▅▄▆▂▃▄▁▃▄▃▃▃▃▄▃▁▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▄▇▅▅▄▅▄▃▅▄▅▃▅█▃▄▂▆▃▃▄▂▄▄▄▄▄▅▂▅▄▃▇▅▅▃▅▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3658
wandb: best/eval_avg_mil_loss 0.90712
wandb:  best/eval_ensemble_f1 0.3658
wandb:            eval/avg_f1 0.3658
wandb:      eval/avg_mil_loss 0.827
wandb:       eval/ensemble_f1 0.3658
wandb:            test/avg_f1 0.41725
wandb:      test/avg_mil_loss 0.76857
wandb:       test/ensemble_f1 0.41725
wandb:           train/avg_f1 0.40201
wandb:      train/ensemble_f1 0.40201
wandb:         train/mil_loss 0.94775
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run solar-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/miu26yfg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_001319-miu26yfg/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: c194y1m2 with config:
wandb: 	actor_learning_rate: 0.0005306958134417732
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4874415748806368
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6775098270986867
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_001538-c194y1m2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c194y1m2
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆█▃▃▅▃▃█▃▂▆▅▃▅▇▂▅▄▅▄▄▅▃▁▅▅▆▃▅▃▄▄▄▂▅▂▂▄▇
wandb:      train/ensemble_f1 ▆█▃▃▃▄▃▄█▃█▅▆▁▂▅▄▃▅▄█▄▃▄▅▅▅▆▄▅▅▆▄█▃▄▅▃▄▄
wandb:         train/mil_loss ▃▂▅▁▃▄▂▆▂▃█▅▃▅▄▆▄▄▆▅▅▅▃▄▇▄▂▄▆▃▄▄▅▆▃▂▃▃▃▆
wandb:      train/policy_loss ▇█▃▁▆▃▃▄█▆█▅▆▇▃▅▆▃█▅▅▄▅▇▇▆▆▇▇▆▃▅▄▄▇▆██▃▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆▇▁▃▆▆▂▅▄▃▄▄▅▆▃▄▃▃▄▆▄▅▄▅▅▅▄▄█▄▃▅▂▄▇▆▆▂▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.98192
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.96549
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.09297
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.348
wandb:      train/ensemble_f1 0.348
wandb:         train/mil_loss 0.78633
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run polar-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c194y1m2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_001538-c194y1m2/logs
wandb: Agent Starting Run: hw16ks5z with config:
wandb: 	actor_learning_rate: 0.00651056377404181
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.40504669454621856
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5278381744527052
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_001707-hw16ks5z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hw16ks5z
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▁▂▅▇▆▆▆█▁▂▆▅▆▃█▆▇▆▆▅▅▇▄▅▃▃▂▃▄▄▃▅▅▆▅▅▃█▆
wandb:      train/ensemble_f1 ▁█▅▅▃▃▅▇▇▅▅▃▅▆▄▅▄▄▆▁▃▄▂▅▃▂▃█▃▃▃▃▆▅▄▅▅▂▇▃
wandb:         train/mil_loss ▆▅█▇▇▅▅▃▅▇▅▄▆▄█▃█▄▆▆▆▆▆▄█▄▅██▄▄▅▇▄▆▄▇▆▁▃
wandb:      train/policy_loss ▄▄▆▂▅▅▆▅▅▄▅▄▇▇▁▇▄▇▅▅█▆▇▇▇█▅▄▄▇▆▇▆▇▇▄▆▅▆▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▇▅▇▅▆▄█▅▅▄▇▇▁▄▇▄▇▅▄█▆▄▇▆█▅▅▆▅█▄▄▇█▇▆▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 4.94529
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 4.78016
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 5.86928
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32942
wandb:      train/ensemble_f1 0.32942
wandb:         train/mil_loss 3.27017
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run radiant-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/hw16ks5z
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_001707-hw16ks5z/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5cbqc939 with config:
wandb: 	actor_learning_rate: 1.688024722004095e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8213860868152788
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1386110098607698
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_001854-5cbqc939
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5cbqc939
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇█▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▂▃▃▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▇▅▅▆▄█▁▆▆▃▂▇▅▆█▅▇▆▇▆▇▇▆▅▄▄▆█▇▄▆▅▅▆▃▇▇▇
wandb:      train/ensemble_f1 ▅▅▄▁▆▃▄▆▅▇▅▆▇▄▇▃█▆▇▂▅▄▅▇▆█▄▄▆▅▆▆▆▇▅▆▅▅▃▃
wandb:         train/mil_loss ▃▇▂▃▆▂▄▂▁▇▆▅▅▃▇▇▁▇▆▃██▄▇▄▆█▃▁▆▄▇▁▇▃▃▂▆▃▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.02008
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.00273
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 0.81959
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.38276
wandb:      train/ensemble_f1 0.38276
wandb:         train/mil_loss 0.61711
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swept-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5cbqc939
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_001854-5cbqc939/logs
wandb: Agent Starting Run: qvsv86pz with config:
wandb: 	actor_learning_rate: 0.0025790399812892105
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.997891838134149
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8234729486663047
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_002021-qvsv86pz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qvsv86pz
wandb: uploading summary; updating run config
wandb: updating run config
wandb: uploading wandb-summary.json
wandb: uploading history steps 148-189, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▆▅▁▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅██▆▆▆▆▆▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃
wandb:      eval/avg_mil_loss █▆▆▆▆▆▆▆▆▆▅▅▃▃▃▂▂▃▁▁▂▂▃▃▃▃▄▄▅▅▅▅▅▅▇▅▅▅▆▇
wandb:       eval/ensemble_f1 ▁▁▁▁▃▅▅▅▅▅▅▅▅▅▅██████▆▆▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▄▃
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▂▅▂▄▃▁▅▅▅▆▅▃▄▆▂▄▅▆▆▇▄█▃▅▄▆▅▇▆▇▅▅▄█▆▆▆▆
wandb:      train/ensemble_f1 ▄▇▆▅▆▆▁▃▃▆▃▅▄▄▅▅▅▄▅▆▇▂▅▅▇▄▃▅▄▅▇▇▄▅▇█▅▅▃▇
wandb:         train/mil_loss ▅▄▆▅▅▅▄▇▅▅▅▄▄▂█▄▃▄█▆▂▄▅▆▄▄▆▄▄▆▃▃▂▄▄▁▃▆▅▅
wandb:      train/policy_loss █████████████████████████▁██████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████▇██▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81971
wandb: best/eval_avg_mil_loss 0.75289
wandb:  best/eval_ensemble_f1 0.81971
wandb:            eval/avg_f1 0.78897
wandb:      eval/avg_mil_loss 0.82646
wandb:       eval/ensemble_f1 0.78897
wandb:            test/avg_f1 0.84554
wandb:      test/avg_mil_loss 1.11288
wandb:       test/ensemble_f1 0.84554
wandb:           train/avg_f1 0.8054
wandb:      train/ensemble_f1 0.8054
wandb:         train/mil_loss 0.57118
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rich-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qvsv86pz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_002021-qvsv86pz/logs
wandb: Agent Starting Run: f32wrje9 with config:
wandb: 	actor_learning_rate: 0.005249962329918948
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.10494985971468428
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.33653837227697536
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_002318-f32wrje9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f32wrje9
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▆▅▇▃▄█▅▄█▆▅▅▄▅▁▁▄▆▅▆▆▅▆▄█▇▇▅▃█▆▆▄▄▄▄▄▆▇
wandb:      train/ensemble_f1 ▇▅▆▃▅▂▇▆▇▃▆▄▄▇▁▃▄▄▅▂▄▃▅▄▆▆▇▅▆▇▅█▆▆▄▃▄▃▃▅
wandb:         train/mil_loss ▄▅▂▃▁▂▃▄▄▄▃▅▆▆▅▃▄▃▂▄▁▃▂▁▄▁▄▅▂▄▃▅▄▆▄█▂▂▅▄
wandb:      train/policy_loss ▄▂▅▄▇█▅▁▄▂▄▅▇▇██▇▂▇█▂▇█▂▅▂▅▄▄▇▂▅▇▅▇▇▄▇█▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▅█▇▇▅▁▄▄▄▁▂▅▇▇█▇▄▂█▄█▂▇▂▅▇▂▄▂▅▄▂▇▇▄▁█▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.01031
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.9854
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.12202
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34102
wandb:      train/ensemble_f1 0.34102
wandb:         train/mil_loss 0.9089
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f32wrje9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_002318-f32wrje9/logs
wandb: Agent Starting Run: whpeggbp with config:
wandb: 	actor_learning_rate: 0.001347099480250673
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.07438118849900766
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3775196154246194
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_002446-whpeggbp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/whpeggbp
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▄▆▅█▅▄▇▅▅▆▆▅▄▅▃▃▆▄▃▅▆▄▅▆▇▆▄▇▇▆▃▅▇▆▆▅▅▁
wandb:      train/ensemble_f1 ▅▄▇▆▄█▅▆▆▆▇▄▆▅▆▆▃▄▆▇▆▅▇▄▅▆█▇▄▅▁▃▅▅▅▃▆█▅▁
wandb:         train/mil_loss ▆▅▅▂▅▅▃▆▂▄▅▅▃▂█▄▆▄▄▇▄▆▆▃▆▆▄▇▆▁▇▂▄▄▄▄▃▄▅▅
wandb:      train/policy_loss ▄▂▄▄▄▅▅▂▅▄▂▁▄▁▄▂▄▁▂▂▅▂▂▁▂▂▂▂▄▂▂▁█▄▂▁▂▅█▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▄█▂▂▅▂▂▅▄▅▂▂▂▄▂▄▂▂▁▂▂▄▄▄▂▂▄▄▁█▄▂▅▁▇▁▄▅▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.82148
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.80448
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.91837
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.31094
wandb:      train/ensemble_f1 0.31094
wandb:         train/mil_loss 0.74531
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run breezy-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/whpeggbp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_002446-whpeggbp/logs
wandb: Agent Starting Run: jhe3z23t with config:
wandb: 	actor_learning_rate: 0.007933501285378846
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2987071525699986
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.698595934205909
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_002613-jhe3z23t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jhe3z23t
wandb: uploading history steps 132-135, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▆▆█
wandb: best/eval_avg_mil_loss █▃▂▁▂▂
wandb:  best/eval_ensemble_f1 ▁▃▄▆▆█
wandb:            eval/avg_f1 ▇▇▇▇▇▇▇▇▇▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▁▁▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▄▅▅▅▄▄▆▆█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train/ensemble_f1 ▅▅▅▅▅▅▅▅▄▆▆█▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/mil_loss ▁▁▁▁▁▁▁▁▁▁▁▃▇██▇▇▆▆▇▆▆▇▆▇█▆▇▇▇▇▇██▇▄▇▇▇▇
wandb:      train/policy_loss ███████████▄▂▁▄▃▃▄▄▄▅▃▇▄▄▆▃▃▄▂▃▄█▅▁▅▄▃▂▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▁█▅▂▃▂▃▃▄▃▃▄▃▄▃▂▃▄▄▃▄▂▃▂▄▂▂▃▃▅▃▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81818
wandb: best/eval_avg_mil_loss 0.45828
wandb:  best/eval_ensemble_f1 0.81818
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 5.35895
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.76979
wandb:      test/avg_mil_loss 0.72969
wandb:       test/ensemble_f1 0.76979
wandb:           train/avg_f1 0.32375
wandb:      train/ensemble_f1 0.32375
wandb:         train/mil_loss 4.21563
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run treasured-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jhe3z23t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_002613-jhe3z23t/logs
wandb: Agent Starting Run: 5nfxo92f with config:
wandb: 	actor_learning_rate: 8.473358394781636e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.242802814577331
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9534286665321596
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_002807-5nfxo92f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5nfxo92f
wandb: uploading history steps 581-596, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▆▇▇▇██
wandb: best/eval_avg_mil_loss ██▇▇▇▆▆▆▆▅▄▄▄▃▃▃▂▂▂▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▆▇▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████
wandb:      eval/avg_mil_loss ██▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▃▃▃▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇███████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▁▂▂▃▃▃▄▃▄▄▄▅▅▅▆▇▆▇▆▇▇▆▇▇█▇▇▇▇▇██▇▆▇██▇
wandb:      train/ensemble_f1 ▁▂▃▂▃▂▃▄▄▃▄▃▃▄▄▅▅▄▅▆▆▆▅▆▇▆▆▇▇███▇▇▇█▇▇▇█
wandb:         train/mil_loss ▇█▆█▅▆▇▇▄▅▃▆▄▆▄▄▄▃▄▃▃▂▃▂▃▂▃▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:      train/policy_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆▆▂▆▆▄▁▃▆▆▆▆▆▆█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81737
wandb: best/eval_avg_mil_loss 0.43717
wandb:  best/eval_ensemble_f1 0.81737
wandb:            eval/avg_f1 0.81737
wandb:      eval/avg_mil_loss 0.4012
wandb:       eval/ensemble_f1 0.81737
wandb:            test/avg_f1 0.81663
wandb:      test/avg_mil_loss 0.39965
wandb:       test/ensemble_f1 0.81663
wandb:           train/avg_f1 0.80106
wandb:      train/ensemble_f1 0.80106
wandb:         train/mil_loss 0.55852
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run wild-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5nfxo92f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_002807-5nfxo92f/logs
wandb: Agent Starting Run: 81cu37nw with config:
wandb: 	actor_learning_rate: 0.00789660380953073
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3198712158517103
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07383763417708522
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_003612-81cu37nw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/81cu37nw
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▅▇▆▃▇▃▇▆▄▅▅▅▆▇▅▅▅▄▆▁▅▃▄▄▄█▃▅▄▆▆▂▇▅▇▃▆▄
wandb:      train/ensemble_f1 ▂▇▄▇█▇▃▄▅▂▆▅▆▇▇▅▅▅▅▆▂▃█▁▃▆▇▅▃▇█▇█▃▆▂▆▆▃▄
wandb:         train/mil_loss ▆▆▅▇▅█▂▇▇▃▆▇▆▃█▇▄▆█▆▅▇▁▃▆▆▅█▅▅▃▂▅▃▅▅▄▄▅▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.06573
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.98328
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.844
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.38558
wandb:      train/ensemble_f1 0.38558
wandb:         train/mil_loss 0.86853
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run avid-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/81cu37nw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_003612-81cu37nw/logs
wandb: Agent Starting Run: o96bda1d with config:
wandb: 	actor_learning_rate: 5.793125201119689e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.27904445462063443
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5094521910346829
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_003740-o96bda1d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o96bda1d
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▆█▅▃▆▄▆▇▇▅▁▄▄▅▆▄▄▂▆▄▇▄▂▇▆▄▅▅▆▆▄▄▅▅▇▄▆▆
wandb:      train/ensemble_f1 ▆█▃▇▆▅▇▇▇▅▇▄▄▇▆▁▄▅▅▃▃▆▇▅▃▅▄▂▅▄▇▅▅▅▄▅▄▅▃▅
wandb:         train/mil_loss ▅▄▆▃▅▆▄▄▃▂▅▃▃▆▄▁▅▅▆▅▇█▆▆▄▃▆▄▆▃▄▃▄▅▃▅▅▃▅▅
wandb:      train/policy_loss ▅▂▅▂▆▃▄▄▃▄▅▄▄▆▄▂▂▂▂▁▅▅▅▂▄▂▄█▄▂▅▄▅▂▆▄▁▅▂▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▂▆▃▆▆▅▄▆▃▄▅▄▄▅▅▄▆▆▅▃▄▁▆▆▅█▄▂▅▄▁▂▂▂▆▄▆▃▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65157
wandb: best/eval_avg_mil_loss 0.52837
wandb:  best/eval_ensemble_f1 0.65157
wandb:            eval/avg_f1 0.65157
wandb:      eval/avg_mil_loss 0.52115
wandb:       eval/ensemble_f1 0.65157
wandb:            test/avg_f1 0.60114
wandb:      test/avg_mil_loss 0.60502
wandb:       test/ensemble_f1 0.60114
wandb:           train/avg_f1 0.60043
wandb:      train/ensemble_f1 0.60043
wandb:         train/mil_loss 0.73247
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run twilight-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/o96bda1d
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_003740-o96bda1d/logs
wandb: Agent Starting Run: aw32h4f0 with config:
wandb: 	actor_learning_rate: 0.0002687029029648472
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6046522781054673
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6709458149565644
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_003909-aw32h4f0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aw32h4f0
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▇▆▃▄▁▄▁▇▅▁▄▅▅▃▆▃▄▃▇▃▅▄▆▆▅▅▄█▃▆▄▅▅▃▅▁▂▃█
wandb:      train/ensemble_f1 ▄▆██▇▄▃▇▃▂▃▂▇▆▅▅▆▃▄▇▇▄▄▅▇▅▆▅▄▆▅▄▇▄▅▄▁▇▃▅
wandb:         train/mil_loss ▁▄▃▄█▄▁▂▇▂▅▄▄▁▇▄▂▇▃█▅▂▆▄▅▆▁▄▆▃▃▂▂▆▄▁▃▄▅▁
wandb:      train/policy_loss ▆▆▆▅▂▃▆▂▄▇▅▃▅▅▅▇▂▆▃▅▅█▇▄█▁▆▄▄▅▄▅▆▄▄▄▆▇▇▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▇▆▆▅▅▁▄▃▇▅▇▂▂▆▁▄▄▅▃▂▄▅▅█▇▄▆▅▄▄▅▄█▇▅▇▅▂▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.96442
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.95164
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.06326
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34694
wandb:      train/ensemble_f1 0.34694
wandb:         train/mil_loss 0.63454
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run helpful-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/aw32h4f0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_003909-aw32h4f0/logs
wandb: Agent Starting Run: jdkbjrtp with config:
wandb: 	actor_learning_rate: 1.2279934332987083e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5775426633739484
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6699790681690905
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_004037-jdkbjrtp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jdkbjrtp
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▄▅▃▅▅▅▆▃▃▃▃▄▅▅▆▁▅▆█▇▃▄▇▅▄▇▅▂▅▄▆▃▁▄▅▂▆▄
wandb:      train/ensemble_f1 ▄▇█▄▃▇▄▃▄▄▇▃▆▁▃▃▁▆▅▃▆█▆▅▅▆▇▆▄▄▆▇▇▆▇▆▂▆▇▅
wandb:         train/mil_loss ▆▅▆▇▇▆▇▇▆▅▇▃▇█▅▅▅▆▅▇▅▅▅▆▃▅▅▄▅▁▇▅▃▅▃█▃▅▅▇
wandb:      train/policy_loss ▆▃▅▄▆▆▃▅▄▇▆▆▆▃▆▄▃▅▅▄▃▃▄▇▃▆▂▄▄▅▆█▅▅▆▁▁▃▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▄▃▃▃▆▄▅▅▆▃▃▃▃▅▅▄▄▂█▄█▄▄▂▄█▁▃▅▇▅▄▃▄▂▂▃▄▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.96275
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.94819
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.06885
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33278
wandb:      train/ensemble_f1 0.33278
wandb:         train/mil_loss 0.7712
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run flowing-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/jdkbjrtp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_004037-jdkbjrtp/logs
wandb: Agent Starting Run: 6s7d5yss with config:
wandb: 	actor_learning_rate: 3.9183395992918294e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3837726341021258
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0878512148849332
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_004205-6s7d5yss
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6s7d5yss
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▂▃▃▄▄▅▅▅▆▆▇▇██
wandb: best/eval_avg_mil_loss █▇▇▇▆▆▆▅▅▄▄▃▃▃▃▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▂▃▃▄▄▅▅▅▆▆▇▇██
wandb:            eval/avg_f1 ▁▂▂▂▂▂▂▂▂▂▃▃▃▄▅▆▆▆▆▆▇▇▇▇▇███▇▇▇▇████▇▇██
wandb:      eval/avg_mil_loss █▇▇▇▇▇▆▆▆▆▆▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▂▂▃▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████▇▇▇████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▃▂▂▃▁▂▄▂▃▄▅▃▄▄▄▅▄▄▅▄▄▄▄▆▅▅▆▅▆▇▅▇▇▇█▇▆█
wandb:      train/ensemble_f1 ▃▂▂▂▁▂▂▃▃▂▃▄▄▃▅▄▄▄▄▆▅▆▄▇▇▆▆▆▆▇▆█▇▇▆█▇▇▇▇
wandb:         train/mil_loss ▆███▇▇▆▅▅▄▆▅▆▆▅▇▄▅▅▆▅▄▃▃▅▆▅▃▂▅▆▃▃▂▅▂▁▃▃▁
wandb:      train/policy_loss ██████████████████████████████▇▄▆▄▁▇▆▆▅█
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████████████████▄▃██▅▄█▁▃▂██▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71492
wandb: best/eval_avg_mil_loss 0.54753
wandb:  best/eval_ensemble_f1 0.71492
wandb:            eval/avg_f1 0.70289
wandb:      eval/avg_mil_loss 0.52894
wandb:       eval/ensemble_f1 0.70289
wandb:            test/avg_f1 0.64422
wandb:      test/avg_mil_loss 0.49274
wandb:       test/ensemble_f1 0.64422
wandb:           train/avg_f1 0.67565
wandb:      train/ensemble_f1 0.67565
wandb:         train/mil_loss 0.64211
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deep-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/6s7d5yss
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_004205-6s7d5yss/logs
wandb: Agent Starting Run: w5xceei1 with config:
wandb: 	actor_learning_rate: 0.0008836518351381359
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.911422806062292
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.08034366787408864
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_004602-w5xceei1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w5xceei1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▃▄▄▃▃▅▅▅▄▅▅▄▄▄▅▆▇██▆▅▆▅▄▄▂▃▃▂▁▂▁▄▄▄▃▃▃▄▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▁▁▆▄▃▆▆▃▄▅▃▃▄▆▃█▄▅▆▂▃▃▃█▃▆▄▂▇▄▂▅▅▃▃▅▅
wandb:      train/ensemble_f1 ▆▄▂▅▄▆▃▄▃▅▅▃▁▆▅█▂▃▄▅▄▃▂▆▃▃▄▂▁▆▁▄▅▂▄▂▂▆▆▄
wandb:         train/mil_loss ▅▇▅▇▄▇▅▄▆▆▂▄▄▃▂▅▁▃▄▅█▅▇▅▃▇▆▄▅▄▅▆▃▃██▂▂▅▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49286
wandb: best/eval_avg_mil_loss 0.7607
wandb:  best/eval_ensemble_f1 0.49286
wandb:            eval/avg_f1 0.49286
wandb:      eval/avg_mil_loss 0.7603
wandb:       eval/ensemble_f1 0.49286
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.65327
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.51233
wandb:      train/ensemble_f1 0.51233
wandb:         train/mil_loss 0.62038
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lilac-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w5xceei1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_004602-w5xceei1/logs
wandb: Agent Starting Run: zslhxpu5 with config:
wandb: 	actor_learning_rate: 0.002407252969518774
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.03177782315568822
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15006305904862727
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_004731-zslhxpu5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zslhxpu5
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▅▅▆▇▆▃▆▅▄█▃▃▄▁▆▇▂▃▅▃▅▅▄▅▃▄▆▅▄█▇▄▄▄▅▄▅▆
wandb:      train/ensemble_f1 ▁▄▅▅▆▂▁▂▂▄▃▆▆▅▃▁▃▄▁▄▅▃▁█▅▁▃▅▂▂▄▆▃▃▇▃▆▄▄▅
wandb:         train/mil_loss ▃▃▆▄██▅▅▆▄█▆▆▃▁▁▄▂▅▃▂▆▄▅▄▄▃▆▂▂▃▄▅▄▂▆▁▃▃▃
wandb:      train/policy_loss ▁▁▃▁▃▁▁▃▁▃▃▁▆▃▁▃▁▁▃▃▆▃▁▃▁▃▃▁▆▃▃▁▆▁▁█▃▆▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▃▃▁▁▁▁▁▃█▆▃▃▁▃▃▃▆▃▆▁▁▁▃▆▁▃▁▁▃▆▃▃▆▁▆▁▃▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.98172
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.95887
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.09151
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33665
wandb:      train/ensemble_f1 0.33665
wandb:         train/mil_loss 0.8978
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run celestial-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zslhxpu5
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_004731-zslhxpu5/logs
wandb: Agent Starting Run: 1hez7d1s with config:
wandb: 	actor_learning_rate: 5.4303975307613065e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8229062620687736
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6753084279160635
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_004859-1hez7d1s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1hez7d1s
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▆▂▄▄▃▄▅▂▂▅▅▅▄▄▃▅▆▃▅▃▇▅▅▂▂▂▃▃▅▅▃▇▄▆█▆▂▄▇
wandb:      train/ensemble_f1 ▆█▄▄▅▃▄▄▅▅▇▅▄▆▅▇▂▅▅▆▇▄▅█▆▄▄▄▅██▄▄▇▇▁▅▆▅▁
wandb:         train/mil_loss ▃▅▄▃▄▄▃█▇▇▇▅▃▂▃▃▆▃▃▅▁▅▂▆▄▃▅▆▅▃▃▃▆▅▅▂▅▄▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.73847
wandb: best/eval_avg_mil_loss 0.69853
wandb:  best/eval_ensemble_f1 0.73847
wandb:            eval/avg_f1 0.73847
wandb:      eval/avg_mil_loss 0.64544
wandb:       eval/ensemble_f1 0.73847
wandb:            test/avg_f1 0.74287
wandb:      test/avg_mil_loss 0.54094
wandb:       test/ensemble_f1 0.74287
wandb:           train/avg_f1 0.73035
wandb:      train/ensemble_f1 0.73035
wandb:         train/mil_loss 0.59026
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run soft-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1hez7d1s
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_004859-1hez7d1s/logs
wandb: Agent Starting Run: 246jjmt2 with config:
wandb: 	actor_learning_rate: 0.00013977985658646783
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.394334350434232
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3249794110170948
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_005026-246jjmt2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/246jjmt2
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▂▁▃▄▄▄▃▃▄▅▂▆▂▆▃▅▄▆▆▃▆▆▆▁▄▄▄▃▃▄▆▇▇▇█▇▃▃
wandb:      train/ensemble_f1 ▂▂▅▄▃▂▁▅▁▃▁▆▂▄▆▅▂▂▆▆▃▆▄▃▂▃▅▆▄▂▇▇▇▄▂▇█▂▆▄
wandb:         train/mil_loss █▂▃█▃▄▇▄▂▄▄▄▅▃▄▄▂▆▃▅▅▃▁▅▄▆▂▅▁▅▅▅▄▃▃█▂▂▁▇
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.83916
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.67318
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 1.41169
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.38689
wandb:      train/ensemble_f1 0.38689
wandb:         train/mil_loss 1.73071
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run young-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/246jjmt2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_005026-246jjmt2/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: e4eeyrky with config:
wandb: 	actor_learning_rate: 5.963387547557226e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4851920339641595
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.35733182955399545
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_005212-e4eeyrky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e4eeyrky
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▁▃▄▃▂▂▃▃▄▃▅▄▄▂▇▄▃▃▆█▃▅▄▅▇▆▅▆▄▅▅▂▅▅▄▆▆▃▄
wandb:      train/ensemble_f1 ▃▆▄▃▅▄▅▅▄▇▅▄▆▆▄▅▄▄▆▃▅▃▁▆▆█▆▇▅▅▆▅▇▇▄▄▇▄▅▅
wandb:         train/mil_loss ▇▄▇▆▄█▆▃▆▃▇█▃▄▅▆▅▄▄▇▆▇▆▅▅▇▁▄▃▇▆▆▆▅▄▃▂▅▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58767
wandb: best/eval_avg_mil_loss 0.57921
wandb:  best/eval_ensemble_f1 0.58767
wandb:            eval/avg_f1 0.58767
wandb:      eval/avg_mil_loss 0.56604
wandb:       eval/ensemble_f1 0.58767
wandb:            test/avg_f1 0.54607
wandb:      test/avg_mil_loss 0.61415
wandb:       test/ensemble_f1 0.54607
wandb:           train/avg_f1 0.56633
wandb:      train/ensemble_f1 0.56633
wandb:         train/mil_loss 0.68927
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run colorful-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/e4eeyrky
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_005212-e4eeyrky/logs
wandb: Agent Starting Run: 9lhwtspm with config:
wandb: 	actor_learning_rate: 0.003740702627002181
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7028437777061766
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9618556263160316
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_005338-9lhwtspm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9lhwtspm
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▅▆▄▃▂▆▃▅▄▄▄▅▄▄▄▇▅▄▂▅▃▅▃▃▂▂▅▃▃█▆▂▅▁▄▃▃▆
wandb:      train/ensemble_f1 ▄▄▅▅▄▃▅▇▃▂▁▄▃▄▄▄▃▅▄▇▄▅▄▁▅▅▁▅▂▅▃▅▂█▆▄▁▄▂▆
wandb:         train/mil_loss ▄▃▂▄▄▅▇▅▄▄▃▂▃▄▄▃▄█▆▃▅▄▅▄▆▃▄▄▆▁▅▄▃▅▅▃▅▆▆▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.73179
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.63247
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 1.28138
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.42755
wandb:      train/ensemble_f1 0.42755
wandb:         train/mil_loss 0.98581
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rural-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9lhwtspm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_005338-9lhwtspm/logs
wandb: Agent Starting Run: 1vy5x8sr with config:
wandb: 	actor_learning_rate: 2.4425832329291827e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4600706355358099
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.26122545986630297
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_005507-1vy5x8sr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1vy5x8sr
wandb: uploading history steps 113-126, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▅██████████████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁██████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▃▃▅▁▄▄▆▄▅▅▅▄▆▆▅▃▄▆▅▅▇▅▄▅▅▅▄▃▅▅▇▅█▇▇▆▆▃
wandb:      train/ensemble_f1 ▄▄▃▃▁▄▃▂▆▄▅▆▂▃▅▄▁▄▄▄▄▅▅▆▆▄▇▆▅▃▂▇▄▆▆▃▃▆█▃
wandb:         train/mil_loss ▅▅▄▅▃▄▇▄▆▅▅▃▆▃▅▂▄▆▅▄▅▄▃█▄▄▄▃▃▅▅▅▅▂▃▅▅▁▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████▁██████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.58478
wandb: best/eval_avg_mil_loss 1.15711
wandb:  best/eval_ensemble_f1 0.58478
wandb:            eval/avg_f1 0.58478
wandb:      eval/avg_mil_loss 1.02225
wandb:       eval/ensemble_f1 0.58478
wandb:            test/avg_f1 0.5842
wandb:      test/avg_mil_loss 0.86529
wandb:       test/ensemble_f1 0.5842
wandb:           train/avg_f1 0.5839
wandb:      train/ensemble_f1 0.5839
wandb:         train/mil_loss 0.97967
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run celestial-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1vy5x8sr
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_005507-1vy5x8sr/logs
wandb: Agent Starting Run: 9dirri7r with config:
wandb: 	actor_learning_rate: 4.25957328845717e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3904389629470063
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.23927352452551895
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_005655-9dirri7r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9dirri7r
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▃▃▄▄▅▆▆▆▇▇▇██
wandb: best/eval_avg_mil_loss █▇▇▆▅▄▄▄▄▄▃▃▃▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▃▃▄▄▅▆▆▆▇▇▇██
wandb:            eval/avg_f1 ▁▂▂▂▂▂▃▃▃▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████████████
wandb:      eval/avg_mil_loss █▇▇▇▇▇▆▆▆▆▅▅▄▄▄▄▄▄▃▃▂▂▂▂▂▁▁▁▂▂▂▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▂▂▂▂▂▂▂▂▂▃▃▃▃▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▂▂▄▄▃▃▄▅▅▅▄▄▄▄▄▄▄▅▆▇▆▆▇▆▇▇▆▇▇▇▇▇█▇█▇█
wandb:      train/ensemble_f1 ▁▂▂▂▂▃▂▃▄▄▄▄▃▃▅▅▅▅▅▅▆▇▆▇▆▇▆▇▆▆▇█▆██▇▇█▇█
wandb:         train/mil_loss █▇█▅▇▆▆▅▄▆▄▄▄▆▅▅▅▄▅▂▄▄▃▄▅▄▂▅▄▄▄▃▃▅▄▄▃▂▁▃
wandb:      train/policy_loss ████████████████████████████▁███████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████▁█████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.82792
wandb: best/eval_avg_mil_loss 0.40909
wandb:  best/eval_ensemble_f1 0.82792
wandb:            eval/avg_f1 0.81737
wandb:      eval/avg_mil_loss 0.39963
wandb:       eval/ensemble_f1 0.81737
wandb:            test/avg_f1 0.83821
wandb:      test/avg_mil_loss 0.37753
wandb:       test/ensemble_f1 0.83821
wandb:           train/avg_f1 0.79585
wandb:      train/ensemble_f1 0.79585
wandb:         train/mil_loss 0.55544
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run chocolate-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9dirri7r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_005655-9dirri7r/logs
wandb: Agent Starting Run: q5fpdync with config:
wandb: 	actor_learning_rate: 0.0012281008699991775
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4497623041859038
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8676400463062888
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_010643-q5fpdync
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q5fpdync
wandb: uploading history steps 225-238, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▆▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████████
wandb:      eval/avg_mil_loss ████▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▃▅▃▂▃▄▅▄▂▆▃█▆▅▆▄▁▄▄▅▁▃▆▅▆▄▅▄▅▅▃▆▃▇▇▃▃▆
wandb:      train/ensemble_f1 ▂▄▄▇▇▅▄▃▅▃▃▄▂▆▆▅▄▃▁▃▄▄▆▄▂▅▆▃▄▅▅▄▁█▃▇▄▆▁▄
wandb:         train/mil_loss ▇▇▆▆▅▃▅█▆▃▇▃▇▃▆▃▅▁▄▆▃▅▄▃▄▄▄▆▄▂▅▅▃▃▃▄▆▂▄▃
wandb:      train/policy_loss ████████████████████▁███████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █████▁██████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49286
wandb: best/eval_avg_mil_loss 0.67261
wandb:  best/eval_ensemble_f1 0.49286
wandb:            eval/avg_f1 0.49286
wandb:      eval/avg_mil_loss 0.65585
wandb:       eval/ensemble_f1 0.49286
wandb:            test/avg_f1 0.47917
wandb:      test/avg_mil_loss 0.60112
wandb:       test/ensemble_f1 0.47917
wandb:           train/avg_f1 0.4946
wandb:      train/ensemble_f1 0.4946
wandb:         train/mil_loss 0.68892
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run easy-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/q5fpdync
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_010643-q5fpdync/logs
wandb: Agent Starting Run: lxzm7g54 with config:
wandb: 	actor_learning_rate: 0.0018035277221693008
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.21636840780198777
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8907739760668335
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_011000-lxzm7g54
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lxzm7g54
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆▇█
wandb: best/eval_avg_mil_loss █▂▁▁▁
wandb:  best/eval_ensemble_f1 ▁▄▆▇█
wandb:            eval/avg_f1 ▂▂▂▁▅█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:      eval/avg_mil_loss █████▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▄▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▃▁▁▁▄▄▇▆▄▄▆▄▇▆█▇▆▅▅▆█▆▇▆▅▆█▄▆▇█▆▄▇█▅▅▆
wandb:      train/ensemble_f1 ▄▁▄▄▃▆▅▅▇▅▆▆▇▇█▇▆▆▇▅█▇▆▆▇▇▆▇▅▇▅▆▇█▇▆▅▆▅▆
wandb:         train/mil_loss ▇▆█▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▁▂▂▁▁▂▂▁▂▁▂▂▂▁▂▁▂▂▁▂▂
wandb:      train/policy_loss ▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65157
wandb: best/eval_avg_mil_loss 0.61178
wandb:  best/eval_ensemble_f1 0.65157
wandb:            eval/avg_f1 0.65157
wandb:      eval/avg_mil_loss 0.55959
wandb:       eval/ensemble_f1 0.65157
wandb:            test/avg_f1 0.49451
wandb:      test/avg_mil_loss 0.68075
wandb:       test/ensemble_f1 0.49451
wandb:           train/avg_f1 0.60105
wandb:      train/ensemble_f1 0.60105
wandb:         train/mil_loss 0.70582
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run lyric-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lxzm7g54
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_011000-lxzm7g54/logs
wandb: Agent Starting Run: 24eq5hxe with config:
wandb: 	actor_learning_rate: 0.0025828661386640343
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4062840139513903
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4357875826987391
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_011138-24eq5hxe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/24eq5hxe
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁███████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▆▃▅▄▃▃▅▃▃▅▃▆█▂▃▂▃▅▆█▅▄▃▃▆▄▃▁▄▅▄▁▅▂▇▃▃▆▃
wandb:      train/ensemble_f1 ▇▆▅▆▆▅█▆▅▄▄▆▄▄▆▄▆▆▅█▃▅▅▅▇▆▄▆▁▄▃▃▃▇▁▇▄▄▄▅
wandb:         train/mil_loss ▅▄▄▄▃▆▇▄▇▆█▄▄▄▇▆█▅▄▆▆▄▄▄▄▄▆▅▅▆▆▃▃▅▅▄▅▁▆▄
wandb:      train/policy_loss ▄▅▂▅▄▄▂▁▅▂▂▂▃▂▅▄▅█▆▅▄▅▅▃▅▅▂▄▇▄▅▃▄▆▅▅▂▄▂▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▅▃▃▂▁▂▂▂▄▂▄▄▂▂▃▃▃▄▃▃▅▃▄▆▃▆▄▂▃▅▇█▄▂▂▃▆▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.83257
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.8684
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.9364
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3311
wandb:      train/ensemble_f1 0.3311
wandb:         train/mil_loss 0.68967
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smart-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/24eq5hxe
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_011138-24eq5hxe/logs
wandb: Agent Starting Run: 2zelwigc with config:
wandb: 	actor_learning_rate: 0.0007687993105704721
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9531205758432748
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.028886418580440942
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_011306-2zelwigc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2zelwigc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss ▁▂▂▂▂▃▃▃▄▄▅▄▄▃▄▃▄▄▅▅▆▆▆▆▆▅▅▅▅▄▅▅▅▅▆▆▇███
wandb:       eval/ensemble_f1 ██████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▆▆▆▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▄▃▃▃▇▅▄▅▇█▄▆▆▄▇▆▅▃▅▆▄▅█▄▂▃▆▄█▁▄▂▅▅▅▃▁▆
wandb:      train/ensemble_f1 ▅▆▅▄▆▄▃▄▄▅▄▅▃▄▄▇█▅▅▇▅▅▅▇▄▆▇▄▁▇▇▅▆▄▅▅▅▄▅▂
wandb:         train/mil_loss ▁▅▄▃▂▄▃▅▄▅▃█▃▆▄▃▃▃▆▂▂▄▅▂▂▃▄▃▂▃▄▃▁▃▂▄▆▅▃▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.63108
wandb: best/eval_avg_mil_loss 0.75311
wandb:  best/eval_ensemble_f1 0.63108
wandb:            eval/avg_f1 0.62637
wandb:      eval/avg_mil_loss 0.76144
wandb:       eval/ensemble_f1 0.62637
wandb:            test/avg_f1 0.6021
wandb:      test/avg_mil_loss 0.53899
wandb:       test/ensemble_f1 0.6021
wandb:           train/avg_f1 0.58548
wandb:      train/ensemble_f1 0.58548
wandb:         train/mil_loss 0.56955
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dazzling-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2zelwigc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_011306-2zelwigc/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: f2nffet0 with config:
wandb: 	actor_learning_rate: 3.7755150490526975e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2216865510180465
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3314515217871572
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_011535-f2nffet0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f2nffet0
wandb: uploading history steps 207-225, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅█
wandb: best/eval_avg_mil_loss █▆▅▁
wandb:  best/eval_ensemble_f1 ▁▃▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▅▅▅▅▅▅▅▅▅████████████████
wandb:      eval/avg_mil_loss ▇▇████▇▇▇▇▆▆▅▄▄▃▃▃▃▃▂▂▂▃▃▂▂▂▃▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅██████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▃▁▄▄▄▃▄▁▃▄▂▂▃▄▃▄▅▃▆▃▄▄▄▃▄▅▃▃▄▅▄▆▄▄▅▅▅█
wandb:      train/ensemble_f1 ▃▂▂▄▅▂▁▃▅▅▄▅▆▂▃▆▄▅▆▄▂▄▆▄▅▆▆▇▄▆▆▅▇█▄▃▆▄█▄
wandb:         train/mil_loss ▃█▆▄▆▅▅▅▆▇▃▅▁▅▄▃▂▆▅█▄▅▆▂▄▁▁▁▂▂▅▅▄▅▇▂▄▁▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65478
wandb: best/eval_avg_mil_loss 0.54287
wandb:  best/eval_ensemble_f1 0.65478
wandb:            eval/avg_f1 0.65478
wandb:      eval/avg_mil_loss 0.53893
wandb:       eval/ensemble_f1 0.65478
wandb:            test/avg_f1 0.57835
wandb:      test/avg_mil_loss 0.60316
wandb:       test/ensemble_f1 0.57835
wandb:           train/avg_f1 0.60981
wandb:      train/ensemble_f1 0.60981
wandb:         train/mil_loss 0.67885
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clean-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/f2nffet0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_011535-f2nffet0/logs
wandb: Agent Starting Run: 1l3m4ktq with config:
wandb: 	actor_learning_rate: 7.140584770642415e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8622725772230563
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5604132981110004
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_011841-1l3m4ktq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1l3m4ktq
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇████▇▇▇▇▇▆▅▅▄▄▄▅▄▄▄▄▃▃▂▂▁▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▃▂▄▂▂▅█▃▂▂▅▄▅▃▅▁▃▂▄▃▃▃▄▃▆▅▆▄▃▁▅▂▅▃▃▄▃
wandb:      train/ensemble_f1 ▄█▄▆▇▄▄▄▄█▄▆▇▅▃▄▅▆▆▅▁▆█▇▅▇▄▅▄▇█▅▆▄▅▇▆▅▅▆
wandb:         train/mil_loss ▃▆▃▂▄▅▄▅█▇▃▃▃▃▂▆▁█▃▆▃▃▃█▇▂▃▄▄▃▄▄▄▄▂▃▄▃▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.62637
wandb: best/eval_avg_mil_loss 0.83192
wandb:  best/eval_ensemble_f1 0.62637
wandb:            eval/avg_f1 0.61786
wandb:      eval/avg_mil_loss 0.79007
wandb:       eval/ensemble_f1 0.61786
wandb:            test/avg_f1 0.6021
wandb:      test/avg_mil_loss 0.59583
wandb:       test/ensemble_f1 0.6021
wandb:           train/avg_f1 0.6133
wandb:      train/ensemble_f1 0.6133
wandb:         train/mil_loss 0.68399
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pretty-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1l3m4ktq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_011841-1l3m4ktq/logs
wandb: Agent Starting Run: zqii7lsl with config:
wandb: 	actor_learning_rate: 0.0021438119512716207
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.784088938248009
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07171950778601677
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_012008-zqii7lsl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zqii7lsl
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▄▅▅▃▃▄▅▅▃▅▆▁▆▅▃▃▄▆▄▃▅▅▄▃▅▃▃▄▃▂▅▆▇▃█▇▃▆
wandb:      train/ensemble_f1 ▇▇▅▇▆▆▅▅▄▆▆▇▃▇█▆▇██▄▅▃▁▆▇▅▆▇▆▅▄▄▃▄█▄▂▄▇█
wandb:         train/mil_loss ▃▂▄▆▄▄▄▃▅▄▆▄▃▅▅▄▄▇▃▅▃▄▅▁▄▄▄▄▄▇█▄▆▄▅▄▆▅▅▃
wandb:      train/policy_loss ▆▆█▆▄▃▄▆▅▆▅▆▁▇▅▆▃▆▇▇▃▆▆▆▆▅▆█▆▆▅▃▅▄▆▆▆▅█▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▄▇▅▂▃▄▃▅▅▆▅▄▄▄▂▅▆▄▆▅▂▄█▅▄▅▄▅▁▅▅▅▆▄▄▅▄▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 7.65931
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 7.49993
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 9.49982
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34426
wandb:      train/ensemble_f1 0.34426
wandb:         train/mil_loss 1.44038
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run gallant-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zqii7lsl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_012008-zqii7lsl/logs
wandb: Agent Starting Run: wgd99cad with config:
wandb: 	actor_learning_rate: 1.2586127060396753e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.182564394026831
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3526538661307753
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_012136-wgd99cad
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wgd99cad
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▄▆▅▄▄▅▄▆▇▄▆▅▃▅▆▄▃▆▅▁▇▆▂▇▄▄▆▅▇█▆▆▆▄▆▅▅▂
wandb:      train/ensemble_f1 ▅▅▂▆▄▂▃▅▄▆▅▃▆▇▃▇▄▄▄▃▄▅▃▅▄▂▅▁█▄▅▃▆▂█▆▄▆▄▇
wandb:         train/mil_loss ▃▃▄▅▆▆▅▆▂▃▃▁█▄▅▆▃▅▄▇▄▄▅▅▂▇▄▂▄▆▅▁▃▄▄▃▅▂▁▃
wandb:      train/policy_loss ▄▄█▄▃▄▅▄▇▅▅▆▃▃▇▅▃▅▆▄▂▅▄▃▆▃▄▂▂█▄▁▅▅▆▃▆▂▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▄▃█▄▄▇▅▄▆▃▂▅▃▅▃▆▆▃▂▄▁▅▂▃▂█▁▄▁▅▅▆▃▂▂▅▂▄▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.83639
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.82016
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.93821
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3133
wandb:      train/ensemble_f1 0.3133
wandb:         train/mil_loss 0.7614
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run divine-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wgd99cad
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_012136-wgd99cad/logs
wandb: Agent Starting Run: yve01qnn with config:
wandb: 	actor_learning_rate: 0.009088582198230269
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4977936110224793
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6896793685471072
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_012304-yve01qnn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yve01qnn
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▅▄▄▆▆▅▃▁▅▄▇▅▃▅▄▆▄▃▅▄█▃▃▄▃▄▅▄▆▆▇▄▅▆▄▂▄▄
wandb:      train/ensemble_f1 ▆▃▆▅▃▄▃▆▅▁▃▆▅▄▄▄▄▄▃▄▁▅█▅▃▇▆▄▄▅▃▄▂▆▄▅▄▅▅█
wandb:         train/mil_loss ▁▇▆▅▅▅▃▃▅▅▄▃▅▆▄▃▆▅▇▄▂▅▄▆▄█▇▅▆▁▂▂▂▃▃▄▅▆▂▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.42183
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.32972
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 1.00496
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.39681
wandb:      train/ensemble_f1 0.39681
wandb:         train/mil_loss 1.02302
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glad-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yve01qnn
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_012304-yve01qnn/logs
wandb: Agent Starting Run: m9zjakne with config:
wandb: 	actor_learning_rate: 3.485947446382807e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4317350879854478
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1813705885724307
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_012432-m9zjakne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m9zjakne
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▅█
wandb: best/eval_avg_mil_loss █▄▃▁
wandb:  best/eval_ensemble_f1 ▁▁▅█
wandb:            eval/avg_f1 ▃▃▃▁▁▁▁▁▁▃▃▆▆▆▆███████████████▆▆▆▆▆▆▆▆▆▆
wandb:      eval/avg_mil_loss █████▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▁▁▁▁▂▂▂▁
wandb:       eval/ensemble_f1 ▃▃▁▁▁▁▁▁▃▃▃▆▆▆▆▆▆▆████████████▆▆▆▆▆▆▆▆▆▆
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▁▅▄▃▆▅▆▅▄▅▆▄▄▆▄▅▅▇▄▅▄▄▂▅▆▇▆█▅▆▅▄▇▇▇█▆▇▅
wandb:      train/ensemble_f1 ▅█▄▃▂▃▁▅▆▂▃▂▃▄▆▇▅▄▆▅▇▅▇▅▄▄▆▇▅▅▇▅▇▇▆▆▆█▅▅
wandb:         train/mil_loss ██▃▇▃▇▁█▃▅▅▅▃▅▄▆▆▄▅▆▇▅▆▄▆▃▂▅▄▁▄▃▂▄▃▃▃▄▄▃
wandb:      train/policy_loss ▄▄▄▄▄▄▂▁▂▆▄▄▄▄▅▆▇▆▅▅▅▆▅█▆▅▅▅▆▂▃▁▂▁▅▁▁▃▃▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▃▅▂▂▅▄▄▄▄▄▄▇▇▆█▆█▄▆▆▅▆▅▆▃▃▁▄▅▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79708
wandb: best/eval_avg_mil_loss 0.43266
wandb:  best/eval_ensemble_f1 0.79708
wandb:            eval/avg_f1 0.78743
wandb:      eval/avg_mil_loss 0.4103
wandb:       eval/ensemble_f1 0.78743
wandb:            test/avg_f1 0.82418
wandb:      test/avg_mil_loss 0.40909
wandb:       test/ensemble_f1 0.82418
wandb:           train/avg_f1 0.78005
wandb:      train/ensemble_f1 0.78005
wandb:         train/mil_loss 0.57754
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sweet-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m9zjakne
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_012432-m9zjakne/logs
wandb: Agent Starting Run: k57eiji3 with config:
wandb: 	actor_learning_rate: 0.0007496993602971159
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.03934091268114448
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.47081079690104766
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_012656-k57eiji3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/v228i2ap
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k57eiji3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████████████
wandb:      eval/avg_mil_loss █████▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁██████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▃█▅▅▃▃▂▅▇▄▅▅▃▄▄▄▅▄▆▃▃▄▅▄▅▆▅▅▃▄▅▅▅▆▃▆▁▄▆
wandb:      train/ensemble_f1 █▆▆▄▂▁▂▇██▄▆▅▂▅▇▅▄▅█▇▃▄▅▄▅▅▆▆▂▅▄▅▆▅█▇▁▄▄
wandb:         train/mil_loss ▆▇▆▇█▅▄▅▇▂▅▆▅▆▄▅▃▁▃▂▄▅▅▂▅▅▂▄▄▂▂▅▅▅▁▂▂▁▂▃
wandb:      train/policy_loss ▇▇▇▇██▇▇█▇█▇██▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇█▇▇▇█▆▇▇▇▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49286
wandb: best/eval_avg_mil_loss 0.70149
wandb:  best/eval_ensemble_f1 0.49286
wandb:            eval/avg_f1 0.49286
wandb:      eval/avg_mil_loss 0.66162
wandb:       eval/ensemble_f1 0.49286
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.59667
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.49699
wandb:      train/ensemble_f1 0.49699
wandb:         train/mil_loss 0.73968
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cool-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k57eiji3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_012656-k57eiji3/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: qk5bvele with config:
wandb: 	actor_learning_rate: 0.0017549142816781385
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9592262710156616
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8322889646086883
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_012918-qk5bvele
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qk5bvele
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▆▆▄▄▅▅▅▅▅▅▅▃▃▂▂▂▃▂▁▁▂▂▂▂▂▂▂▂▂▃▂▃
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▄▁▅▁▅▆▅▅▃█▅▇▇▇█▆▅█▅█▅▄▅▆▄▆▅▇▄▃▅▆▄▃▆▇▅▃
wandb:      train/ensemble_f1 ▁▆▆▇▄▁▅▅▃▆▇▅▅▇▅▇█▆▅▃█▄▂▄▆▆▂▄▄▆▂▂▄▅▄▅▂▄▄▄
wandb:         train/mil_loss ▄▅▃▄▅█▅▆▁▅█▄▅█▇▇▅▄▄▂▄▁▅▅▄▅▄▄▅▇▄▃▂▅▅▅▇▁▇▂
wandb:      train/policy_loss █▆▃▁▆▆▃▆▃▆█▃▆▆▃▁▆█▆█▃██▃▆▁▆▃▆██▃██████▃▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▆▄▃▄▅█▄▃█▆▄▃█▃▆▆▆▆▆█▃▆▄▄█▁▄████▄█▅▄▆██
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61279
wandb: best/eval_avg_mil_loss 0.92583
wandb:  best/eval_ensemble_f1 0.61279
wandb:            eval/avg_f1 0.61279
wandb:      eval/avg_mil_loss 0.91873
wandb:       eval/ensemble_f1 0.61279
wandb:            test/avg_f1 0.6021
wandb:      test/avg_mil_loss 0.76318
wandb:       test/ensemble_f1 0.6021
wandb:           train/avg_f1 0.5822
wandb:      train/ensemble_f1 0.5822
wandb:         train/mil_loss 0.52995
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run celestial-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qk5bvele
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_012918-qk5bvele/logs
wandb: Agent Starting Run: rmgq87e0 with config:
wandb: 	actor_learning_rate: 5.6546679659588094e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.21245488545459812
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2644025575441816
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_013046-rmgq87e0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rmgq87e0
wandb: uploading history steps 312-330, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▃▃▄▅▅▆▆▇██
wandb: best/eval_avg_mil_loss █▇▇▄▄▄▄▄▃▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▂▃▃▃▄▅▅▆▆▇██
wandb:            eval/avg_f1 ▁▂▁▁▂▃▃▃▂▂▅▆▆▆▆▆▆▇▆▆▇▇▇▆▇██████████████▇
wandb:      eval/avg_mil_loss ███▇▆▆▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▂▁▁▂▂▂▂▂▂▃▅▆▆▆▆▆▆▇▆▆▇▇▇▇▆▆▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▂▂▄▂▃▄▄▇▃▃▆▅▄▅▆▇▆▇▆▆▅▆▇▆▇██▇▇▇▇██▇██▇
wandb:      train/ensemble_f1 ▁▃▂▃▃▂▂▃▃▃▄▅▄▅▄▄▆▆▅█▆▅▆▆▇▆▇▆▇▇▇▇▇█▇▇▇▆▆▇
wandb:         train/mil_loss █▄▇▆▄▄▅▃▆▅▅▅▄▃▄▄▃▄▃▃▂▂▃▂▃▁▁▂▁▂▂▁▂▂▂▁▁▂▁▁
wandb:      train/policy_loss ██▁█████████████▅██▆████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▁████████████▅██▆██████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79708
wandb: best/eval_avg_mil_loss 0.37734
wandb:  best/eval_ensemble_f1 0.79708
wandb:            eval/avg_f1 0.78639
wandb:      eval/avg_mil_loss 0.36894
wandb:       eval/ensemble_f1 0.78639
wandb:            test/avg_f1 0.6938
wandb:      test/avg_mil_loss 0.53293
wandb:       test/ensemble_f1 0.6938
wandb:           train/avg_f1 0.73139
wandb:      train/ensemble_f1 0.73139
wandb:         train/mil_loss 0.595
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run resilient-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rmgq87e0
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_013046-rmgq87e0/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ahqr1vlz with config:
wandb: 	actor_learning_rate: 0.00035397922368029795
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.44593616133803626
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5428021507696205
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_013530-ahqr1vlz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ahqr1vlz
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▅▃▇▆▃▆▅▇▆▅▅▆▆▅▄▂▄▆▁▆▅▄▃▅▃▄▄█▆▄▄▆▆▆▃▂▅▄
wandb:      train/ensemble_f1 ▄▅▅▇▆▆▇▃▄▇▅▆▆▆█▄▄▄▂▇▇▁▆▆▃▃▅█▅▃▇▄▆▆▆▄▆▆▃▂
wandb:         train/mil_loss ▂▅▅▆▆▅▇▄█▅▅▄▇▅▅▄▄▅▆▅▂▄▃▄▄▃▆█▆▃▃▅▅▅▄▄▅▁▄▄
wandb:      train/policy_loss ▇▃▃▄▂▂▄▄▃▁▄▆▇▃▄▂▃▂▄▃▆▄▃▄▇▄▁█▃▄▅▇▄▄▂▇▂▄▄▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▄▁▅▃▂▆▅▅▃▄▃▅▃▄▃▄▅▆▃▄▃▃▄▃▃▄▃▇▅▅▅▅▃█▃▂▅▅▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.94393
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.92556
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.06237
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32603
wandb:      train/ensemble_f1 0.32603
wandb:         train/mil_loss 0.74741
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crisp-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ahqr1vlz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_013530-ahqr1vlz/logs
wandb: Agent Starting Run: vbco8qrc with config:
wandb: 	actor_learning_rate: 0.00019162064735213477
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.12843329564270944
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.37571059314919686
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_013657-vbco8qrc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vbco8qrc
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▃▃▃▂▂▂▂▂▃██▇▆▆▅▄▆▆▆▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄
wandb:       eval/ensemble_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▁▄█▅▇▂▇▁▃▁▄▃▆▄▆▅▅▃▂▃▄▃▄█▆▄▃▄▂▃▄▄▃▂▁██▃
wandb:      train/ensemble_f1 ▂▆▄▃▂▃▃▅▇▆▅▁▃▄▄▁█▆▅▅▄▄▇▆▆▄▃▂▄▄▂▂▄▆▄▃▁▄▂▄
wandb:         train/mil_loss ▇▁▂▄▄▅▁▃██▆▄▆▆▃▆▂▃▇▆▅▇▅▃▅▅▇▃▇▅▃▃▇▄▁▂▄▅▆▅
wandb:      train/policy_loss ██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.69914
wandb: best/eval_avg_mil_loss 0.50438
wandb:  best/eval_ensemble_f1 0.69914
wandb:            eval/avg_f1 0.6875
wandb:      eval/avg_mil_loss 0.50909
wandb:       eval/ensemble_f1 0.6875
wandb:            test/avg_f1 0.64349
wandb:      test/avg_mil_loss 0.54201
wandb:       test/ensemble_f1 0.64349
wandb:           train/avg_f1 0.66001
wandb:      train/ensemble_f1 0.66001
wandb:         train/mil_loss 0.66165
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clear-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vbco8qrc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_013657-vbco8qrc/logs
wandb: Agent Starting Run: k67dgbt7 with config:
wandb: 	actor_learning_rate: 5.849108916484255e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.10641393898426588
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.18896209335553693
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_013825-k67dgbt7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k67dgbt7
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██████▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▃▄▅▅▆▃▃▅▇▃▄▄▅▄▆▄▅▄▄█▇▄▅▅▅▅▃█▄▆▄▃▁▁▅▇▅▄
wandb:      train/ensemble_f1 ▅▆▄▄▇▃▃▅█▆▆█▄▆▄▇▄▅▅▄▆▇▄▅▆▇▆▆█▅▅▆▆█▄▁▆▃▅▅
wandb:         train/mil_loss ▃▅▅▆▃▃▄▅▅▅▄▅▆▅▇▄▃▄▆█▅█▆▄▆▅▇▆▃▃██▃▅▂▃▅▄▁▅
wandb:      train/policy_loss ▅▅█▃▃▃▅▅▅▃▄▆▃▄▁▂▄▂▄▄▄▆▃▃▁▄▄▄▅▄▅▄▁▂▄▃▄▂▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▄▇▄▄▂▇▇▇▅▂▄▅▄▄█▇█▁▅▇▇▂▇▄▄▄▂▇▅▂▄▅▅▁▁▂▂▇▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.98177
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.95973
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.09153
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3383
wandb:      train/ensemble_f1 0.3383
wandb:         train/mil_loss 0.90574
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dark-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/k67dgbt7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_013825-k67dgbt7/logs
wandb: Agent Starting Run: 26db9kr7 with config:
wandb: 	actor_learning_rate: 0.00013560349220351458
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9326451727809574
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4184846342514027
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_013953-26db9kr7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/26db9kr7
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅██▄▇▇▃▇▅▅▄▃▃▇▅▇▆▄▅▆▁▅▇▄▆▄▅▅▃▆▄▄▆▅▃▃▆▇▃
wandb:      train/ensemble_f1 ▄█▅▅▄▅▃▇▇▅▅▃▃▃▅▅▅▇▆▅▆▄▁▂▆▃▄▅▃▂▅▆▄▆▃▅▁▃▄▃
wandb:         train/mil_loss ▁▂▆▂▃▅▃▃▄▆▂▂▄▆▃▃▃▃▂▄▁▅▃▃▂▃▄▅▂█▃▄▄▂▂▁▅▂▂▄
wandb:      train/policy_loss ▄▄▇▅▁▇▇▅▅▇▇▂█▇▄▂▇██▇█▅▂▇█▄▇▂▅▂▇▅▇▇▄▇█▇▂▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▇▄▅▄▇▅▇▇▇▇▂▇█▂█▇▇▁▄▇█▅█▄▂█▄▅▅▇▅▇▇▇▇▄▇▇▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.85587
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.85131
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.97915
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32773
wandb:      train/ensemble_f1 0.32773
wandb:         train/mil_loss 0.57251
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rose-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/26db9kr7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_013953-26db9kr7/logs
wandb: Agent Starting Run: l5a5gvvj with config:
wandb: 	actor_learning_rate: 0.00532261379495662
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4353222245266215
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8794315698484174
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_014123-l5a5gvvj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l5a5gvvj
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 █▄▄▂▆▃▆▃▃▃▆▄▅▆▃▃▅▁▁▄▂▅▅▅▇▃▆▅▆▂▆▄▃▁▇▃▇▄▆▃
wandb:      train/ensemble_f1 █▄▄▂▅▃▄▇▃▅▅▆▅▆▁▅▂▄▄▁▂▄▅▅▇▅▆▂▆▆▄▂▇▅▄▆▃▇▇▄
wandb:         train/mil_loss ▃▆▆▅▆▆▄▆▃▂▄▃▅▅▆▄▂▃▅▄▄▄█▃▁▅▅▃▄▃▄▃▆▄▂▄▁▄▄▄
wandb:      train/policy_loss ▅▃▆▄▂▃▃▅▃▄▆▄▄▃▃▃▆▆▅▅▄▅█▃▆▅▂▅▃▄▆▂▅▁▅▅▅▄▄▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▅▃▄▆▅▅▅▅▇▇▄▅▄▅▅▇▇▆▅▂▁▆▄▇▇▅▃▄█▇▃▆▅▄▅▇▅▇▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.81796
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.80505
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.91468
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32998
wandb:      train/ensemble_f1 0.32998
wandb:         train/mil_loss 0.67778
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run smooth-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l5a5gvvj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_014123-l5a5gvvj/logs
wandb: Agent Starting Run: w33zq4fu with config:
wandb: 	actor_learning_rate: 1.7814310949216092e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4795601192523419
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8839274748518542
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_014251-w33zq4fu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w33zq4fu
wandb: uploading history steps 148-163, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▃▁▁▃▆▆▆▆▆▆▆▆████▆▆▆▆▆▆▆▆▆███████████████
wandb:      eval/avg_mil_loss ████▇▆▆▆▆▆▅▅▅▅▅▄▄▄▅▄▄▄▄▄▃▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▃▁▁▁▁▁▆▆▆▆▆▆▆▆▆▆▆███▆▆▆▆▆▆▆▆▆███████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▄▄▄▄▁▃▅▅▅▅▅▅▃▅▃▅▅▃▂▅▄▅▆▄▄▅▄▄▇▄▄▅▇▄▄▅▆█
wandb:      train/ensemble_f1 ▄█▇▅▄▄▁▅▄▄▅▅▄▇▃▅▆▅▆▅▄▆▆▅▄▆▅▄▄▄▅▃▅▇▇▆▅▃▅▅
wandb:         train/mil_loss ▄▆▃▄▇▂▄▇▅▂▄▅█▄▂▂▄▄▅▁▄▅▂▆▃▃▆▆▃▄▃▄▃▄▄▃▂▄▁▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61786
wandb: best/eval_avg_mil_loss 0.55957
wandb:  best/eval_ensemble_f1 0.61786
wandb:            eval/avg_f1 0.61786
wandb:      eval/avg_mil_loss 0.5508
wandb:       eval/ensemble_f1 0.61786
wandb:            test/avg_f1 0.57928
wandb:      test/avg_mil_loss 0.59031
wandb:       test/ensemble_f1 0.57928
wandb:           train/avg_f1 0.60087
wandb:      train/ensemble_f1 0.60087
wandb:         train/mil_loss 0.63835
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run amber-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w33zq4fu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_014251-w33zq4fu/logs
wandb: Agent Starting Run: ca7n1oo9 with config:
wandb: 	actor_learning_rate: 6.698755061830404e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3654578240761177
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2671287025384611
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_014509-ca7n1oo9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ca7n1oo9
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████████████████████████████████▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ███████████████████████████████████████▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▃▃▃▄▂▅▃▃▃▂▃▆▃▄▅▄▅█▄▅▅▆▃▆▅▆▃▆▄█▅▃▃▅▂▅▆▄
wandb:      train/ensemble_f1 ▁▅▄▂▃▄▅▄▂▃▄▄▃▂▂▃▃▅▂▄▆▃▃▃▆▇▃▆▅▆█▆▄▄▅▅▂▆▄▇
wandb:         train/mil_loss ▆▁▆▄█▇▅▆▅▆▆▃▅▅▃▁▃▄▄▆▅▁▅▆▇▅▅▄▃▆▆▇▄▂▃▆▅▃▆▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.60938
wandb: best/eval_avg_mil_loss 0.56239
wandb:  best/eval_ensemble_f1 0.60938
wandb:            eval/avg_f1 0.60091
wandb:      eval/avg_mil_loss 0.53942
wandb:       eval/ensemble_f1 0.60091
wandb:            test/avg_f1 0.61146
wandb:      test/avg_mil_loss 0.51838
wandb:       test/ensemble_f1 0.61146
wandb:           train/avg_f1 0.63035
wandb:      train/ensemble_f1 0.63035
wandb:         train/mil_loss 0.6553
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run northern-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ca7n1oo9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_014509-ca7n1oo9/logs
wandb: Agent Starting Run: iy3wo3j6 with config:
wandb: 	actor_learning_rate: 5.419359645293266e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5510164897668841
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9217322750993832
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_014638-iy3wo3j6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iy3wo3j6
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▁▄▃▅▄▄▆▅▆▃▂▃▅▅▆▃▄▂▄▇▆▄▆▆▄▆▄▆▇▆▄▅▆█▅█▇▇
wandb:      train/ensemble_f1 ▁▁▂▅▄▂▃▃▄▅▅▃▂▄▂▄▃▄▄▅▄▂▃▃▇▆▆▆▃▆▄▃▄█▆█▇▇▄▅
wandb:         train/mil_loss ▆▃▃▃▃▇▄▃▅▃▃▅█▄▃▄▆▄▅▂▁█▄▂▄▃▆▁▃▃▂▁▄▃▃▄▅▂▃▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77263
wandb: best/eval_avg_mil_loss 0.59101
wandb:  best/eval_ensemble_f1 0.77263
wandb:            eval/avg_f1 0.77263
wandb:      eval/avg_mil_loss 0.49801
wandb:       eval/ensemble_f1 0.77263
wandb:            test/avg_f1 0.77022
wandb:      test/avg_mil_loss 0.48271
wandb:       test/ensemble_f1 0.77022
wandb:           train/avg_f1 0.8013
wandb:      train/ensemble_f1 0.8013
wandb:         train/mil_loss 0.65717
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run absurd-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/iy3wo3j6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_014638-iy3wo3j6/logs
wandb: Agent Starting Run: bphyhm87 with config:
wandb: 	actor_learning_rate: 1.8998715120453197e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8163030953257265
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3932671794536387
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_014806-bphyhm87
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bphyhm87
wandb: uploading history steps 184-199, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▁▂
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▅▃▄▄▄▃▃▃▃▃▃▂▃▃▂▂▂▁▁▁▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▆▅▅▅▆▄▅▅▆▄█▆▅▄▅▆▅▄▅▆▄▅▆▇▁▄▆▆▅▆▆▅▄▄▅▄▆▆
wandb:      train/ensemble_f1 ▃▄▂▁▃▃▃▂▄▂▁▅▃▄▂▅▄▃▃▃▆▃▅▇▄█▅▁▆▅▅▃▄▆▁▄▅▄▅▅
wandb:         train/mil_loss ▇▃▂▅▂▅▁▅▄▁▇▆▃▇▄▃▂▃▇▆▃▅▁▄▂▃▆▇▂▄▄▆▂█▇▁▇█▄▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59893
wandb: best/eval_avg_mil_loss 0.97373
wandb:  best/eval_ensemble_f1 0.59893
wandb:            eval/avg_f1 0.59893
wandb:      eval/avg_mil_loss 0.96181
wandb:       eval/ensemble_f1 0.59893
wandb:            test/avg_f1 0.66875
wandb:      test/avg_mil_loss 0.63309
wandb:       test/ensemble_f1 0.66875
wandb:           train/avg_f1 0.60363
wandb:      train/ensemble_f1 0.60363
wandb:         train/mil_loss 0.65288
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glad-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bphyhm87
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_014806-bphyhm87/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: eol54ywd with config:
wandb: 	actor_learning_rate: 0.00011418684306537984
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7970796652977558
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.02359530186439396
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_015105-eol54ywd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eol54ywd
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▅▅▅▅▅▆██▇▇▃▂▂▃▃▄▄▄▄▄▅▅▁▁▁▁▁▁▁▁▁▁▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▄▇▂▂▄▆▃▅▂▅▃▄▃▇▂▅▆▇▃▅▁█▆▂▆▅▅▄▅▄▄▅▃▆▅▆▃▇
wandb:      train/ensemble_f1 ▅▄▄█▄▂▄▂▄▇▃▃▇▇▃▄▁▃▄▆▄▅▁▁▆▁▂█▂▆▂▄▅▄▃▅▂▄▅▆
wandb:         train/mil_loss ▄▅▅▄▂▁▆▄▃▁▆▂▄▄▄▄▂▆▃▃▂▄▄▇▄▄▃▃▂▄▃▆▃▅▃▁▆█▅▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.64405
wandb: best/eval_avg_mil_loss 0.49128
wandb:  best/eval_ensemble_f1 0.64405
wandb:            eval/avg_f1 0.64405
wandb:      eval/avg_mil_loss 0.48978
wandb:       eval/ensemble_f1 0.64405
wandb:            test/avg_f1 0.62599
wandb:      test/avg_mil_loss 0.59515
wandb:       test/ensemble_f1 0.62599
wandb:           train/avg_f1 0.63747
wandb:      train/ensemble_f1 0.63747
wandb:         train/mil_loss 0.62203
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run quiet-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eol54ywd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_015105-eol54ywd/logs
wandb: Agent Starting Run: 46itjg2h with config:
wandb: 	actor_learning_rate: 9.824284919633392e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4168026404643267
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7085628640357093
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_015233-46itjg2h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/46itjg2h
wandb: uploading history steps 553-570, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▁▂▂▃▃▄▄▅▅▆▆▇▇▇███
wandb: best/eval_avg_mil_loss ███▇▆▆▅▄▄▄▄▃▃▃▃▂▂▁
wandb:  best/eval_ensemble_f1 ▁▁▂▂▃▃▄▄▅▅▆▆▇▇▇███
wandb:            eval/avg_f1 ▁▂▂▂▂▂▂▂▂▂▃▃▃▄▄▅▅▅▅▆▇▇▇▇▇███████████████
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▅▆▆▆▆▇▇▇█████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▂▂▂▂▂▂▁▃▄▃▃▃▃▃▄▄▄▅▅▄▄▅▆▆▆▇▆▇▆▇▇▇█▇█▇▇
wandb:      train/ensemble_f1 ▁▁▃▃▃▃▃▃▄▄▄▅▇▆▄▅▇▇▆▇▆▇▇▇▇▇▇▇▇▆█▇▇██▇█▇██
wandb:         train/mil_loss ██▆▇▇▆▆▇▅▅▄▄▄▄▅▂▃▄▅▄▃▃▄▃▄▁▂▃▂▂▃▂▃▂▂▂▃▃▂▁
wandb:      train/policy_loss ███████████▁████▅███████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▂▅▅▅██▅▅▃▁▅▅▅▅▅▅▅▅▅▅▅▇▂▃▃▅▅▅▅▅▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80673
wandb: best/eval_avg_mil_loss 0.38555
wandb:  best/eval_ensemble_f1 0.80673
wandb:            eval/avg_f1 0.80673
wandb:      eval/avg_mil_loss 0.35451
wandb:       eval/ensemble_f1 0.80673
wandb:            test/avg_f1 0.82418
wandb:      test/avg_mil_loss 0.35211
wandb:       test/ensemble_f1 0.82418
wandb:           train/avg_f1 0.82684
wandb:      train/ensemble_f1 0.82684
wandb:         train/mil_loss 0.50738
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run atomic-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/46itjg2h
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_015233-46itjg2h/logs
wandb: Agent Starting Run: 9grw7cdo with config:
wandb: 	actor_learning_rate: 0.008883477002695228
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5198182327991097
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8656270085593977
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_020023-9grw7cdo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9grw7cdo
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▄▄▃▂▂▃▃▂▁▄▁▂▄▄▆▅▆█▄▃▆▅▃▃▄▄▄▆▇▄▃▃▃▃▅▅▄▄
wandb:      train/ensemble_f1 ▃▅▄▄▃▆▂▁▁▄▂▄▂▅▅▅▃▆▅▆▃██▄▅▄▅▄▄▃▄▆▆▄▄▅▄▅▅▅
wandb:         train/mil_loss ▂▅▂▂▆▅▂▆▂▄▁▄▂▇▆▁▃█▃▂▄▅▇▅▆▃▇▃▄▄▅▄▅▃▄▄▂▄▄▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.00471
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.94563
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 0.81255
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.37296
wandb:      train/ensemble_f1 0.37296
wandb:         train/mil_loss 0.87621
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run visionary-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9grw7cdo
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_020023-9grw7cdo/logs
wandb: Agent Starting Run: tzm3blhq with config:
wandb: 	actor_learning_rate: 5.037575866025208e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.719875544110226
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.37147537210940385
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_020150-tzm3blhq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tzm3blhq
wandb: uploading history steps 258-274, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆▇█
wandb: best/eval_avg_mil_loss █▇▅▄▂▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆▇█
wandb:            eval/avg_f1 ▁▃▃▃▃▃▃▃▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇███████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▃▃▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▃▂▃▂▃▂▁▂▃▁▂▄▄▄▂▅▄▄▅▅▅▅▅▆▅▅▆▄▅▅▆▅▆▆▆▆█▅
wandb:      train/ensemble_f1 ▃▁▂▃▃▄▃▂▄▂▅▄▅▅▆▄▃▄▅▄▆▄▅▆▇▅▄▇▆▆▆▅▆▆▅▅█▇▆▆
wandb:         train/mil_loss ▅▄▅▇▆▃▄▄▄▆▅▅▄▂▆█▄▁▃▄▅▅▄▅▆▃▁▃▄▂▄▃▅▄▁▃▄▄▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss █▇▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▂▁▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.77263
wandb: best/eval_avg_mil_loss 0.66491
wandb:  best/eval_ensemble_f1 0.77263
wandb:            eval/avg_f1 0.77263
wandb:      eval/avg_mil_loss 0.60409
wandb:       eval/ensemble_f1 0.77263
wandb:            test/avg_f1 0.75669
wandb:      test/avg_mil_loss 0.50349
wandb:       test/ensemble_f1 0.75669
wandb:           train/avg_f1 0.75217
wandb:      train/ensemble_f1 0.75217
wandb:         train/mil_loss 0.62119
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dauntless-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tzm3blhq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_020150-tzm3blhq/logs
wandb: Agent Starting Run: ymsl68l1 with config:
wandb: 	actor_learning_rate: 0.0016136565563708623
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8806400464597502
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3860299322784312
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_020537-ymsl68l1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ymsl68l1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▄▃▅▅▇▆▂▄█▆▅▃▁▆▅▇▅▄█▄▄▃▄▆▆▄▆▅▆▅▅▇▃▃▅▅▅▅
wandb:      train/ensemble_f1 ▄▄▄▄▅▅▁▂▅▄▄▃▂▅▁▃▅▅▃▂▂▃▅▇▆▅▅▅▄▃▂▃█▅▄▄▃▃▅▄
wandb:         train/mil_loss █▃▅▆▅▄▅▇▁▃▅▆▅▃▄▆▃▂▄▅▅▄▅▄▅▆▄▆▇▅▄▅▃▅▄▄▄▅▃▅
wandb:      train/policy_loss ▅▇▇▇▆▇▇▆▃▃▇▄▃▃▅▄▅▃▆▇▇▇▇▆▇▇▁▃█▆▅▆▅▆▆▆▆▅▅▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▇▃▇▇▆▄█▄▅▃▄▇▄▅▃▅▅▆▄█▅▇▄▁█▇▆▅▆▆▆▄▅▅▆▅▅▄▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.83262
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.82699
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.93761
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32998
wandb:      train/ensemble_f1 0.32998
wandb:         train/mil_loss 0.59652
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run revived-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ymsl68l1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_020537-ymsl68l1/logs
wandb: Agent Starting Run: tpgz1w1a with config:
wandb: 	actor_learning_rate: 3.935664150068998e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5048311053742081
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8614284528515479
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_020705-tpgz1w1a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tpgz1w1a
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▆█
wandb: best/eval_avg_mil_loss █▅▁
wandb:  best/eval_ensemble_f1 ▁▆█
wandb:            eval/avg_f1 ▁▁▁▁▆▆▆▆▆▆▆▆▆▆▃▃▃▃▃▃▃▃██████████████████
wandb:      eval/avg_mil_loss ▆▆▅▅▃█████▇▇▇▇▇▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▆▆▆▆▆▃▃▃▃▃▃▃▃▃██████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▅▃▃▄▆▃▃▃▃▁▂▆▅▄▄▆▄▄▆▄▄▅▅▆▇▅▅▅▅▇▅▄▅▇█▆▃█▇
wandb:      train/ensemble_f1 ▁▂▂▃▃▄▁▅▄▄▃▃▂▃▄▄▄▅▅▃▇▄▆▅▆▆▄█▅▄▆▆▃▅▅▇▆▆▅▇
wandb:         train/mil_loss ▄▅▄▄▆▃▄▄▂▅█▄▂▄▄▃▄▄▃▃▃▄▆▄▅▄▃▃▁▁▄▄▄▄▂▃▃▁▆▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ███████████████▁████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.63535
wandb: best/eval_avg_mil_loss 0.51691
wandb:  best/eval_ensemble_f1 0.63535
wandb:            eval/avg_f1 0.63535
wandb:      eval/avg_mil_loss 0.5072
wandb:       eval/ensemble_f1 0.63535
wandb:            test/avg_f1 0.61766
wandb:      test/avg_mil_loss 0.54743
wandb:       test/ensemble_f1 0.61766
wandb:           train/avg_f1 0.65886
wandb:      train/ensemble_f1 0.65886
wandb:         train/mil_loss 0.69346
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run silver-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tpgz1w1a
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_020705-tpgz1w1a/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: cmnyf1wy with config:
wandb: 	actor_learning_rate: 1.6972592565373576e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.59223126173598
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.01022082258444168
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_021028-cmnyf1wy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cmnyf1wy
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▅▅▄▄▄▄▄▄▃▃▃▃▂▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▁▁▄█▂▆▄▃▅▆▄▂▄▄▃▅▃▃▂▄▆▄▂▁▄▁▇▅▃▅▅▄▃▄▄▆▇▄▄
wandb:      train/ensemble_f1 ▄▂▁▄█▆▄▅▇▅▄▂▅▄▄▃▃▂▃▆▃▄▅▁▇▃▅▅▁▆▆▅▃▃▃▃▇▄▄▄
wandb:         train/mil_loss ▃▁▃▄▇▆▃▄█▄▄▇▇▅▄▅▆▇▄▃▅▄▅▄▄▅▄▃▄▅▆▆▂▄▃▁▆▃▆▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.55556
wandb: best/eval_avg_mil_loss 0.92098
wandb:  best/eval_ensemble_f1 0.55556
wandb:            eval/avg_f1 0.55556
wandb:      eval/avg_mil_loss 0.86631
wandb:       eval/ensemble_f1 0.55556
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.80714
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.53853
wandb:      train/ensemble_f1 0.53853
wandb:         train/mil_loss 0.82521
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stilted-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cmnyf1wy
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_021028-cmnyf1wy/logs
wandb: Agent Starting Run: 2vqf6vsd with config:
wandb: 	actor_learning_rate: 3.1985093558939106e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7409254299223229
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.421467733728212
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_021158-2vqf6vsd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2vqf6vsd
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▂▄▂▇▆▇▄▆▄▃▃▂▅▂▆▅▄▃▅█▁▄▅▃▄▄▅▆▂▅▃█▇▁▅▆▅█
wandb:      train/ensemble_f1 ▄▁▃▃▇▇▄▆▅▇▄▅▅▆█▄▄▅▅▄▄▃▄▆▄▅▇▅▆▆▆▇▅▆▆▅▆▆▆▅
wandb:         train/mil_loss ▄▄▅▆▂▄▃▆▃▄▄▃▃█▄▅▃▃▆▃▄▄▆▄▄▄▂▅▄▅▂▆▆▅▄▄▄▄▁▃
wandb:      train/policy_loss ▂▇▄▅▅▅▆▆█▃▅▁▆▄▅▂▇▅▇▄▅▃▅▆▆▆▆▄▅▅▇▃▇▅▆▅▅▅▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▆▅▄▃▃▅▅█▅▂▂▆▇▆▅▄▅▁▅▃▅▅▅▅▆▅▃▅▅▅▄▁▆▂▅▅▄▆▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61279
wandb: best/eval_avg_mil_loss 1.19387
wandb:  best/eval_ensemble_f1 0.61279
wandb:            eval/avg_f1 0.61279
wandb:      eval/avg_mil_loss 1.11178
wandb:       eval/ensemble_f1 0.61279
wandb:            test/avg_f1 0.5842
wandb:      test/avg_mil_loss 0.83079
wandb:       test/ensemble_f1 0.5842
wandb:           train/avg_f1 0.63398
wandb:      train/ensemble_f1 0.63398
wandb:         train/mil_loss 1.04189
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crisp-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/2vqf6vsd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_021158-2vqf6vsd/logs
wandb: Agent Starting Run: ivsotiaa with config:
wandb: 	actor_learning_rate: 0.0002403654624708811
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.19236928886644533
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.06513788988791891
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_021326-ivsotiaa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ivsotiaa
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▃▆▅▅▂▄▄▃▅▅▄▂▃▂▄▅▅▄▂▃▄▂▃▄▃▅▃▅▃▅▄▁▃▄▄█▃▄
wandb:      train/ensemble_f1 ▄▃▄▄▆▇▄▃▄▂▃▅▂▃▅▄▃▅▃▃▅▅▃▄▄▆▆▄▄▅▄▅▇▄▅▁▁▄█▄
wandb:         train/mil_loss ▄▅▄▆▆█▆▃▃▂▆▃▆▃▂▄▂▆▃▄▅▄▅▃▅▄▃▇▂▃▄▄▄▂▆▃▅▁▂▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.0213
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.94946
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.83911
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.40554
wandb:      train/ensemble_f1 0.40554
wandb:         train/mil_loss 0.88926
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run brisk-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ivsotiaa
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_021326-ivsotiaa/logs
wandb: Agent Starting Run: kbwavg10 with config:
wandb: 	actor_learning_rate: 1.4485176352097833e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4039528556684613
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.545542176726783
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_021453-kbwavg10
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kbwavg10
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ██████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▂▄▆▃▁▇▆▂▄▄▃▅▃▃▃▄▄▂▂▄▄▄▄█▅▆▆▇▄▃▆▁▂▆▆▄▅▄
wandb:      train/ensemble_f1 ▆▅▃▄▆▅▇▄█▃▅▄▅▃▄▅▅▃▇▁▄▅▄▅▆▇▅█▅▆▃▄▅▇▃▄▅▆▆▅
wandb:         train/mil_loss ▇▆█▆▅▃▆▅▆▃▅▃▄▅▄▂▄▆▅▂▄▂▁▅▆▃▄▅▃▃▅▃▂▃▃▄▆▇▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.63922
wandb: best/eval_avg_mil_loss 0.55437
wandb:  best/eval_ensemble_f1 0.63922
wandb:            eval/avg_f1 0.63045
wandb:      eval/avg_mil_loss 0.54417
wandb:       eval/ensemble_f1 0.63045
wandb:            test/avg_f1 0.60262
wandb:      test/avg_mil_loss 0.57663
wandb:       test/ensemble_f1 0.60262
wandb:           train/avg_f1 0.63793
wandb:      train/ensemble_f1 0.63793
wandb:         train/mil_loss 0.6371
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rose-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kbwavg10
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_021453-kbwavg10/logs
wandb: Agent Starting Run: vu14j73f with config:
wandb: 	actor_learning_rate: 0.0002767128071128754
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.21329064504287976
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.13454807044607042
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_021622-vu14j73f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vu14j73f
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▅▃▇▄▄▄▄█▆▇▃▅▇▆▅▃▅▅▄▇▄▅▆▅▅▅▁▆▄▇▂▄█▆▇█▆▆
wandb:      train/ensemble_f1 ▄▄▆▃▂▃▇▄▃█▇▂▁▇▅▅▂▄▇▃▃▅▃▅▅▆█▅▅▆█▄▇▃▄▄▇▂▃▃
wandb:         train/mil_loss ▅▆█▆▇██▃▄█▇▇▇▂▄▆▆▁▄▅▂▇▄█▅▇▃▅▅▅▃▄▄▂▄▄▂▄▅▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 0.94941
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.88321
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.7892
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.39973
wandb:      train/ensemble_f1 0.39973
wandb:         train/mil_loss 0.81287
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dashing-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vu14j73f
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_021622-vu14j73f/logs
wandb: Agent Starting Run: qkkjtpfg with config:
wandb: 	actor_learning_rate: 0.000454092717618297
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9979527497356612
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1330660433953751
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_021750-qkkjtpfg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qkkjtpfg
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▆▆▆▄▅▆▅▅▄▄▄▄▄▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▄▄▄█▆▅▅▅▇▄▆▄▃▅▁▄▄▄▃▅▄▅▃▄▄▂▄▄▄▄▂▃▅▄▂▁▇▅▅
wandb:      train/ensemble_f1 ▄▄▅▃▇▅▅▃▃▂▅▅▅▄▅▃▆▅▆▅▄▅▄▃▄▂▄▆▂▅▄▂▅▅▁▃█▆▇▅
wandb:         train/mil_loss ▄▅▄▇▄▂▅▇▄▃▄▆▄▅▆▁▅▅▂▆▄▅▆▅▅▆▄▅▂▅▁▃▄▅▆▄▅█▄▄
wandb:      train/policy_loss ██████████████████▁█████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████▁█████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.98195
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.98111
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.09292
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3372
wandb:      train/ensemble_f1 0.3372
wandb:         train/mil_loss 0.59822
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run twilight-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qkkjtpfg
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_021750-qkkjtpfg/logs
wandb: Agent Starting Run: y4m0npoe with config:
wandb: 	actor_learning_rate: 0.003592173442816055
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.20379221045252785
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2953745148325446
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_021918-y4m0npoe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y4m0npoe
wandb: uploading history steps 130-136, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▅▅▅▅▅▃▃▃▃▁██▆▆▆▆▆▆▆▆▆███████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇█▆▆▃▃▃▂▃▃▃▃▄▄▄▄▄▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▅▅▅▅▅▁▁▁▁▁▁████▆▆▆▆▆▆▆▆▆▆▆▆█████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▃▄▃▁▄▃▃▂▅█▃▆▅▆▅▆▇▆▄▅▅▄▃▄▆▆▃▅▆▃▄▆▃▅▅▃▆▄
wandb:      train/ensemble_f1 ▆▃▅▃▃▃▂▂▄▅▅▂█▆▃▆▆▄▆▇▄▃▃▂▂▅▃▂▂▆▁▆▄▅▅▄▄▄▆▃
wandb:         train/mil_loss ▄▂▃▃▄▂▂▁▃▅▂▄▃▅▄▃▅▄▃█▄▇▄▄▃▄▄▄▆▄▄▅▄▇▃▄▄▁▃▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.62248
wandb: best/eval_avg_mil_loss 0.55021
wandb:  best/eval_ensemble_f1 0.62248
wandb:            eval/avg_f1 0.62248
wandb:      eval/avg_mil_loss 0.53502
wandb:       eval/ensemble_f1 0.62248
wandb:            test/avg_f1 0.58722
wandb:      test/avg_mil_loss 0.62593
wandb:       test/ensemble_f1 0.58722
wandb:           train/avg_f1 0.58
wandb:      train/ensemble_f1 0.58
wandb:         train/mil_loss 0.71007
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clean-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y4m0npoe
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_021918-y4m0npoe/logs
wandb: Agent Starting Run: h1rj5ibu with config:
wandb: 	actor_learning_rate: 3.244439724556985e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4982291941904431
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7279168077151124
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_022111-h1rj5ibu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h1rj5ibu
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃▇▅▅▅▅▅▄▅█▁▃▃▇▇▃▅▄▄▇▄▄█▅▃▄▅▆▇▃▄▂█▃▃█▆▅
wandb:      train/ensemble_f1 ▁▂▂▅██▄▃▇▄▄▅▅▅█▄▃▅▃▇▅▄▅▅▄▄▃█▄▅▆▅▇▃▄▅▅▇█▅
wandb:         train/mil_loss ▃▆▆▅▅▂▅▄▅▄▂▄▆▆▄▆▂▃▁█▇▂▅▄▂▄▁▅▄▆▄▄▇▂▂▄▃▄▅▃
wandb:      train/policy_loss ▅▄▃▄▁▆▃▃▄▄▄▆▄▂▄█▅▄▅▅▄▄▄▇▄▄▅▄▃▄▂▄▄▄▂▄▄▄▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▄▃▃▂▃▃▅▃▄▄▃▄▄▄█▅▄▅▆▁▅▃▄▅▆▄▆▂▃▅▄▆▄▄▅▃▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 8.00269
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 7.76984
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 9.82261
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32546
wandb:      train/ensemble_f1 0.32546
wandb:         train/mil_loss 3.98869
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run major-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/h1rj5ibu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_022111-h1rj5ibu/logs
wandb: Agent Starting Run: ye9v9crp with config:
wandb: 	actor_learning_rate: 0.00010356669812989438
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6868872325282124
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.29637212568043336
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_022239-ye9v9crp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ye9v9crp
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▅▂▆▄▇▂▅▅▆▆▇▄▃▅▃▄▂▇█▅▄▄▄▂▃▆▅▄▄▅▁▆▄▄▃▆▄▆
wandb:      train/ensemble_f1 ▆▁▆▃▇▇▅▇▇▅▇▇▄▃▄▃▆▂█▃▅█▃▄▄▇█▁▃▄▄▆▆▃▂▇▅▄▆▆
wandb:         train/mil_loss ▆▃▃▂▆▄▅▅▇▂▅▄▆▆▃▆▇▅▄▆▅▆▆▆▅▆▆▆▃▅█▇▄▇▄▆▁▆▆▅
wandb:      train/policy_loss ▄▆▅▄▅█▆▄▅▆▃▆▃█▇▃▃▆▄▃▃▃▇▃▅▄▄▄▄▁▃▄▆▃▆▃▄▄▃▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▅▅▆▄▁▆▄▄▄▃▃▇█▄▂▆▄▆▄▃▅▂▃▂▃▂▂▄▄▄▄▄▅▄▅▄▆▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.97958
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.9661
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.08925
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34048
wandb:      train/ensemble_f1 0.34048
wandb:         train/mil_loss 0.68937
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run ruby-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ye9v9crp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_022239-ye9v9crp/logs
wandb: Agent Starting Run: ecml931t with config:
wandb: 	actor_learning_rate: 0.0064295997224801385
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.41792166838757305
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5405844989275714
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_022407-ecml931t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ecml931t
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       eval/ensemble_f1 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇█▁▁▂▂▁▁▁▁▁▂▂▁▁▁▂▁▁▁▂▂▂▁▂▁▁▁▂▂▁▁▁▁▂▂▁▁▂▂
wandb:      train/ensemble_f1 █▂▁▂▁▂▂▁▂▁▁▂▁▁▁▁▂▁▁▂▂▁▂▁▁▁▂▁▂▁▁▁▂▁▂▁▁▁▂▁
wandb:         train/mil_loss ▃█▃▂▁▁▂▃▁▂▃▂▁▁▂▃▂▃▃▃▃▃▃▁▂▁▂▃▂▂▂▃▁▃▂▂▃▃▂▂
wandb:      train/policy_loss ▇▇▇▂▄▂▄▃▅▄▄▂▄▅█▂▃▃▄▇▂▄▅▄▅▅▂▇▅▅▇▄▄▁▅▂▆█▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▂▃▃▂▄▄▃▅▂▃▅▂▂▃▅▅▄▄▄▃▆▂▅▄▄▆▆▃▄▁█▃▅▆▃▄▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.52497
wandb: best/eval_avg_mil_loss 0.77062
wandb:  best/eval_ensemble_f1 0.52497
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.82725
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.68375
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.3361
wandb:      train/ensemble_f1 0.3361
wandb:         train/mil_loss 0.69226
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run golden-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ecml931t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_022407-ecml931t/logs
wandb: Agent Starting Run: 3b5uah2r with config:
wandb: 	actor_learning_rate: 0.006359791167400525
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.762103937039682
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8360947510105254
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_022535-3b5uah2r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3b5uah2r
wandb: uploading history steps 168-175, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████
wandb:      eval/avg_mil_loss ██████▇▇▇▇▇▇▇▇▆▆▄▄▄▃▂▂▁▃▂▂▂▂▂▁▁▁▁▁▁▁▃▃▂▂
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▆▃▄▆▃▄▅▅▇▅▆▆▆▃▁▄▇▅▇▅▆▇█▆▅▆▅▆▄▆▆▇▅▅▆▇▇▇
wandb:      train/ensemble_f1 ▄▅▅▁▃▁▃▃▅▃▅▃▅▃▁▅█▅▂▄▂▆▆▄▅▄▄▅▆▄▆▅▃▃▅▄▆▃▆▃
wandb:         train/mil_loss ▂▅▄▁▄▇▂▄▄▂▁▃▆▅▁▂█▃█▂▁▂▂▅▁▄▂▂▄▆▃▂▇▃▂▆▅▃▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66933
wandb: best/eval_avg_mil_loss 0.46835
wandb:  best/eval_ensemble_f1 0.66933
wandb:            eval/avg_f1 0.66933
wandb:      eval/avg_mil_loss 0.4677
wandb:       eval/ensemble_f1 0.66933
wandb:            test/avg_f1 0.64672
wandb:      test/avg_mil_loss 0.52402
wandb:       test/ensemble_f1 0.64672
wandb:           train/avg_f1 0.61067
wandb:      train/ensemble_f1 0.61067
wandb:         train/mil_loss 0.60981
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run misunderstood-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3b5uah2r
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_022535-3b5uah2r/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: m1obhbgl with config:
wandb: 	actor_learning_rate: 1.1893081255967112e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.46197159963292656
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9279850110189718
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_022828-m1obhbgl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m1obhbgl
wandb: uploading history steps 167-181, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▁█▁▂▁▄▂▂▃▅▃▇▃▅▅▃▅▄▄▃▃▅▃▅▇▄▅▄▅▇▅▇▆▃▄▄▆▆▁
wandb:      train/ensemble_f1 ▆▂▄▃▁▄█▂▅▂▄▃▂▆▄▂▃▃▅▅▃▆▄▂▄▆▅▄▅▆▅▆▆▆▇▄▄▆▆▂
wandb:         train/mil_loss ▆▆▄▅▄▄█▇▅▃▄▅▅▄▄█▄▅▄▄▅▄▃▆▅▅▆▅▁▆▄▄▄▆▅▆▅▂▆▆
wandb:      train/policy_loss ▅▇▇█▃▆▅▆▁▇▅▇▆▂▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.60938
wandb: best/eval_avg_mil_loss 0.5637
wandb:  best/eval_ensemble_f1 0.60938
wandb:            eval/avg_f1 0.60938
wandb:      eval/avg_mil_loss 0.55551
wandb:       eval/ensemble_f1 0.60938
wandb:            test/avg_f1 0.57924
wandb:      test/avg_mil_loss 0.58386
wandb:       test/ensemble_f1 0.57924
wandb:           train/avg_f1 0.56024
wandb:      train/ensemble_f1 0.56024
wandb:         train/mil_loss 0.65429
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run bumbling-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m1obhbgl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_022828-m1obhbgl/logs
wandb: Agent Starting Run: 5c7oyxj6 with config:
wandb: 	actor_learning_rate: 7.793745307473822e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3314262373427871
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.035832270714750813
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_023102-5c7oyxj6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5c7oyxj6
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▃▁▆▃▅▅▅▃▂▆▄▆▅▄▅▃▂▆▂▆▄▄▃▂▄▃▆█▅▄▇▄▄▇▅▂▄▃▅
wandb:      train/ensemble_f1 ▆▅▅▁▄▅▅▄▄▂▃▄▆▄▆█▃▅▄▆▄▃▅▂▄▄█▄▄▆▄▅▆▄▆▁▃▅▂▃
wandb:         train/mil_loss ▅▅▆▇▇▆▄▇▅▇█▆▅▃▃▂▄▆▅▇▄█▃▄▂▆▄▄▄▂▁▆▇▄▆▃▄▂▃▇
wandb:      train/policy_loss ▆▆▆▃▆▃▂▃▃▅▅▆▆▄▆██▆▃▆▇▆▄▆▄▂▆▆▁▂▃▃▂▄▄▆▄▄▆▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▃▃▆▂▃▆▅▆▃▅▆▁▂▄▃█▃▆▄▆▂▄▂▃▂▃▃▆▂▃▄▃▄▆▆▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.98031
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.95891
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.07754
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33884
wandb:      train/ensemble_f1 0.33884
wandb:         train/mil_loss 0.8459
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/5c7oyxj6
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_023102-5c7oyxj6/logs
wandb: Agent Starting Run: td8186yk with config:
wandb: 	actor_learning_rate: 0.004389987540091747
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.29050238490374103
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5601855201142009
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_023229-td8186yk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/td8186yk
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▃▄▄▅▅▆▆▆▇▇██
wandb: best/eval_avg_mil_loss █▆▄▄▄▃▃▃▃▃▃▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▃▄▄▅▅▆▆▆▇▇██
wandb:            eval/avg_f1 ▂▂▁▃▃▃▃▃▄▄▄▄▄▄▄▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇███████
wandb:      eval/avg_mil_loss █▇▇▇▇▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▂▄▄▄▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇█████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▂▂▁▁▃▃▃▃▂▃▄▄▄▄▅▅▄▅▅▅▅▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇
wandb:      train/ensemble_f1 ▁▁▁▂▃▃▃▃▃▄▃▃▃▄▄▅▅▃▅▅▅▇▆▇▇▆▇▆▇▇▇▆▇▇▇▆▇▇▇█
wandb:         train/mil_loss █▆▅▅▃▄▄▄▃▃▃▃▂▂▃▂▃▃▂▂▂▂▂▁▂▂▂▂▂▁▁▂▂▁▂▂▂▁▂▁
wandb:      train/policy_loss ▁▁▁▁▅▁▁▁▁▁▁▁▃▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81737
wandb: best/eval_avg_mil_loss 0.42761
wandb:  best/eval_ensemble_f1 0.81737
wandb:            eval/avg_f1 0.81737
wandb:      eval/avg_mil_loss 0.40323
wandb:       eval/ensemble_f1 0.81737
wandb:            test/avg_f1 0.82418
wandb:      test/avg_mil_loss 0.36298
wandb:       test/ensemble_f1 0.82418
wandb:           train/avg_f1 0.84429
wandb:      train/ensemble_f1 0.84429
wandb:         train/mil_loss 0.49841
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run young-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/td8186yk
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_023229-td8186yk/logs
wandb: Agent Starting Run: z9welsd2 with config:
wandb: 	actor_learning_rate: 0.0099627730193815
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8913668941696884
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5205896603437248
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_024013-z9welsd2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z9welsd2
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▅▃▆▄▇▄██▆▄▅▃▆▄▅▇▆▄▅▃▇▂▅▃▇▄▄▅▃▄▂▂▁▇▅▃▃▅
wandb:      train/ensemble_f1 ▆▃▄▄▆▂▃▆▄▆▁▆▅▆▄▇▅█▆▅▂▅▄▅▃▃▂▅▇▃▂▄▁▁▆▃▆█▃▂
wandb:         train/mil_loss ▂▄▆▂▄▃▆▄▁▅▄▄▄▄▅▄▃▃▂▂▃▄▂▅▂▂▂▆▂▁▃█▄▂▃▂▂▄▆▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.56173
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.52113
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 1.10244
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.3756
wandb:      train/ensemble_f1 0.3756
wandb:         train/mil_loss 0.68775
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run rich-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z9welsd2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_024013-z9welsd2/logs
wandb: Agent Starting Run: ztp5f97b with config:
wandb: 	actor_learning_rate: 0.00090797223679954
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.815601228725473
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3605398472524281
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_024143-ztp5f97b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ztp5f97b
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███▇▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▂▅███████████████████████████████
wandb:       eval/ensemble_f1 █████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▇▇█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▂▁▁▂▁
wandb:      train/ensemble_f1 ██▇█▆▁▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁▁▁▂▂▁▂▁▁▁▁▂▁
wandb:         train/mil_loss ▁▁▂▃▂▄▄▆▃▃█▇▅▃▄▂▃▃▁▄▃▃▂▂▃▄▄▂▄▂▂▃▅▆▃▃▅▄▅▄
wandb:      train/policy_loss ███████▁████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██▇▅█▁▁▅▄▃▄▂▂▄▃▄▃▄▅▅▄▄▃▄▅▅▅▃▄▄▄▃▄▅▄▄▂▃▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.68467
wandb: best/eval_avg_mil_loss 0.68967
wandb:  best/eval_ensemble_f1 0.68467
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 7.34361
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.56892
wandb:      test/avg_mil_loss 1.28629
wandb:       test/ensemble_f1 0.56892
wandb:           train/avg_f1 0.3311
wandb:      train/ensemble_f1 0.3311
wandb:         train/mil_loss 1.9389
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run logical-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ztp5f97b
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_024143-ztp5f97b/logs
wandb: Agent Starting Run: qwqy1k5m with config:
wandb: 	actor_learning_rate: 0.009801669388109516
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.09653871651765712
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07954417914789336
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_024311-qwqy1k5m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qwqy1k5m
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄
wandb:       eval/ensemble_f1 █████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ███▇▄▂▃▃▂▂▂▄▃▃▂▂▄▃▂▃▃▂▁▁▁▄▂▃▂▁▂▃▃▁▃▃▁▃▄▁
wandb:      train/ensemble_f1 █▇▃▂▂▃▂▁▃▂▂▂▃▂▂▃▃▂▁▂▂▂▂▁▁▂▁▂▄▁▂▂▃▃▁▂▃▄▃▃
wandb:         train/mil_loss ▆▃▄▆█▆▆▇▅█▅▃▇▅▆▆▆▅▅▅▅▇▇▄▅▂▄▅▃▆▄▄▆▃▄▄▁▄▅▅
wandb:      train/policy_loss ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49286
wandb: best/eval_avg_mil_loss 1.01295
wandb:  best/eval_ensemble_f1 0.49286
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.10088
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.78218
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.38234
wandb:      train/ensemble_f1 0.38234
wandb:         train/mil_loss 1.11149
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run swept-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/qwqy1k5m
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_024311-qwqy1k5m/logs
wandb: Agent Starting Run: yrpw3l9z with config:
wandb: 	actor_learning_rate: 0.006742778126280348
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6075824460240763
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9663555793714116
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_024439-yrpw3l9z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yrpw3l9z
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▃▆▁▃▃▅▃▂▃▃▄▄▃▁█▂▅▄▁▇▄▆▄▃▅▃▂▁▅▂▇▂▃▃▅▂▄▄▃
wandb:      train/ensemble_f1 ▃▁▆▃▃▃▄▃▃▆▅▅▄▄▄▂█▃▆▁▇▃▇▃▄▆▆▃▅▃▄▂█▆▅▆▃▅▅▅
wandb:         train/mil_loss ▄▃▇▄▃▄▇▇█▆▅▆▃▂▄▅▅▄▄▅▄▅▅▃▅▅▂▁▇▄▂▄▂▇▁▃▅█▂▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.55997
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.45829
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 1.25791
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.39322
wandb:      train/ensemble_f1 0.39322
wandb:         train/mil_loss 0.87078
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run desert-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yrpw3l9z
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_024439-yrpw3l9z/logs
wandb: Agent Starting Run: j18xp86a with config:
wandb: 	actor_learning_rate: 0.0007423605831185932
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2998658271776409
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3887591890710558
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_024607-j18xp86a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j18xp86a
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▆▃▆▁█▇▅▆▆▅▇▆▄▅▆▅▇▃▄▆▇▇▆▅▅▄▅▆▃▅▇▄▅▄▇▅▂█
wandb:      train/ensemble_f1 ▄▃▇▇▇▇▄▇▆▆▄▆▆▄▄▃▃▇▄▃▆▁▆▄█▇▅▅▃▃██▃▅▄▄▅▂▃▆
wandb:         train/mil_loss ▃▇▅█▂▂▃▆▄▅▅▄▇▁▃▄▅▂▆▄▄▄▁▃▅▂▅▁▅▃▄▅▁▄▁▃▄▃▁▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49286
wandb: best/eval_avg_mil_loss 0.68029
wandb:  best/eval_ensemble_f1 0.49286
wandb:            eval/avg_f1 0.49286
wandb:      eval/avg_mil_loss 0.65441
wandb:       eval/ensemble_f1 0.49286
wandb:            test/avg_f1 0.48547
wandb:      test/avg_mil_loss 0.58835
wandb:       test/ensemble_f1 0.48547
wandb:           train/avg_f1 0.4735
wandb:      train/ensemble_f1 0.4735
wandb:         train/mil_loss 0.68918
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run daily-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/j18xp86a
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_024607-j18xp86a/logs
wandb: Agent Starting Run: 93dvkcjv with config:
wandb: 	actor_learning_rate: 5.380151089627026e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4226812493480886
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5461869551117772
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_024735-93dvkcjv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/93dvkcjv
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▆▃▆▄▃▇▁▄▄▁▃▂▃▄▇▅▄▃█▂▆▅▃▆▄▅▅▆▃▄▄▆▆█▅▇█▅
wandb:      train/ensemble_f1 ▅▆▃▃▅▅▄▃▇▄▁▃▄▄▄▅▆▃▃▂▄▁▂▃▃▇▇▅█▅▃▃▃▅▂▂▅▄▇▆
wandb:         train/mil_loss ▆▄▆▃▃▆▅▄▃▃▇▆▇▆▂▆█▆▄▄▆▅▃▇▄▃▁▃▅▅█▂▃▇▁▆▆▅▇▆
wandb:      train/policy_loss ▇█▄▁▂▇▆▄▄▄▄▇▅▃▅▅▆▆▄▄▃▄▄▂▅▅▃▅▂▅▄▅▄▄█▅▃▆▄▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▂▄▄▂▅▇▇▄▃▄▃▆▂▃▅▆▆▆▁▄▂▄█▁▅▁▄▄▇▁▇▃█▄▆▅▂▆▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.98177
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.96421
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.09156
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34102
wandb:      train/ensemble_f1 0.34102
wandb:         train/mil_loss 0.77821
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eternal-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/93dvkcjv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_024735-93dvkcjv/logs
wandb: Agent Starting Run: l89xvtno with config:
wandb: 	actor_learning_rate: 2.9925103629387253e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.676158860631858
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.379233273169262
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_024903-l89xvtno
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l89xvtno
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▆▆▅▅▅▄▄▄▃▃▂▂▂▂▂▁▁████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▅▄▂▅▃▄▅▄▆▆▂▇▇▅▆█▅▃▆▇▆▇▄▆▅▅▆▅█▇▇▅▅▆▆▇▄▁
wandb:      train/ensemble_f1 ▄▁▅▅▄▂▆▅▁▄▇▅█▅▃▁▄▅▆▆▂▆▅▃▅▃▄█▃▃▇▇▆▅▅▃▅▅▆▃
wandb:         train/mil_loss ▅▄▄▂▆▇▁▅▄▅▅▄▄▂▃▇▃█▅▂▃▄▄▂▄▇▃▅▅▅█▆▄▂▅▄▆▅▁▅
wandb:      train/policy_loss ▆▃▅▅▃▅█▅▆▁▅▅▄▆█▅▇▄▄█▄▆█▇▄▆▄▄▅▇▃▅▇▆▅▃▅▆█▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▄▄▅▃▄▃▄▃▂▅▅▄▂▄▅▅▅▂▄▃▄▂▅█▂▄▂▂▄▄▂▄▅▃▂▅▂▂▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.98508
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.9825
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.10183
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34048
wandb:      train/ensemble_f1 0.34048
wandb:         train/mil_loss 0.71778
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run peach-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/l89xvtno
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_024903-l89xvtno/logs
wandb: Agent Starting Run: zx472ls8 with config:
wandb: 	actor_learning_rate: 0.0035933645359938096
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4734279708207081
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.01581494947470785
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_025031-zx472ls8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zx472ls8
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▃▃▄▁▂▄▇▃▂▃▂▂▂▄▃▄▄▇▂█▅▅▄▄▅▅▄▂▇▂▄▃▃▅▇▇▅▂
wandb:      train/ensemble_f1 ▆▄▄▃▃▄▅▁▇▄▂▂▂▅▁▂▄▃▅▆▄▄▅▅▆▇▆▂█▅█▃▄▇▄▇▅▇▅▄
wandb:         train/mil_loss █▃▅▆▃▃▅▃▅▆▄▁▅▅▁▅▃▃▄▄▄▃▇▄▁▄▃▇▄▅▆▄▂▃▄▂▅▂▆▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.08912
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.02473
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 0.87749
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.36659
wandb:      train/ensemble_f1 0.36659
wandb:         train/mil_loss 0.83503
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run happy-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zx472ls8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_025031-zx472ls8/logs
wandb: Agent Starting Run: bvun3g5q with config:
wandb: 	actor_learning_rate: 6.724884677028391e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7934037076004006
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7514806347767373
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_025158-bvun3g5q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bvun3g5q
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▂▂▅▅▃▄▄▇█▅▅▂▄▇▄▆▄▄▆▇▇▆▆█▃▄▂▇▁▅▁▃▅▆▅▆▆▃
wandb:      train/ensemble_f1 ▄▁▃▅▃▇▄▄▄▃▆▅▆▆▅▆█▇▅▂▆▇▅▃▄▄▇▄▆▃▅▅▅▄▆▆▃▄▃▅
wandb:         train/mil_loss ▃▆▃▄▁▅▅▆▄▃▄▄▄▅▃▄▃▆▅█▅▃▃▃▆▄▄▅▃▆▃▃▃▅▄▂▆▅▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.21586
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.15599
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 0.90278
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.40679
wandb:      train/ensemble_f1 0.40679
wandb:         train/mil_loss 0.80016
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run super-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/bvun3g5q
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_025158-bvun3g5q/logs
wandb: Agent Starting Run: 3vp0jl1y with config:
wandb: 	actor_learning_rate: 2.673458637694433e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4503121934856096
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9329339075124984
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_025327-3vp0jl1y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3vp0jl1y
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▃▄▇▄▁▄█▄▆▇▄▂▃▅▅▃▄▄▅▂▅▅▃▅▄▅▂▇▆▃▂▄▃▄▅▄▅▃
wandb:      train/ensemble_f1 ▇▃▃▄▄▄▂▃█▅▄▅▃▃▅▆▄▃▄▅▂▁▄▁▂▂▆▄▇▅▂▄▂▂▅▂▄▃▄▃
wandb:         train/mil_loss ▆▆▄▇▆▇▆▄▃▇▅▇▅▆█▅▆▅▃▅▅▁▃▄▂▅▅▅▆▄▁▃▅▂▆▃▅▄▄▃
wandb:      train/policy_loss ▃▂▄▄▂▄▅▄▂▃▃▅▂▂▂▄▅▅▄▃▃▃▃▃▁▅▃▅▃▄▂▄█▆▃▆▃▆▂▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▂▄▂▅▃▄▂▅▂▄▄▂▅▂▅▃▅▂█▁▅▄▄▃▃▄▂▂▄▅█▅▆▄▆▄▅▄▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 7.65813
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 7.4065
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 9.49984
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32942
wandb:      train/ensemble_f1 0.32942
wandb:         train/mil_loss 4.54621
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earthy-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/3vp0jl1y
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_025327-3vp0jl1y/logs
wandb: Agent Starting Run: vkuhubam with config:
wandb: 	actor_learning_rate: 0.0003948408328440946
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.13041010409646348
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7572697264865925
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_025454-vkuhubam
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vkuhubam
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅█▃▆▇▇▂▅▄▁▃▅▃▆▇▃▃▇▁▄▂▃▄▇▂▁▆▅▃▅▄▅▄▆▄▆▄▅▅
wandb:      train/ensemble_f1 ▆▂▅▃▅▆▇▃▄▆▃▇▇▆▂▇▅▄▅▁▂▃▇▅▂▅▅▅▃▅▆█▅▃▄█▅▅▁▅
wandb:         train/mil_loss ▃▇▄▇▃█▅▁▄▅▃▆▅▅▂▄▅▅▂▁▄▄▃▅▆█▆▅▅▁▅▆▅▂▅▅▃▃▅▃
wandb:      train/policy_loss ▃▃▂▅▄▃▁▅▃▅▃▆▇▂▅█▃▂▅▆▆▇▃▆▁▇▃▃▂▃▅▃▃▂▅▄▇▃▂▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▁▃▇▂▃▁▆▃█▅▅▆▃▇▂▆▁▅▅▄▅▇▃▂▆▇▂▁▃▃▅▃▂▂▃▂▁▃▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.97431
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.95307
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.08503
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32546
wandb:      train/ensemble_f1 0.32546
wandb:         train/mil_loss 0.84136
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run stoic-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vkuhubam
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_025454-vkuhubam/logs
wandb: Agent Starting Run: m61mdpeu with config:
wandb: 	actor_learning_rate: 7.138831179831891e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8599041800036669
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.27121072248563494
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_025622-m61mdpeu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m61mdpeu
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▆▆▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▆█▅▆▃▄▇▅▆▅▅▇▄▄▅█▁▅▅▄▅▇▄▄▃▅▇▅▆▄▆▃▃▆▇▂▅▅
wandb:      train/ensemble_f1 ▅▄▅▂▅▄▃▄▆▄▄▇▇▃█▂▇▂▅▃▅▄▇▆▄▃▅▇▇▅▄▅▁▆▆▂▇▅▅▆
wandb:         train/mil_loss ▃▃▄▅▅▆▄▄▇▆▃▇▄▂▇▂▃▇▁▄▇▄▄▆▆▁▄▂▄▄▃▆▃▆▃▇▄▄▄█
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.35569
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.30597
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.41725
wandb:      test/avg_mil_loss 1.09061
wandb:       test/ensemble_f1 0.41725
wandb:           train/avg_f1 0.42413
wandb:      train/ensemble_f1 0.42413
wandb:         train/mil_loss 0.77343
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deft-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m61mdpeu
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_025622-m61mdpeu/logs
wandb: Agent Starting Run: tsm6sajs with config:
wandb: 	actor_learning_rate: 0.006246935464925324
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.46540406366671383
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4460584827922295
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_025750-tsm6sajs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tsm6sajs
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▆▃▁▆▄▆▄▅█▅▅▅▅▇▆▆▃▄▇▆▅▅▇▅▃▃▅▃▅▆▅▇▅▅▃▅▅▅
wandb:      train/ensemble_f1 ▄▄▄▃▅▅▅▅▃▇▄▁▅▄▃▆▅▅▃▆▄█▃▆▆▆▆▅▄▄▂▄▃▃▅▄▃▄▅▄
wandb:         train/mil_loss ▄▇▅▁█▄▅▄▅▄▅▇▅▃▃▆▅▆▅▆▃█▆▃▆▄▆▄▃▃█▅▇▅█▄▄▅▆▃
wandb:      train/policy_loss ▇█▁▄▇▇▆▅▆▆▆▆▇▆▇▇▇▅▆▇▅▆▇▄▇▄▇▇▇▅▃▅▆▇▆▆▆▄▅▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▇▄▄▄▄▆▄▇▅▁▅▆▅▇▇▅▄▄▄▇▆▇▅▄▇▇▅▅▂▅▁▇▄▅▅█▅▂▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.95325
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.93399
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.05033
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33222
wandb:      train/ensemble_f1 0.33222
wandb:         train/mil_loss 0.77884
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run helpful-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/tsm6sajs
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_025750-tsm6sajs/logs
wandb: Agent Starting Run: nqqsxht2 with config:
wandb: 	actor_learning_rate: 9.882401897952713e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8363497934288928
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3190299067732443
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_025918-nqqsxht2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nqqsxht2
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▁▁▁▁▄▄▄▄▄▇▄▂▂▂▂▂▂▂▂▂▂▂▂▂▅▅▅▅███████████
wandb:       eval/ensemble_f1 ███████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▇▄▆▄▄▁▄▅▅▅▃▄▃▅▅▄▄▂▃▄▁█▅▅▄▄▆▂▄▇▄█▂▄▄▄▆▁▄
wandb:      train/ensemble_f1 ▆▇▄▅▅▄▅▆▄▃▄▃▃▄▄▂▃▄▁▄▄▁▄▃█▂▅▇▄▄▂▄▄▆▇▂▄▆▃▃
wandb:         train/mil_loss ▃▅▇▄▃▁▄▃▆▇▇▄█▂▂▄▅▆▃▅▄▂▂▂▄▅█▅▂▃▆▃▃▂▃▆▄▅▄█
wandb:      train/policy_loss ███████████▁████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▇▇▆▅▆▇▇▇▇██▇▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80952
wandb: best/eval_avg_mil_loss 0.46277
wandb:  best/eval_ensemble_f1 0.80952
wandb:            eval/avg_f1 0.79928
wandb:      eval/avg_mil_loss 0.474
wandb:       eval/ensemble_f1 0.79928
wandb:            test/avg_f1 0.86513
wandb:      test/avg_mil_loss 1.0223
wandb:       test/ensemble_f1 0.86513
wandb:           train/avg_f1 0.81908
wandb:      train/ensemble_f1 0.81908
wandb:         train/mil_loss 0.63207
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dainty-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/nqqsxht2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_025918-nqqsxht2/logs
wandb: Agent Starting Run: snjwudzh with config:
wandb: 	actor_learning_rate: 0.00017954736607213371
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2894095404510697
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7723940701402549
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_030045-snjwudzh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/snjwudzh
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▆▆▄▁▃▅▂▃▄▃▄▅▃▃▅▃▃▄▅▄▃▄▆▃▅▄▅▂▆▃▅▆▅█▃▂▃▅
wandb:      train/ensemble_f1 ▆█▁▆▄▅▆▇▄▅▄▆▆▆▇▆▅▅▆▆▆▄▅█▅▆▄▆▇▅▃▅▅▆▅▇▆▅▄▆
wandb:         train/mil_loss ▅▄▂▇▄▅▆▄▇▄▄▅█▅▃▆▄▄▅▄▆▃▅▆▅█▂▂▄▄▃▇▅▂▄▁▄▇▆▃
wandb:      train/policy_loss ▂▅▂▃▃▂▄▅▃▅▄▆▄█▃▄█▂▅▃▄▂▄▂▅▄▃▆▄▆▇▁▃▃▄▇▃▄▆▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▆▁▂▅▅▄▃▂▄▅▂▄▇▂█▄▄▆▄▃▅▅█▄▃▆▄▇▄▄▆▅▄▄▅▃▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.96266
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.94321
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.06875
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33884
wandb:      train/ensemble_f1 0.33884
wandb:         train/mil_loss 0.82259
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run zesty-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/snjwudzh
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_030045-snjwudzh/logs
wandb: Agent Starting Run: wahwyh3z with config:
wandb: 	actor_learning_rate: 0.0006765389620057316
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.833231239980973
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.09462316902992318
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_030214-wahwyh3z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wahwyh3z
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 █████████▅▅▄▄▄▄▄▁▁▁▃▃▃▅▅▅▅▅▅▅▅▅▅▅▅▅▇▇▇▇▇
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ███████████▅▅▅▄▄▄▁▁▁▁▁▃▃▃▅▅▅▅▅▅▅▅▅▅▅▇▇▇▇
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▂▄▅▃▂▄▄▆▅▁▄▄█▅▃▁▆▂▃▁▃▂▄▅▂▄▂▄▂▅▅▃▂▆▄▄▄▄▃
wandb:      train/ensemble_f1 ▆▆█▂▃▇█▄▅▄▅▁▆▂▆▄▃▅▃▄▄▃▅▃▃▃▂▃▅▅▃▄▅▆▁▇▅▅▆▄
wandb:         train/mil_loss ▃▆▅▇█▅▃▅▄▆▄▃▄▄▆▃▆▃▃▅▃▇▅▆▃▄▇▃▅▃▅▃▃▄▁▄▅▃▅▃
wandb:      train/policy_loss ██████████████▁███████████▃█████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████▁█████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59839
wandb: best/eval_avg_mil_loss 0.65071
wandb:  best/eval_ensemble_f1 0.59839
wandb:            eval/avg_f1 0.59201
wandb:      eval/avg_mil_loss 0.61679
wandb:       eval/ensemble_f1 0.59201
wandb:            test/avg_f1 0.5281
wandb:      test/avg_mil_loss 0.73595
wandb:       test/ensemble_f1 0.5281
wandb:           train/avg_f1 0.57386
wandb:      train/ensemble_f1 0.57386
wandb:         train/mil_loss 0.61583
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run volcanic-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wahwyh3z
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_030214-wahwyh3z/logs
wandb: Agent Starting Run: r1nzyyuc with config:
wandb: 	actor_learning_rate: 6.361915970857803e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.408324448414107
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.19548429526923605
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_030342-r1nzyyuc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r1nzyyuc
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▄▄▃▃▃▄▁▂▄▃▃▃▁▃▇▂▅▄▄▄▂▆▄▃▄▂▃▄█▅▅▄▅▃▅▄▄▇
wandb:      train/ensemble_f1 ▃▄▄▄▁▄▂▄▄▄▂▄▃▅▃▃▆▅▄▇▆▄▆█▃▄▄▄▃▄▆▄▅▆▅▅▆▆▆▆
wandb:         train/mil_loss █▄▇▇▄▁▇▄▆█▂▅▅▃▇▇▄▄▆▆▅▆▅▅▃▄▆▄▁▅█▅▂▄▄▄▃▅▂▅
wandb:      train/policy_loss ▆▂▄▅▆▃▂▃▃█▄▂▆▅▁▂▃▂▅▃▄▄▅▄▇▃▂▄▄▄▇▃▄▃▅▄▃▄▅▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▇▅▄▄▄▄▄▅█▇▄▇▅▂▄▇▅▅▅▄▁▃▅▆▆▅▅▄▅▄▅▄▄▆▅▅▄▄▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.61279
wandb: best/eval_avg_mil_loss 1.23036
wandb:  best/eval_ensemble_f1 0.61279
wandb:            eval/avg_f1 0.61279
wandb:      eval/avg_mil_loss 1.1332
wandb:       eval/ensemble_f1 0.61279
wandb:            test/avg_f1 0.56573
wandb:      test/avg_mil_loss 0.81495
wandb:       test/ensemble_f1 0.56573
wandb:           train/avg_f1 0.63639
wandb:      train/ensemble_f1 0.63639
wandb:         train/mil_loss 1.00925
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fluent-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r1nzyyuc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_030342-r1nzyyuc/logs
wandb: Agent Starting Run: v6d9ujqi with config:
wandb: 	actor_learning_rate: 9.487468693309848e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8615488328097674
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.010227013951474406
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_030509-v6d9ujqi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v6d9ujqi
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▅█▄▃▆▅▆▅▆▂▁▄▄▄▄▅▆▅▄▅▄▆▄▅▅▂▄▄▆▄▄▅▄▂▅▇▅▄▆
wandb:      train/ensemble_f1 ▆█▅▅▁▄▅▂▆▅▇▄▅▆▅▆▆█▇▆▆▅▅▆██▆▇▅▆▅▆▆▅▆▆▃▆▅▅
wandb:         train/mil_loss ▆▄█▅▅▁▆▅▅▄▄▆▆▆▄▁▅▄▆█▄▅▄▃▁▅█▅▅▆▆▃▆▄▆▇▇▇█▃
wandb:      train/policy_loss ▆▄▆▂▄▂▄▇▃▆▆▅▅▁▃▃█▄▂▃▄▂▃▇▃▅▄▅▇▃▅▅▆▃▆▁▆▅▃▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▄▅▇▆▅▄█▇▄▄▅▇▄▆▅▆▄█▅▄▆▆▇▄▄▃█▁▇█▄▅▁▆▄▂▃▆▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.01046
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 1.00066
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.1222
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3448
wandb:      train/ensemble_f1 0.3448
wandb:         train/mil_loss 0.58004
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clear-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v6d9ujqi
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_030509-v6d9ujqi/logs
wandb: Agent Starting Run: z503mo61 with config:
wandb: 	actor_learning_rate: 0.00025644621917720716
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9176331618206504
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4913842131769909
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_030638-z503mo61
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/yfr1t3w5
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z503mo61
wandb: uploading history steps 93-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████▅▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▄▄▇▇▇█████████████████████████
wandb:       eval/ensemble_f1 ██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▁▅▆▆▆▇▆▅█▅▅▅▄▅▅▃▅▃█▅▄▅▄▆▅▄▇▇▃▆▆▅▃▅▆▄█▆
wandb:      train/ensemble_f1 ▆▅▆▅▇▇▆▄▇▇▆▇▅▄▆▇▅▄▇▃█▅▅▇▅▅▄▂▁▇▄▄▅▅▅▅▄▆█▆
wandb:         train/mil_loss ▁▂▄▅▁▂▄▄▄▄▂▃▂▅▄▃▅▂▃▂▅▃▃▂█▃▄▂▅▄▂▄▄▃▄▃▃▅▅▃
wandb:      train/policy_loss ██████████▁█████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████████████▁███████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70997
wandb: best/eval_avg_mil_loss 0.58732
wandb:  best/eval_ensemble_f1 0.70997
wandb:            eval/avg_f1 0.69988
wandb:      eval/avg_mil_loss 0.69411
wandb:       eval/ensemble_f1 0.69988
wandb:            test/avg_f1 0.74694
wandb:      test/avg_mil_loss 0.5909
wandb:       test/ensemble_f1 0.74694
wandb:           train/avg_f1 0.73625
wandb:      train/ensemble_f1 0.73625
wandb:         train/mil_loss 0.52756
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dutiful-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z503mo61
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_030638-z503mo61/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
wandb: Agent Starting Run: v33i5tw8 with config:
wandb: 	actor_learning_rate: 0.0012227128613048685
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.26725710825762006
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9956933895179136
wandb: Currently logged in as: ninabraakman (ninabraakman-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_030842-v33i5tw8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-1
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v33i5tw8
/gpfs/work5/0/prjs1491/Attention-based-RL-MIL/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂█████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ██████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▇▇▄▇█▆▇▇█▆▆▆█▆▇▇▁▂▂▂▄▃▂▁▂▄▄▂▂▁▄▂▂▅▄▃▄▃
wandb:      train/ensemble_f1 ▆▇▆▇▅▅▆▇▅▆▇▇▇▆█▆▅▃▃▂▄▁▂▁▄▄▂▂▃▁▁▂▂▄▄▂▅▄▂▁
wandb:         train/mil_loss ▂▃▄▃▃▃▅▄▅▃▄▁▄▂▂▅▇▅▆▄▄▄▂▅▆▄▄▅▆▄▄▅▅▆▂▅▂▃█▃
wandb:      train/policy_loss ██████████████▂▂▃▄▂▃▁▂▁▂▁▃▃▅▁▂▃▃▂▂▂▄▁▄▂▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▅▃▂▂▂▃▁▁▄▁▁▁▂▁▂▂▂▂▂▂▃▃▃▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.49286
wandb: best/eval_avg_mil_loss 0.77216
wandb:  best/eval_ensemble_f1 0.49286
wandb:            eval/avg_f1 0.38558
wandb:      eval/avg_mil_loss 0.86031
wandb:       eval/ensemble_f1 0.38558
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.60961
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.42802
wandb:      train/ensemble_f1 0.42802
wandb:         train/mil_loss 0.80809
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worldly-sweep-1 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/v33i5tw8
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_030842-v33i5tw8/logs
wandb: Agent Starting Run: w62fnt8p with config:
wandb: 	actor_learning_rate: 0.00292903881041303
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5001661528463307
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15053489640364692
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_031015-w62fnt8p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-2
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w62fnt8p
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ████████████▅▁▁▁▁▁▁▁▂▂▂▂▂▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:      eval/avg_mil_loss ▁▁▁▁▁▁▁▁▁▁▇▇▇▇████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       eval/ensemble_f1 ██████████▁▁▁▁▁▁▁▁▁▁▂▂▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆▇▇▆▂█▇▅▅▆▃▇▁▄▃▄▆▃▄▅▂▂▄▅▁█▃▃▄▁▆▃▅▅▁▅▄▅▆
wandb:      train/ensemble_f1 ▅▇▅▆▅█▇▅▆▅▆▅▇▆▃▆▄▆▅▄▄▅▂▃▂▅▃▅▇▂▄▄▆▅▅▅▄▁▅▆
wandb:         train/mil_loss ▄▄▅▅▂▅█▅▂▂▄▅▁▆▆▆▄▇▃▁▆▃▅▇▄▇▅▂▃▃▂▅▂▃▂▄▂▄▂▃
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▄▇▄▂▅▆▅▅▅▅▅▄▇▁▃▇▇▃▇▅▅▃▆▃▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.70332
wandb: best/eval_avg_mil_loss 0.50144
wandb:  best/eval_ensemble_f1 0.70332
wandb:            eval/avg_f1 0.6757
wandb:      eval/avg_mil_loss 0.52659
wandb:       eval/ensemble_f1 0.6757
wandb:            test/avg_f1 0.59677
wandb:      test/avg_mil_loss 0.56126
wandb:       test/ensemble_f1 0.59677
wandb:           train/avg_f1 0.6436
wandb:      train/ensemble_f1 0.6436
wandb:         train/mil_loss 0.6251
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run clean-sweep-2 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/w62fnt8p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_031015-w62fnt8p/logs
wandb: Agent Starting Run: awjcm4wc with config:
wandb: 	actor_learning_rate: 2.9588155482115757e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.27280655328929826
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.28385009561255514
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_031208-awjcm4wc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-3
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/awjcm4wc
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆█
wandb: best/eval_avg_mil_loss █▇▄▁
wandb:  best/eval_ensemble_f1 ▁▄▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅██████████
wandb:      eval/avg_mil_loss ██▇▆▆▆▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▄▄▄▄▄▄▄▄▄▄▄▄▆▆▆▆▆▆▆▆▆▆▆███████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▄▂▁▇▇▄▃▅▄▃▅▄▄▄▂▂▂▅▂▆▆▇▃▄▇▆▅▆▃▄█▄▇▃▆▆▇▄▅
wandb:      train/ensemble_f1 ▁▄▂▄▅▂▃▇▃▅▄▃▃▂▅▆▄▅▆▅▄▃▅▆▅▅▇█▄▄▇▄▆▇▂▇▃▆▄▇
wandb:         train/mil_loss █▄█▇▆▆▆▇▇▃▇▆▆▄▄▆▆▄▃▇▅▄▅▁█▃▄▆▂▅▆▄▄▂▄▅▅▄▄▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.6568
wandb: best/eval_avg_mil_loss 0.51821
wandb:  best/eval_ensemble_f1 0.6568
wandb:            eval/avg_f1 0.6568
wandb:      eval/avg_mil_loss 0.50459
wandb:       eval/ensemble_f1 0.6568
wandb:            test/avg_f1 0.64286
wandb:      test/avg_mil_loss 0.53525
wandb:       test/ensemble_f1 0.64286
wandb:           train/avg_f1 0.608
wandb:      train/ensemble_f1 0.608
wandb:         train/mil_loss 0.62397
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run snowy-sweep-3 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/awjcm4wc
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_031208-awjcm4wc/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: lkhom37w with config:
wandb: 	actor_learning_rate: 5.310230490196502e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.31348117848813706
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1651366682731067
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_031545-lkhom37w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-4
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lkhom37w
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▅▄▅▅▇█▅▄▃▃▄▆▁▅▅▅▇▄▆▅▇▂▆▃▃▄▃▆▆▆▄▅▂▅▂▁▅▅▄
wandb:      train/ensemble_f1 ▄▇▅▃▇▅▅▅█▄▃▄▆▅▂▆▅▄▆▅▃▅▅▅▄▆▅▅▁▅▅▇▅▅▂▆▅▃▃▅
wandb:         train/mil_loss ▃▂▄▅▄▅▆▂▆▂▄▇▇▂▄▄▄▆▁▆▂▃▆▃█▇▂▁▄▄▂▇█▅▃▅▄▂▅▄
wandb:      train/policy_loss ▄▄▅▁▅▅▃▂▅█▄▇▃▅▅▅▅▄▅▆▅▆▅▄▅▄▃▃▂▅▅▄▅▅▄▇▄▄▄▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅▄▅▆█▁▅▅▄▃▅▃█▃▄▅▅▅▅▁▆▆▅▄▄█▄▇▄▅▅▄▅▄▇▅▄▄▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.98189
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.96252
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.09294
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33555
wandb:      train/ensemble_f1 0.33555
wandb:         train/mil_loss 0.80989
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run colorful-sweep-4 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/lkhom37w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_031545-lkhom37w/logs
wandb: Agent Starting Run: 97lymkb3 with config:
wandb: 	actor_learning_rate: 4.025581381450929e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9487552823622484
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1161882722998605
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_031713-97lymkb3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-5
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/97lymkb3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇█████▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▃▃▃▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▄▆▇▆▄█▃▃▇▆▄▅▇▅▄▆▁▄▂▆▆▄▅▄▆▃▄▃▅▅▂▅▂▆▅▅▄▂
wandb:      train/ensemble_f1 ▆▆█▇▇▃▄▇▅▅█▆▃▆▇▄▅▃▆▃▃▇▃▆▅▁▂▅▃▆█▁█▆▂▁▅▆▂▂
wandb:         train/mil_loss ▂▂▂▄▇▃▂▆▅▄▂▁▆▃▃▃▆▄▂▅▂▅▃▃▄▃▃▄▃▂▄▅▄▂▄▄█▇▁▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.59893
wandb: best/eval_avg_mil_loss 1.12098
wandb:  best/eval_ensemble_f1 0.59893
wandb:            eval/avg_f1 0.59893
wandb:      eval/avg_mil_loss 1.10879
wandb:       eval/ensemble_f1 0.59893
wandb:            test/avg_f1 0.5842
wandb:      test/avg_mil_loss 0.87673
wandb:       test/ensemble_f1 0.5842
wandb:           train/avg_f1 0.55545
wandb:      train/ensemble_f1 0.55545
wandb:         train/mil_loss 0.56241
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run worldly-sweep-5 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/97lymkb3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_031713-97lymkb3/logs
wandb: Agent Starting Run: pgbs7p84 with config:
wandb: 	actor_learning_rate: 4.682710579857664e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8444933934691657
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9100594219340378
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_031840-pgbs7p84
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-6
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pgbs7p84
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ███████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▁▄▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███
wandb:       eval/ensemble_f1 ███████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▂▅▃▄▂▄▃▂▅▅▇▂▆▃▃█▄▄▄▂▄▃▃▃▅▅▃▄▁▅▄▄▆▁▄▂▂▃▃
wandb:      train/ensemble_f1 ▃▂▃▃▃▂▅▄▂▅▄▇▅▂▆▃▄▃▅█▄▄▃▄▃▃▃▃▂▅▂▅▁▁▁▆▄▆▃▃
wandb:         train/mil_loss ▄▃▄▅▅▅▄▄▁▄▄▄▂▅▅▃▄▅▁▂▅█▃▃▅▂▃▄▅▄▁▂▃▆▂▄▂▃▄▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.40782
wandb: best/eval_avg_mil_loss 4.11044
wandb:  best/eval_ensemble_f1 0.40782
wandb:            eval/avg_f1 0.36478
wandb:      eval/avg_mil_loss 4.38237
wandb:       eval/ensemble_f1 0.36478
wandb:            test/avg_f1 0.35134
wandb:      test/avg_mil_loss 4.29625
wandb:       test/ensemble_f1 0.35134
wandb:           train/avg_f1 0.38
wandb:      train/ensemble_f1 0.38
wandb:         train/mil_loss 1.12197
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run skilled-sweep-6 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pgbs7p84
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_031840-pgbs7p84/logs
wandb: Agent Starting Run: zs5liro1 with config:
wandb: 	actor_learning_rate: 4.481900768988726e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.056594630122691614
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.42011844850820834
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_032008-zs5liro1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-7
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zs5liro1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁███████████████████████████████████
wandb:      eval/avg_mil_loss ███▇▇▇▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁██████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▇▆▃▃▁▃▇▂█▅█▅▂▄█▅▄▄▄▃▇▃▆▄▂▇▇▅▃▆▄▄▇▂▆▄▃▇▇
wandb:      train/ensemble_f1 ▆▅▇▆▁█▄▆▆▅▆▅▃▄█▄▇▇▅▇▃▁▅▄▆▆▅▆▄▇▇▃▆▅▄▅▅▇▆▇
wandb:         train/mil_loss ▁▃▅▄▂▃▅▅▅▄▁▂▄█▆▅▃▇▃▃▃▇▅▇▂▄▃▆▆▇▃▂▂▃▄▅▂▂▃▄
wandb:      train/policy_loss █████▁██████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▇█▇▇██▇▇▇▇████▇▇▇▇███▇█▇▇██▇██▇██▇▇█▇
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67269
wandb: best/eval_avg_mil_loss 0.52586
wandb:  best/eval_ensemble_f1 0.67269
wandb:            eval/avg_f1 0.67269
wandb:      eval/avg_mil_loss 0.50853
wandb:       eval/ensemble_f1 0.67269
wandb:            test/avg_f1 0.57924
wandb:      test/avg_mil_loss 0.56873
wandb:       test/ensemble_f1 0.57924
wandb:           train/avg_f1 0.63372
wandb:      train/ensemble_f1 0.63372
wandb:         train/mil_loss 0.72021
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hardy-sweep-7 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zs5liro1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_032008-zs5liro1/logs
wandb: Agent Starting Run: m16lwi0w with config:
wandb: 	actor_learning_rate: 0.0029441716934425714
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.182244182103099
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.41776536276606535
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_032146-m16lwi0w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-8
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m16lwi0w
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▆▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▆▅▅▆▅▅▅▇▇▇▆▃▆▅▆▄▂▃▇▃▂▅▄▅▇▆▇▇█▇▅▇▅▁▄▇▆▇▅
wandb:      train/ensemble_f1 ▂▃▁▄▅▃▃▄▁▆▂▂▂▄▃▃▄▃▁▇▄█▆▃▃▃▅▅▃▆▄▅▅▄▃▃▄▅▆▄
wandb:         train/mil_loss ▄▃▃▅▃▇▂▄▆▃▆▄▅▄▃▃▄▃▆▆▄▅▅▂▅▆▆▃▆▁▇▄▃▇█▄▄▄▂▄
wandb:      train/policy_loss ▃▂▃▆▂▆▃▅▂▃▄▆▂▃▄▂▅▃█▃▂▃▃▃▄▃▆▄▃▄▄▁▄▅▅▅▅▃▃▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▁▃▄█▄▆▅▅▄▇▄▃▄▄▆▃▄▂▃▃▇▄▄▅▅▅▄▅▄▆▅▅▅▅▂▄▄▅▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66044
wandb: best/eval_avg_mil_loss 0.47841
wandb:  best/eval_ensemble_f1 0.66044
wandb:            eval/avg_f1 0.66044
wandb:      eval/avg_mil_loss 0.47527
wandb:       eval/ensemble_f1 0.66044
wandb:            test/avg_f1 0.62121
wandb:      test/avg_mil_loss 0.591
wandb:       test/ensemble_f1 0.62121
wandb:           train/avg_f1 0.63309
wandb:      train/ensemble_f1 0.63309
wandb:         train/mil_loss 0.69098
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-8 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m16lwi0w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_032146-m16lwi0w/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0agjagy9 with config:
wandb: 	actor_learning_rate: 0.006785624128714921
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0755260929792666
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.014319116911090446
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_032330-0agjagy9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-9
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0agjagy9
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▅▅▅▄▄▄▄▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▃▂▄▄▁▃▃▅▇▂▃▃▅▅▆▄▃▅▅█▃▄█▄▄▃▆▂▄▅▅▅▅▄▅▆▇▁
wandb:      train/ensemble_f1 ▄▃▅▇▃▄▄▁▃▃▆▇▂▅▆▅▃▅▁▆▁▅▅▃█▃█▄▄▄▆▅▇▅▆▄▅▆▃▁
wandb:         train/mil_loss ▅▇▆▄▅█▄▄▅▆▄▅▄▅▆▃▄▆▅▃▃▃▅▃▂▆▃▄▄▃▂▅▃▃▃▄▅▄▁▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.04737
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.95833
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 0.82513
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.36316
wandb:      train/ensemble_f1 0.36316
wandb:         train/mil_loss 0.88034
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run warm-sweep-9 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/0agjagy9
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_032330-0agjagy9/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: b8cjgm1t with config:
wandb: 	actor_learning_rate: 0.00791902508709088
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.012755359662429131
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7963748865606995
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_032505-b8cjgm1t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-10
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b8cjgm1t
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▆▆▇▆▁▃▄▃▆▃▃▆▁▅▄▄▄▅▄▅█▄▅▅▇▅▆▄▅█▄▅▆▅▆▅▅▆
wandb:      train/ensemble_f1 ▅▃▆▇▄▆▆▁▇▅▄▅▅▇▆▃▅▅▄▅▆▅▇▅▆▆▅█▅▄▄▇▅█▃▆▆▅▅▅
wandb:         train/mil_loss ▅█▅▆▅▅▇▅▅▅▅▅▄▁▄▃▆▃▄▃▇▃▃▇▁▃▂▂▇▄▂▃▄▇▆▅▄▆▆▃
wandb:      train/policy_loss ▁▆▁▁▁▃▁▁▁▁▃▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▁▁▁▃█▁▁▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▁▃▆▃▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▃▃▁▁▁▁▁▁▁▃▁▁▁▁█▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.93366
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.91073
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.02771
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33222
wandb:      train/ensemble_f1 0.33222
wandb:         train/mil_loss 0.87028
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run cerulean-sweep-10 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/b8cjgm1t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_032505-b8cjgm1t/logs
wandb: Agent Starting Run: dugkwtko with config:
wandb: 	actor_learning_rate: 1.2591788897005366e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.11630606893321038
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.29315165278279287
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_032631-dugkwtko
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-11
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dugkwtko
wandb: uploading history steps 133-136, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▅▆█
wandb: best/eval_avg_mil_loss █▇▇▃▁
wandb:  best/eval_ensemble_f1 ▁▃▅▆█
wandb:            eval/avg_f1 ▁▁▁▁▃▆▆▆▆▆█▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▂▂
wandb:       eval/ensemble_f1 ▁▁▁██▇▇▇▇▇▇▇▇▇▇▇▇▇▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▂▇▄▅▆▇▅▅▆▄█▄▆▁▅▆▄▇▃▆▄▅▃▅▃▆▃▂▅▆▃▄▆▅▄▅▆▂
wandb:      train/ensemble_f1 ▂▂▄▃▄▂▂▅▅▇▅▆▄▅█▆▇▃▄▄▆▁▆▄▆▄▆▆▅▆▂▃▅▁▄▆▆▄▅▂
wandb:         train/mil_loss ▆▅▄▄▄▅▅▃▄▆▃▄▅▅▆▃▅▆▅▅▄▅▃▃▅▁▃▄▇▄▆▃▆▂▆▅█▆▆▄
wandb:      train/policy_loss ▁▁▁▁▁▆█▅▇▇▇▆▆▆▇▁▁▁▁▁▇█▆▆▅▇▆█▇▇▅▆▇▆▅▇▅▇▇▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.6757
wandb: best/eval_avg_mil_loss 0.62544
wandb:  best/eval_ensemble_f1 0.6757
wandb:            eval/avg_f1 0.64862
wandb:      eval/avg_mil_loss 0.6048
wandb:       eval/ensemble_f1 0.64862
wandb:            test/avg_f1 0.60114
wandb:      test/avg_mil_loss 0.58369
wandb:       test/ensemble_f1 0.60114
wandb:           train/avg_f1 0.62057
wandb:      train/ensemble_f1 0.62057
wandb:         train/mil_loss 0.68507
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sparkling-sweep-11 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/dugkwtko
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_032631-dugkwtko/logs
wandb: Agent Starting Run: 37ahxqbz with config:
wandb: 	actor_learning_rate: 0.0005392077269539467
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.04862317184267895
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5007648557463187
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_032825-37ahxqbz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-12
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/37ahxqbz
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▆▅▅▄▃▇▄▃▃▄▁▁▇▄▄▂▄▃▄▃▄▆▃▃▃▂▄▅▄▄▃▄▅▃▄▇▅█
wandb:      train/ensemble_f1 ▆▄▅▅▄▅▃▄▁▃▆▄▄█▂▂▅▅▅▆▆▃█▆▃▆▇▄█▅▆▅▅▅▆▆▄▅▆▇
wandb:         train/mil_loss █▄▆▆▆▇▇▆▅▆▄▆▆▅▅▅▄▅▅▄▄▆▅▄▅▃▃▇▅▄▁▄▃▄▃▅▃▄▂▄
wandb:      train/policy_loss ▁▁▃▆▄▁▄▆▁▁▄▁▆▁▄▃▄▆█▆▃▁▅▆▆▄▄▃▆▁█▆▁▃▁▁▁▁▆▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▆▄▁▆▆▆▄▄▁▃▆▁█▄▆▆▁▁▆▆▆▃▆▆▁▆▆▃▆▃▆▄▁▆▃▁▃▁▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3658
wandb: best/eval_avg_mil_loss 1.01609
wandb:  best/eval_ensemble_f1 0.3658
wandb:            eval/avg_f1 0.3658
wandb:      eval/avg_mil_loss 0.93171
wandb:       eval/ensemble_f1 0.3658
wandb:            test/avg_f1 0.46358
wandb:      test/avg_mil_loss 0.79531
wandb:       test/ensemble_f1 0.46358
wandb:           train/avg_f1 0.45562
wandb:      train/ensemble_f1 0.45562
wandb:         train/mil_loss 0.97833
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run honest-sweep-12 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/37ahxqbz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_032825-37ahxqbz/logs
wandb: Agent Starting Run: m3cd90ir with config:
wandb: 	actor_learning_rate: 0.008616705373550733
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3553760095167582
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3071149884613217
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_032953-m3cd90ir
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-13
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m3cd90ir
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████▁▆▅▇▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:      eval/avg_mil_loss ██████████▂▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:       eval/ensemble_f1 █████████▆▁▃▇▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▆█▅▄▅▆▅▆▄▆▇▅▆▆▅▅▄▅▃▂▄▅▃▃▅▂▃▄▂▂▄▁▅▃▅▅▂▃▃
wandb:      train/ensemble_f1 ▄█▃▄▄▃▆▆▄▅▅▅▅▆▃▄▄▄▄▃▂▁▄▃▄▂▃▂▆▃▅▂▄▄▃▁▃▄▂▂
wandb:         train/mil_loss ▆█▆▆▇▅▅▆▆▂▂▁▁▂▂▁▂▂▂▁▂▂▂▂▂▁▂▁▂▂▁▂▁▂▂▁▂▂▂▁
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████████▁▅██████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67825
wandb: best/eval_avg_mil_loss 1.08565
wandb:  best/eval_ensemble_f1 0.67825
wandb:            eval/avg_f1 0.65764
wandb:      eval/avg_mil_loss 0.57451
wandb:       eval/ensemble_f1 0.65764
wandb:            test/avg_f1 0.63636
wandb:      test/avg_mil_loss 0.80717
wandb:       test/ensemble_f1 0.63636
wandb:           train/avg_f1 0.60168
wandb:      train/ensemble_f1 0.60168
wandb:         train/mil_loss 0.6626
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run toasty-sweep-13 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/m3cd90ir
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_032953-m3cd90ir/logs
wandb: Agent Starting Run: xltsa5nx with config:
wandb: 	actor_learning_rate: 0.007337506345768138
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8083517933427989
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.02599781314423899
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_033120-xltsa5nx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-14
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xltsa5nx
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▄▅▇▆▃▅▄▃▅▅▆▆▂▄▄▂▄▇▅▅▄▁▂█▂▅▄▄▅▇▆▅▅▃▁▅▅▄▅
wandb:      train/ensemble_f1 █▅▂▃▆▄▆▆▄▄▆▆▂▆▃▅▄▄▆▅▅▄▁▇▅▅▂▇▅▄▅█▄▄▅▅▆▇▆▆
wandb:         train/mil_loss ▆█▆▆▂▄▆▃▄▂▂▅▅▅▃▁▅▂▂▃▄▄▄▇▅▅▁▄▄▂▅▃▂▃▃▃▂▅▄▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.29094
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.21616
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 1.03092
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.39579
wandb:      train/ensemble_f1 0.39579
wandb:         train/mil_loss 0.87149
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run treasured-sweep-14 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xltsa5nx
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_033120-xltsa5nx/logs
wandb: Agent Starting Run: uqphebqv with config:
wandb: 	actor_learning_rate: 0.0018599946364959972
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.41475841786255285
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.348735041550678
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_033248-uqphebqv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-15
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uqphebqv
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▆▆▆██▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▃▂▃▃▃▅▅▄▂▄▃▅▃▃▅▄▄▂▃▃▃▃▇▁▅▆▃▄▃▂▃▂▄▅▃█▅▃
wandb:      train/ensemble_f1 ▇▅▆▅▃▄▅▄▅▅▅▄▅▅▄▅▃▅█▄█▅▆▄▇▄▅▆▆▅▁▄▇▄▇▇▅▅▅▃
wandb:         train/mil_loss ▃▇▁▇▄▅▃▅▇▁█▅▃▄▄▃▄▄▅▅▄▄▆▄▆▄▅▄▇▄▅▄█▃▂▄▅█▄▅
wandb:      train/policy_loss ▄█▃▄▄▅▄▅▆▄▃▅▆▂▆▅▃▅▅▅▄▆▆▄▄▄▅▄▄▁▅▅▅▅▄▂▆▃▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▃▁▄▇▄▅▅▅▇▂▃▆▅▆▆▆█▃▂▄▃▃▅▅▃▂▃▃▃▃▄▆▃▄▃▃▂▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.78768
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.77801
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.87456
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32146
wandb:      train/ensemble_f1 0.32146
wandb:         train/mil_loss 0.67977
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run hopeful-sweep-15 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uqphebqv
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_033248-uqphebqv/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4imsry50 with config:
wandb: 	actor_learning_rate: 1.3240116840593412e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.005669889334735556
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.5266572379758343
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_033434-4imsry50
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-16
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4imsry50
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▆▇▄▄▆█▆█▅▁▆▇▄▅▇▄▇▄▆▃▄▄▄▆▆▄▆▃▆▄▇▅▄▆▆▄▃▇
wandb:      train/ensemble_f1 █▄▂▄▁▂▅▆▁▃▄▄▂▃▁▃▃▅▆▂▄▅▃▄▁▅▄▅▄▂▅▅▂▆▃▂▂▄▄▄
wandb:         train/mil_loss ▄▄▇▆▇██▇▇▇▆▆▅▄▁▅▇▆▅▅▆▄▇▆▄▄▄▃▆▅▇▆▃▅▅▇▃▅▅▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▃▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▄▁█▁▁▁▁▁▁▁▅▅▄▁▁▁▁▁▁▅▁▁▅▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.91629
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.89438
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.99633
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33939
wandb:      train/ensemble_f1 0.33939
wandb:         train/mil_loss 0.876
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run charmed-sweep-16 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4imsry50
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_033434-4imsry50/logs
wandb: Agent Starting Run: 50mh1rv3 with config:
wandb: 	actor_learning_rate: 0.009140744561149054
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.1561102620120688
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4486283146707959
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_033603-50mh1rv3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-17
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/50mh1rv3
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ██▂▂▃▃▁▂▂▂▂▂▂▂▂▃▁▁▂▃▂▂▂▂▂▂▂▁▂▁▂▂▂▂▂▂▂▁▃▂
wandb:      train/ensemble_f1 █▇███▂▁▂▃▁▂▂▂▂▁▂▂▃▂▃▂▁▂▂▃▁▂▂▂▂▂▂▂▂▂▁▂▂▂▂
wandb:         train/mil_loss ▁▁▆▇▇▅█▆▆▇▇▇▄██▅▃▆▅▅▅▇▆▅▅▆▇▅▄▆▆▅▆▅▄▅▅▆▅▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.57033
wandb: best/eval_avg_mil_loss 0.9391
wandb:  best/eval_ensemble_f1 0.57033
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.59733
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.5842
wandb:      test/avg_mil_loss 0.66555
wandb:       test/ensemble_f1 0.5842
wandb:           train/avg_f1 0.41507
wandb:      train/ensemble_f1 0.41507
wandb:         train/mil_loss 1.73961
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run spring-sweep-17 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/50mh1rv3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_033603-50mh1rv3/logs
wandb: Agent Starting Run: rfwum2nd with config:
wandb: 	actor_learning_rate: 0.0017793457006415286
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.19594624074614275
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.30623151417648875
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_033730-rfwum2nd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-18
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rfwum2nd
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▃▄▄▆▃▅▃▆▅▁▄▃▅▅▃▇▄▃▅▆▄▆▇▆▅▄▅▄█▆▅▆▅▇▄▆▅▅▇
wandb:      train/ensemble_f1 ▄▂▃▃▂▄▃▄▄▄▂▄▄▃▃▃▂▅▂█▂▄▂▄▃▄▅▆▅▅▄█▇▅▄▁▄▅▄▅
wandb:         train/mil_loss ▆▂▄▄▇▃▇▄▆▄▃▃▂▁▄▄▄▆▆▄▄▅▃▆▆▄▂▄▅▃▄▂█▃▆▃▂▂▇▂
wandb:      train/policy_loss ▄▂▆▄▄▃▁▅▅▅█▄▅▄▄▄▄▅▂▄▅▄▅▂▄▄▄▅▂▄▅▂▅▅▅▅▄▄▂▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▂▁▃▄▄▄▅▅▅▄▇▄▂▄▄▄▄▃▄▄▄▄▃▅▂▄▃▃▄▄▄▅▂▅▄▅▁█▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.93021
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.91039
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.02328
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.34426
wandb:      train/ensemble_f1 0.34426
wandb:         train/mil_loss 0.77897
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run helpful-sweep-18 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rfwum2nd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_033730-rfwum2nd/logs
wandb: Agent Starting Run: uebvbt3u with config:
wandb: 	actor_learning_rate: 0.007343984152127134
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4266503983550253
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.12094866132053406
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_033858-uebvbt3u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-19
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uebvbt3u
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▃▅▅▇█
wandb: best/eval_avg_mil_loss █▇▇▅▄▃▁
wandb:  best/eval_ensemble_f1 ▁▂▃▅▅▇█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▃▃▃▃▃▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇▇▇████████████
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▁▁▁▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▂▃▃▃▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇▇▇█████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃▁▄▁▁▄▃▅▃▄▄▅▄▃▄▄▅▅▁▄▄▅▆▂▅▃▄▆▅▄▂█▄▄▄▃▄▄▅
wandb:      train/ensemble_f1 ▂▄▄▆▃▃▄▁▅▅▃▄▆▅▅▆▅▄▅▅▅▄▃▅▃▆▆▅▃▇▅█▅▆▅▃▅▅▄▂
wandb:         train/mil_loss ▇▆▄▂▁█▇▃▄▆▆▄▂▅▅▂▅▇▃▅▅█▃▃▃▆▃▃▃▅▃▃▄▃▃▃▃▂▂▃
wandb:      train/policy_loss ▇▇▇▇▇▇▇▇▇▇▇▇█▆▃▇▇▇▇▇▇▇▇▇▇▇▇▇▃▁▄▂▆▅▇▆▄▇▂▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████▇████▁████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.6938
wandb: best/eval_avg_mil_loss 0.48732
wandb:  best/eval_ensemble_f1 0.6938
wandb:            eval/avg_f1 0.6938
wandb:      eval/avg_mil_loss 0.47974
wandb:       eval/ensemble_f1 0.6938
wandb:            test/avg_f1 0.62393
wandb:      test/avg_mil_loss 0.57379
wandb:       test/ensemble_f1 0.62393
wandb:           train/avg_f1 0.62716
wandb:      train/ensemble_f1 0.62716
wandb:         train/mil_loss 0.6261
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run revived-sweep-19 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/uebvbt3u
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_033858-uebvbt3u/logs
wandb: Agent Starting Run: 7xogf1ip with config:
wandb: 	actor_learning_rate: 0.009571838370560389
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.5008068860091596
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.27529000217001176
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_034226-7xogf1ip
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-20
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7xogf1ip
wandb: uploading history steps 94-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▂▃▅▄▅▄▃▁▄▅▂▃▄▄▄▆▄▄▅▁▄▄▃▃▃▃▄▂█▁▄▂▃▂▃▃▄▅▃
wandb:      train/ensemble_f1 ▅▆▆▄▅▁▅▂▃▁▅▅▅▄▃▃▅▄▅▃▄▃▄▅▃▅▁▄▂▅▄█▁▂▃▅▃▁▅▅
wandb:         train/mil_loss ▄█▁▂▅▅▇▇▅▄▅▃▅▅▅▄▅▃▁▂▄▆▅▃▁▅▃▅▂▃▅▃▇▅▆▂▃▃▄▃
wandb:      train/policy_loss ▅▄▂█▅▄▇▁▄▅▅▃▅▅▄▅▇▄▆▆▅▄▅▄▅▇▄▅▄▄▇▂▅▅▇▂▇▅▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▂▁▇▅▃▄▁▄▅▅▅▃▄▅▄▄▄▄▅▆▅▆▅▄▅▇▄▄▄▅▄▅▆▄▄█▅▇▆
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.87516
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.85543
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 0.98734
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33775
wandb:      train/ensemble_f1 0.33775
wandb:         train/mil_loss 0.69941
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run earthy-sweep-20 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/7xogf1ip
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_034226-7xogf1ip/logs
wandb: Agent Starting Run: cjdgtafp with config:
wandb: 	actor_learning_rate: 3.9269798070071914e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.24221785261514597
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4414281047578922
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_034353-cjdgtafp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-21
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cjdgtafp
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆█▄▄▅▆▆▁▄▄▆▄█▆▅▇▅▃▇▁▆▆▅▄▇▅▅▃▆▅▄▄▅▄▄▂▆▃▇
wandb:      train/ensemble_f1 ▄▄▆▅▃▄▄▅▅▄▄▆▄▅▆▆▁▂▅▃▆▄▃▅▇▄▅▄▄▄█▅▅▅▅▆▅▃▃▆
wandb:         train/mil_loss ▄▆▄▄▃▃▆▇▆▄▅█▃▆▅█▇▇▇▃▇▅▆▂▁▆▃▄▅▄▆▄▄▃▇▆▅▄▄▃
wandb:      train/policy_loss ▄▃▄▄▄▅▄▂▅▁▅▄▆▄▄▅▅▃▄▂▄▄█▅▅▄▇▇▇▄▄▂▃▅▇▇▇▅▂▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▄▂▄▄▅▄▁█▅▃▂▅▄▄▄▂▄▄▂▄▄█▄▆▁▃▇▂▆▃▅▄▁▂▇▄▃▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66044
wandb: best/eval_avg_mil_loss 0.48551
wandb:  best/eval_ensemble_f1 0.66044
wandb:            eval/avg_f1 0.66044
wandb:      eval/avg_mil_loss 0.47901
wandb:       eval/ensemble_f1 0.66044
wandb:            test/avg_f1 0.62393
wandb:      test/avg_mil_loss 0.53691
wandb:       test/ensemble_f1 0.62393
wandb:           train/avg_f1 0.64239
wandb:      train/ensemble_f1 0.64239
wandb:         train/mil_loss 0.65163
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run daily-sweep-21 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/cjdgtafp
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_034353-cjdgtafp/logs
wandb: Agent Starting Run: wn9d89r4 with config:
wandb: 	actor_learning_rate: 0.002335777852067614
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2857230693163103
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4872491212597466
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_034522-wn9d89r4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-22
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wn9d89r4
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅█▅▇▇▇▆▆▄▁▆▃▃▆▂▇▃▁▂▂██▅▆█▃▃▃▇▄▁▅▄▆█▃▃▅▆▆
wandb:      train/ensemble_f1 ▆▆▄▇▃▆▆▂▅█▆▃▃▂▃▅▆▅▁▂▄▅▅▆▅▂▅▂▄▄▅▆▄▅▃▂▁▅▄▅
wandb:         train/mil_loss ▄▇▅▅▇▄▄▇▅▄▆▁▅▅▇▄▆▃▆█▆▆▂▅▃▆▇▃▅▆▂▃▃▄▄▃▅▄▄▄
wandb:      train/policy_loss ▅▇▁█▄▅▄▇▄▆▄▃▃▆█▅▄▅▄▃▆▅▄▇▅▆▅▁▅▄█▇▇▅▄▅▅▂▄▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▅█▄▅▄▇▄▆█▅▃▆█▁▄▄▅▃▆▄▇▅▄▃▄▅▃█▄▇▁▇▂▅█▆▆▄▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.01027
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.98844
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.12177
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33884
wandb:      train/ensemble_f1 0.33884
wandb:         train/mil_loss 0.85034
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pious-sweep-22 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wn9d89r4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_034522-wn9d89r4/logs
wandb: Agent Starting Run: y5cy5o1u with config:
wandb: 	actor_learning_rate: 0.004263500010655333
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.34614850721987367
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.20260360029066635
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_034649-y5cy5o1u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-23
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y5cy5o1u
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▂▇▄▆▃▄▃▄▄▇▄▄▃▅▅▄▄▄▄▁▅█▄▆█▅▄▄█▄▄▅▄▆▄▅█▅▅
wandb:      train/ensemble_f1 ▂▃▁▇▇▆▆▄▂▆▃▄▆▄▆▄▃▄▃▃▂▆▃█▄▄▄▃▁▂▄▇▃▂▃▆▅▃▅▃
wandb:         train/mil_loss ▅▄▅▄▅▆▅▃▅▂▄▄▆▆▃▃▃▄▇▄█▁▃▄▂▃▅▄▄▂▃▅▃▁▃▃▆▃▇▃
wandb:      train/policy_loss ▄▅▅▅▂▁▄▁▄▂▂▄█▂▅▂▄▃▇▅▂▅▅▂▃▂▂▄▂▆▂▃▂▂▂▄▄▃▄▄
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▅▅▆▂▃▄▇▁▅▄▆▄▅██▇▂▅▄▅▃▅▄▅█▅▅▃▄▄▂█▄▂▆▂▃▅▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.38558
wandb: best/eval_avg_mil_loss 0.7317
wandb:  best/eval_ensemble_f1 0.38558
wandb:            eval/avg_f1 0.38558
wandb:      eval/avg_mil_loss 0.70747
wandb:       eval/ensemble_f1 0.38558
wandb:            test/avg_f1 0.46358
wandb:      test/avg_mil_loss 0.62032
wandb:       test/ensemble_f1 0.46358
wandb:           train/avg_f1 0.44338
wandb:      train/ensemble_f1 0.44338
wandb:         train/mil_loss 0.68758
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run faithful-sweep-23 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/y5cy5o1u
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_034649-y5cy5o1u/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: de4rmc19 with config:
wandb: 	actor_learning_rate: 0.0028925028226304533
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4294161635896435
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0015111356388031183
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_034828-de4rmc19
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-24
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/de4rmc19
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▆█
wandb: best/eval_avg_mil_loss █▅▄▁
wandb:  best/eval_ensemble_f1 ▁▃▆█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▃▆▁▃▃▃▃▃▃▃▃▃▃▃▃███████████████
wandb:      eval/avg_mil_loss ███████▇▇▇▇▆▆▆▇▆▆▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▃▃▃▆▃▃▃▃▃▃▃██████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▄▃▄▄▄▁▄▅▄▄▅▅▄▅▆▄▅▄▆▆▆▅▅▇▅▆▅▅▄▆▇▆▅▅▅▄▅▄█
wandb:      train/ensemble_f1 ▂▃▄▃▅▂▅▁▂▄▃▅▄▄▅▄▅▆▃▃█▅▅▆▆█▄▅▆▆▅█▇▃▆▇▄▆▇█
wandb:         train/mil_loss █▅▆▅▄▅▅▅▅▅▆▁▁▃▅▂▂▄▃▅▄▆▄▄▅█▅▂▅▄▆▄▂▁▄▃▂▃▄▁
wandb:      train/policy_loss ▂▂▂▂▂▂▂▂▂▂▁▇▂▂▂█▂▇▇▃▃▇▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.78375
wandb: best/eval_avg_mil_loss 0.69031
wandb:  best/eval_ensemble_f1 0.78375
wandb:            eval/avg_f1 0.78375
wandb:      eval/avg_mil_loss 0.57335
wandb:       eval/ensemble_f1 0.78375
wandb:            test/avg_f1 0.78348
wandb:      test/avg_mil_loss 0.52103
wandb:       test/ensemble_f1 0.78348
wandb:           train/avg_f1 0.79608
wandb:      train/ensemble_f1 0.79608
wandb:         train/mil_loss 0.62055
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fearless-sweep-24 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/de4rmc19
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_034828-de4rmc19/logs
wandb: Agent Starting Run: eih5xqft with config:
wandb: 	actor_learning_rate: 3.3644402704134055e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.15363743857821177
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3865567251082471
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_035119-eih5xqft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-25
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eih5xqft
wandb: uploading history steps 207-221, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▃▄▅▇▇██
wandb: best/eval_avg_mil_loss █▇▄▄▄▄▃▁
wandb:  best/eval_ensemble_f1 ▁▃▄▅▇▇██
wandb:            eval/avg_f1 ▁▁▃▃▃▃▄▅▅▅▇██▇▇▇▆▆▆▆▇▆▆▇████████████████
wandb:      eval/avg_mil_loss █▇▇▆▆▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▃▇▇▇▇▇▇▇▇▇▆▆▇▇▆▆▇▇█████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▃▁▂▄▂▃▁▄▃▂▃▃▂▃▃▅▄▄▂▂▄▄▄▄▅▆█▇▃▄▅▄▄▂▅▅▇▅█
wandb:      train/ensemble_f1 ▃▁▄▂▃▃▃▄▄▂▃▅▂▁▆▃▃▅▅▅▆▄▄▄▆▂▆█▄▇▇▇▄▅▇▄▄▄▇▇
wandb:         train/mil_loss ▇▆▅█▂▇▃▆▄▄▅▃▃▃▄▅▅▃▄▂▂▂▄▂▆▃▁▂▃▄▃▃▃▁▁▂▃▁▄▂
wandb:      train/policy_loss ▄▄▇▇▆█▄▄▄▄▇▇▇██▁▂▂▁▁▄▂▁▂▄▆▇▇▆▇▇█▇▇▇▇██▆▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▃▃▃▃█▃▃▃▃▃▃▃▃▃▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80906
wandb: best/eval_avg_mil_loss 0.43447
wandb:  best/eval_ensemble_f1 0.80906
wandb:            eval/avg_f1 0.80906
wandb:      eval/avg_mil_loss 0.4142
wandb:       eval/ensemble_f1 0.80906
wandb:            test/avg_f1 0.74888
wandb:      test/avg_mil_loss 0.47642
wandb:       test/ensemble_f1 0.74888
wandb:           train/avg_f1 0.76911
wandb:      train/ensemble_f1 0.76911
wandb:         train/mil_loss 0.54999
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run icy-sweep-25 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/eih5xqft
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_035119-eih5xqft/logs
wandb: Agent Starting Run: kqhtwz83 with config:
wandb: 	actor_learning_rate: 1.2253736230602497e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.021148158138262207
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.029237786279428857
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_035419-kqhtwz83
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-26
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kqhtwz83
wandb: uploading history steps 115-117, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▇▇▇▇█▇▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▂▂
wandb:      eval/avg_mil_loss ▂▂▂▂▂▂▁▁▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▄▃▄▄▃▆▆▆▆▆▇█████
wandb:       eval/ensemble_f1 ▇▇▇▇▇▇██▆▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▆▇▅▅▅▇▄▆▆▄▅▆█▆▇▆█▅█▄▅▇▃▅▄▃▅▃▃▂▁▇▂▃▅▂▂▃▄
wandb:      train/ensemble_f1 ▇▆▅██▅▆▃▅▃▅▇▄▆▄▅█▄▄▅█▆▅▅▅▅▃▆▅▅▃▂▁▇▃▅▂▃▄▂
wandb:         train/mil_loss ▃▄▃▂▅▇▄▃▄▃▆▄▁▅▅▅▅▁▅▃▃▅▄▅▅▅▇▅▆▅▇▄▃▅▆█▅▅▇▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.64271
wandb: best/eval_avg_mil_loss 0.5752
wandb:  best/eval_ensemble_f1 0.64271
wandb:            eval/avg_f1 0.59539
wandb:      eval/avg_mil_loss 0.60267
wandb:       eval/ensemble_f1 0.59539
wandb:            test/avg_f1 0.697
wandb:      test/avg_mil_loss 0.48622
wandb:       test/ensemble_f1 0.697
wandb:           train/avg_f1 0.62242
wandb:      train/ensemble_f1 0.62242
wandb:         train/mil_loss 0.60456
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sparkling-sweep-26 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/kqhtwz83
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_035419-kqhtwz83/logs
wandb: Agent Starting Run: wlbcb5ei with config:
wandb: 	actor_learning_rate: 6.388811916793807e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.005299616642987615
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1516486473056311
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_035557-wlbcb5ei
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-27
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wlbcb5ei
wandb: uploading history steps 152-165, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████████
wandb:      eval/avg_mil_loss ▇▇▇▇▇▆▆▅▅▅▅▅▅██▇▅▅▅▅▅▅▅▅▅▄▃▃▃▃▃▂▂▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▄▃▅▆▄▆▅▆▁▅▅▄▄▄▅▅▇▇▃▄▆▆▃▅▄▆▅▅█▅▇▄▁▅▅▅▇▅
wandb:      train/ensemble_f1 ▆▅▆▄▅▃▃▆▃▆▅▄▅▆▄▇▁▅▇▆▆█▃█▆█▆▆▂▅▅▅█▂▄▅▇▄▂▅
wandb:         train/mil_loss ▄▄█▄▆▃▆▁▂▄▄▅▄▅▃▃▅▅▇▇▆▃▅▃▃▆▄▂▅▄▄▃▁▄▄▅▃▃█▄
wandb:      train/policy_loss █▁▁▁█▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁█▁█▁█▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁█▁▁▁▁▁▁▁▁█▁▁▁▁▁███▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.79968
wandb: best/eval_avg_mil_loss 0.47408
wandb:  best/eval_ensemble_f1 0.79968
wandb:            eval/avg_f1 0.79968
wandb:      eval/avg_mil_loss 0.4541
wandb:       eval/ensemble_f1 0.79968
wandb:            test/avg_f1 0.87825
wandb:      test/avg_mil_loss 0.64298
wandb:       test/ensemble_f1 0.87825
wandb:           train/avg_f1 0.79368
wandb:      train/ensemble_f1 0.79368
wandb:         train/mil_loss 0.65331
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run faithful-sweep-27 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/wlbcb5ei
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_035557-wlbcb5ei/logs
wandb: Agent Starting Run: 1ibq2yb2 with config:
wandb: 	actor_learning_rate: 3.236115142624702e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.03683642964684042
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2576982001299627
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_035811-1ibq2yb2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-28
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1ibq2yb2
wandb: uploading history steps 95-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▃█▆▁▁▁▂▆▂▄▄▅▇▆▆▃▆▆▃▄▆▇▆▇▅▆▇▅▇▃▄▆▆▅▆▄▆▃▅
wandb:      train/ensemble_f1 ▅▂▃▅▃█▅▄▁▁▄▆▅▂▅▄▅▇▆▄▂▆▂█▅▆▆▆▄▁▅▅▅▄▄▂▆▇▄▄
wandb:         train/mil_loss █▃▅█▆▅▃▃▅▆▄▃▆▄▄▄▃▄▃▄▅▃▄▂▅▅▃▄▄▂▃▂▃▃▂▃▄▁▃▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54044
wandb: best/eval_avg_mil_loss 0.79912
wandb:  best/eval_ensemble_f1 0.54044
wandb:            eval/avg_f1 0.54044
wandb:      eval/avg_mil_loss 0.70683
wandb:       eval/ensemble_f1 0.54044
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.66938
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.52586
wandb:      train/ensemble_f1 0.52586
wandb:         train/mil_loss 0.83926
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run warm-sweep-28 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1ibq2yb2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_035811-1ibq2yb2/logs
wandb: Agent Starting Run: xo926rii with config:
wandb: 	actor_learning_rate: 0.00022189964062826345
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.002460438840741652
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10245331947054805
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_035939-xo926rii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-29
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xo926rii
wandb: uploading history steps 114-131, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▂▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▅▅▅▅███████████████████████████████
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▅▅▅███████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▆▇▂▃▄▅▃▆▃▄▇▄▄▅▂▃▅▃▄▃▃▁▄▂▂▇▄▃▅▆▇▆▆▄█▄▂▄
wandb:      train/ensemble_f1 ▁▁▁▂▃▂█▃▄▂▅▃▃▄▂▂▆▃▃▂▅▃▁▆▃▂▄▂▄▅▃▄▄▄▃▃▃▆▁▄
wandb:         train/mil_loss ▇▆▅▂▅▄▄▆▆█▁▃▄▂▃▂▄▅▅▄▃▁▂▂▂▂▅▃▅▃▄▅▃▃▃▂▂▂▃▃
wandb:      train/policy_loss ██████▁█████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ████████▁███████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.54044
wandb: best/eval_avg_mil_loss 0.72721
wandb:  best/eval_ensemble_f1 0.54044
wandb:            eval/avg_f1 0.54044
wandb:      eval/avg_mil_loss 0.67289
wandb:       eval/ensemble_f1 0.54044
wandb:            test/avg_f1 0.50658
wandb:      test/avg_mil_loss 0.64712
wandb:       test/ensemble_f1 0.50658
wandb:           train/avg_f1 0.53198
wandb:      train/ensemble_f1 0.53198
wandb:         train/mil_loss 0.74889
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pretty-sweep-29 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/xo926rii
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_035939-xo926rii/logs
wandb: Agent Starting Run: z82zi55n with config:
wandb: 	actor_learning_rate: 4.430469080888337e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.017139758571042885
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.0362790548323455
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_040128-z82zi55n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-30
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z82zi55n
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▃▄▄▅▅▆▆▆▇▇███
wandb: best/eval_avg_mil_loss █▇▆▆▆▆▆▅▅▅▄▄▂▁▁▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▃▄▄▅▅▆▆▆▇▇███
wandb:            eval/avg_f1 ▁▁▂▂▃▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇██████████████
wandb:      eval/avg_mil_loss ████▇▇▆▆▆▆▆▆▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▂▃▃▄▄▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇██████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▂▃▁▂▃▃▃▄▃▃▆▆▅▅▅▅▆▇█▇▇▇▇▇▆▆▇▆▇▇▆▆▆█▇▆▇
wandb:      train/ensemble_f1 ▁▁▂▂▃▂▃▃▃▃▄▄▆▆▅▆▅▆▆▅▅▇▇▇▆▆▇▇███▇▇███▇█▇▇
wandb:         train/mil_loss ▆▆▇▄▆█▇▆▅▆▆▅▄▄▄▅▂▃▄▃▅▂▃▄▂▃▂▂▂▂▂▂▃▂▂▄▁▂▂▂
wandb:      train/policy_loss █████████████████████▁██████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▂▁██▄▄▄██▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄██████████▄
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81818
wandb: best/eval_avg_mil_loss 0.42048
wandb:  best/eval_ensemble_f1 0.81818
wandb:            eval/avg_f1 0.80845
wandb:      eval/avg_mil_loss 0.36518
wandb:       eval/ensemble_f1 0.80845
wandb:            test/avg_f1 0.8284
wandb:      test/avg_mil_loss 0.46831
wandb:       test/ensemble_f1 0.8284
wandb:           train/avg_f1 0.7921
wandb:      train/ensemble_f1 0.7921
wandb:         train/mil_loss 0.49363
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run deep-sweep-30 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z82zi55n
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_040128-z82zi55n/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: z215q0zz with config:
wandb: 	actor_learning_rate: 0.0008534421297001248
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.00018551143100864476
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.978402431009829
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_040627-z215q0zz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-31
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z215q0zz
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▆▆▆▅▄▄▄▄▄▃▄▄▃▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▂▂▆▂▅▃▅▄▄▅▂▇▅▄▇▄▃▄▃▅▆▅█▅▂▅▄▃▆▂▅▃▁▅▄▃▆▇▇
wandb:      train/ensemble_f1 ▂▁▆▂▇▂▅▂▅▄▃▅▄▄▅▂▆▃▆▄▆▆▁▁█▅▄▂▅▃▄▅▄▅▇▄▃█▆▆
wandb:         train/mil_loss ▅▅▆▆▅█▇▄▇▅▄▆▇▄▅▅▅▅▄▆▇▆▆▂▄▅▃▁▄▃▄▄▃▃▅▃▅▄▇▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 0.92795
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.87373
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.75884
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.40314
wandb:      train/ensemble_f1 0.40314
wandb:         train/mil_loss 1.01809
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run dulcet-sweep-31 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/z215q0zz
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_040627-z215q0zz/logs
wandb: Agent Starting Run: zvwowmbq with config:
wandb: 	actor_learning_rate: 1.1661430453970436e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2777812396727535
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.4032993088989676
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_040756-zvwowmbq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-32
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zvwowmbq
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▆▃▂▄▅▃▃▆▃▄▃▄▅▆▅▃▂▅▇▆█▂▅▅▃▆▆▂▆▁▇▇▃▅▆▅▃█▇
wandb:      train/ensemble_f1 ▃▄▃▁▄▃▄▃▃▄▃▃▁▁▄▃▆▃▄▄▅▅▄▄▃▅▃▅▇▅▆▄▄▅▁▄█▆▆▅
wandb:         train/mil_loss ▇▆▂▇▅▅▅▄▅▃▆▅█▅▆▇█▅▄▆▃▃▃▃▃▄▁▅▃▆▇▅▇▄▁▁▁▃▂▄
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.04489
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.9695
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.87105
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.42534
wandb:      train/ensemble_f1 0.42534
wandb:         train/mil_loss 0.9513
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run daily-sweep-32 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zvwowmbq
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_040756-zvwowmbq/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pqoo5h5x with config:
wandb: 	actor_learning_rate: 7.48307868401468e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.17894279896728582
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.434754453122666
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_040934-pqoo5h5x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-33
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pqoo5h5x
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▇▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▇███▇▆▆▆▆▅▅▃▃▃▃▄▄▃▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▄▄▃▃▄▃▃
wandb:       eval/ensemble_f1 ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▆▄▄▇▂▄▃▄▆▅▂▇▄▃█▅▃▆▃▅▃▇▅▁█▃▄▅▂▃▁▄▂▄▅▄▅▅▃
wandb:      train/ensemble_f1 ▇▄▄▃▅▆▂▂▃█▄▆▆▄▅▅▅▄▆▃▅▃▅▅▄▁▂▅▅▃▂▃▄▄▆▄▄▅▆▄
wandb:         train/mil_loss ▆▄▇▇▇▆▄▄▇▂▄▄▃▅▄▂▅▁▆▅▅▃▄▅▃▅▃▆▃▃▆▆▄▇▄▇▃▅█▅
wandb:      train/policy_loss █████▃▃▂▄▂▃▃▁▄▃▄▃▂▃▃▂▄▃▂▂▃▃▄▃▄▂▃▄▅▂▃▃▃▂▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▆▆▆▆▆▆▆█▂▂▃▁▁▂▂▄▂▂▁▂▃▃▂▃▂▂▁▃▂▁▁▄▂▁▂▂▃▁▁▂
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.83974
wandb: best/eval_avg_mil_loss 0.47579
wandb:  best/eval_ensemble_f1 0.83974
wandb:            eval/avg_f1 0.81993
wandb:      eval/avg_mil_loss 0.49884
wandb:       eval/ensemble_f1 0.81993
wandb:            test/avg_f1 0.93842
wandb:      test/avg_mil_loss 0.95467
wandb:       test/ensemble_f1 0.93842
wandb:           train/avg_f1 0.84231
wandb:      train/ensemble_f1 0.84231
wandb:         train/mil_loss 0.73453
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run eager-sweep-33 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/pqoo5h5x
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_040934-pqoo5h5x/logs
wandb: Agent Starting Run: 1moyfu96 with config:
wandb: 	actor_learning_rate: 4.412173189592791e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.01263723862719912
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9433387748404488
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_041229-1moyfu96
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-34
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1moyfu96
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▄▆█
wandb: best/eval_avg_mil_loss █▄▂▁
wandb:  best/eval_ensemble_f1 ▁▄▆█
wandb:            eval/avg_f1 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▅▅▅▅▅▅▅████▆▆▃▃▁▁▃▃▃▃▃▃▃
wandb:      eval/avg_mil_loss ██▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▂▁▁▁▁▁▁▃▂▁▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▄▄▄▄▆███▅▅▅▅▂▂▂▂▂▂▂▂▂▂▂
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▅▃█▂▁▄▇▂▂▃▅▃▃▆▃▄▄▃▃▇▇▇▄▅▆▆▅▆██▆▇▃▇▅▄▄▇
wandb:      train/ensemble_f1 ▆▃█▅▇▄▃▆▄▁▆▇▆▆▅▅▅▅▅▆▅▅▇▇█▆▆▇▆█▇▇█▃▅▇▅▇▅▆
wandb:         train/mil_loss ▅▇▅▅█▃▆▅▃▅▆▅▅▆▆▇▅▆▆▄▃▄▅▄▂▄▃▄▅▄▄▃▂▃▄▄▁▃▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.64271
wandb: best/eval_avg_mil_loss 0.54775
wandb:  best/eval_ensemble_f1 0.64271
wandb:            eval/avg_f1 0.618
wandb:      eval/avg_mil_loss 0.5487
wandb:       eval/ensemble_f1 0.618
wandb:            test/avg_f1 0.54641
wandb:      test/avg_mil_loss 0.6385
wandb:       test/ensemble_f1 0.54641
wandb:           train/avg_f1 0.58506
wandb:      train/ensemble_f1 0.58506
wandb:         train/mil_loss 0.71938
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run honest-sweep-34 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1moyfu96
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_041229-1moyfu96/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: a76wncx4 with config:
wandb: 	actor_learning_rate: 6.676493391827476e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.0289158647717892
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7242022448427062
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_041548-a76wncx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-35
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a76wncx4
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▂▂▃▃▄▄▅▅▆▇▇██
wandb: best/eval_avg_mil_loss █▇▇▆▆▅▅▄▄▄▃▂▁▁
wandb:  best/eval_ensemble_f1 ▁▂▂▃▃▄▄▅▅▆▇▇██
wandb:            eval/avg_f1 ▁▁▁▁▂▃▃▃▃▃▃▄▄▄▄▄▅▆▆▆▇▇▇▇▇███████████████
wandb:      eval/avg_mil_loss ██▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▂▃▃▃▃▄▄▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇██████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▁▁▂▁▁▁▁▁▃▁▂▂▂▂▂▄▃▄▄▃▄▄▄▄▄▅▅▅▆▇▅▆▇▇▆▇▇███
wandb:      train/ensemble_f1 ▂▁▂▃▂▃▂▃▃▃▃▃▄▄▄▄▅▄▆▅▅▅▅▆▆▆▇▆▆▆▆▆▆▇▆▇▆██▇
wandb:         train/mil_loss █▇█▇█▆▆▇▆▆▅▄▆▄▅▆▄▅▅▄▄▄▄▄▅▄▃▃▄▃▃▃▃▃▄▂▂▂▂▁
wandb:      train/policy_loss ▅▅▅▅▅▅▅▅▅▅▅▅▁▅▅▅█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.73847
wandb: best/eval_avg_mil_loss 0.64739
wandb:  best/eval_ensemble_f1 0.73847
wandb:            eval/avg_f1 0.73847
wandb:      eval/avg_mil_loss 0.5452
wandb:       eval/ensemble_f1 0.73847
wandb:            test/avg_f1 0.72874
wandb:      test/avg_mil_loss 0.51007
wandb:       test/ensemble_f1 0.72874
wandb:           train/avg_f1 0.744
wandb:      train/ensemble_f1 0.744
wandb:         train/mil_loss 0.67867
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run whole-sweep-35 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/a76wncx4
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_041548-a76wncx4/logs
wandb: Agent Starting Run: 25nqxe4t with config:
wandb: 	actor_learning_rate: 8.629923065842088e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.06832306374079644
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.02889855318109935
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_042102-25nqxe4t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-36
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/25nqxe4t
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ██████████████████████████████▄▄▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ██████████████████████████████▄▄▄▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▃▄▃▃▁▁▄▂▂▄▂▄▃▂▄▅▁▃▇▂▄▃▇▄▄▃▄▅▄▅▄█▅▅▇▃▅▇
wandb:      train/ensemble_f1 ▃▃▁▄▆▂▅▃▄▄▃▆▂▃▄▃▆▅▃▇▃▂▆▇▃█▅█▄▅▅▄▆▅▆█▅▆▆█
wandb:         train/mil_loss ▃▃█▇▃▅▃▅▇▄▆▄▅▅▄▃▃▅▅▃▅▃▃▄▂▁▄▃▄▆▄▅▃▄▄▄▃▃▅▃
wandb:      train/policy_loss ██▇▅█▇▇▇▇▆█▇▆█▇▆█▇▇▇▆▇███▇█▇██▇█▇█▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ██████████████████████████████████▁█████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.67269
wandb: best/eval_avg_mil_loss 1.8939
wandb:  best/eval_ensemble_f1 0.67269
wandb:            eval/avg_f1 0.65478
wandb:      eval/avg_mil_loss 1.65385
wandb:       eval/ensemble_f1 0.65478
wandb:            test/avg_f1 0.62148
wandb:      test/avg_mil_loss 2.53477
wandb:       test/ensemble_f1 0.62148
wandb:           train/avg_f1 0.73787
wandb:      train/ensemble_f1 0.73787
wandb:         train/mil_loss 1.12606
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run winter-sweep-36 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/25nqxe4t
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_042102-25nqxe4t/logs
wandb: Agent Starting Run: x23r8txd with config:
wandb: 	actor_learning_rate: 3.105518289900275e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.017710217225984648
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.10648472977768508
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_042230-x23r8txd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-37
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x23r8txd
wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 █████▁▁▁████████████████████████████████
wandb:      eval/avg_mil_loss ███▇▇█▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▅▅▄▄▄▄▃▃▃▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁███████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▅▆▇▅█▁▄▅▃█▃▆▇▂▆▇▆▄▄▄▆▂▃▆▄▇▇▃▅▁▁▇▅▆▃▇▆▁▄
wandb:      train/ensemble_f1 ▆▄▆▆▆▆▄▄▄▄▅█▇▃▂▇▅▅▂▆▅▆▇▇▅▅▆▃▇▅▂▄▅▃▁▆▃▆█▇
wandb:         train/mil_loss ▄▅▅▃▅▅▅▅▅▆▆▆▄▆█▆█▅▅▇▆▅▅▄▆▆▆▂▇▁▅▃▃▅▅▆▄▆▅▄
wandb:      train/policy_loss ▁▁▂▁▁▁▁▁▁▁▁▁████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▂▁▁▁▁▁████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.80983
wandb: best/eval_avg_mil_loss 0.643
wandb:  best/eval_ensemble_f1 0.80983
wandb:            eval/avg_f1 0.80983
wandb:      eval/avg_mil_loss 0.61448
wandb:       eval/ensemble_f1 0.80983
wandb:            test/avg_f1 0.87598
wandb:      test/avg_mil_loss 1.10432
wandb:       test/ensemble_f1 0.87598
wandb:           train/avg_f1 0.83498
wandb:      train/ensemble_f1 0.83498
wandb:         train/mil_loss 0.71307
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run unique-sweep-37 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/x23r8txd
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_042230-x23r8txd/logs
wandb: Agent Starting Run: r5xbsilj with config:
wandb: 	actor_learning_rate: 0.00011457615556476509
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.000748336416879658
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.3100115180462153
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_042424-r5xbsilj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-38
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r5xbsilj
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▄▄▃▆▄▃▃▆▃█▆▆▅█▆▂▅▆▃▆█▅▄▆▅▆▆▄▂▆▁▆▆▅▂▅▂▅█
wandb:      train/ensemble_f1 ▃▂▃▂▁▆▄▄▁▂▅▃█▄▄▂▅▃▃▅▃▆▂▄▆▃▅▆▂▅▆▃▅▅▅▄▅▂▇█
wandb:         train/mil_loss █▄▄▄▅▄█▅▆█▅▃▄▅▄▆▅▆▂▃▁▁▄▃▄▂▆▃▄▆▄▃▃▄▆▄▅▆▄▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 1.01028
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.98396
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.12199
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.32546
wandb:      train/ensemble_f1 0.32546
wandb:         train/mil_loss 0.95111
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run efficient-sweep-38 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/r5xbsilj
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_042424-r5xbsilj/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vndislmm with config:
wandb: 	actor_learning_rate: 5.743518692593307e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.2180551475521314
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6559278029218816
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_042602-vndislmm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-39
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vndislmm
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▅▆▄█▆▆▇▆▆▅▅▇▅▅▆▅▄▅▆▄▆▅▆▆▆▅▆▇▅▆▆▁▅▄▄▄▅▅
wandb:      train/ensemble_f1 ▅▅▆▄▇▇▆▄▇▆▆▄█▆▃▃█▂▃▆▄▂▅▆▇▂▄▂▆█▆▅▆▅▅▅▃▁▇▄
wandb:         train/mil_loss ▆▅▃▆█▅▄▇▂▄▄▆▄▅▅▅▃▆▄▄▄▇▄▆▅▂▁▂▃▄▄▆▅▃▃▅▆▃▅▃
wandb:      train/policy_loss ▃▆▅▃▄▃▅▅▃▂▆▅▂▂▅▄▃▅▃▅▅▄▁▇█▄▁▅▅▅▂▄▄▅▃▅▂▄▆▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▇▅▅▃▅█▂▆▃▃▂▅▃▅▃▅▄▃▅▅▅▆▄█▅▇▅▁▅▂▄▆▆▃█▆▄▇▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 7.32752
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 7.00286
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 9.21579
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.33389
wandb:      train/ensemble_f1 0.33389
wandb:         train/mil_loss 5.32952
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run chocolate-sweep-39 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/vndislmm
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_042602-vndislmm/logs
wandb: Agent Starting Run: 9zm389aw with config:
wandb: 	actor_learning_rate: 0.0018184932246626136
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7891494081624242
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7341306779674329
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_042730-9zm389aw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-40
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9zm389aw
wandb: uploading history steps 91-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss █████▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▂▇█▆▇▅▅▄▆▆▅▇▆▄█▅▅█▅▇▃█▅█▇▁▅▆▇▆▆▃▄▂▄▄▄▄█
wandb:      train/ensemble_f1 ▆▅▇▅▄▄▃▅▃▅▅▅▅▇▆▆▄▃▆▅▆▄▅▅▆▁▃▄▆▇█▅▂▄▄▆▄▇▄▅
wandb:         train/mil_loss ▄▆▄▅▅▆▂▃▄█▃▅▃▄▆▄▅▅▅▄▅▂▃▂▆▃▅▇▅▄▅▃▁▅▄▄▄▁▃▃
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.42338
wandb: best/eval_avg_mil_loss 0.74563
wandb:  best/eval_ensemble_f1 0.42338
wandb:            eval/avg_f1 0.42338
wandb:      eval/avg_mil_loss 0.73358
wandb:       eval/ensemble_f1 0.42338
wandb:            test/avg_f1 0.41725
wandb:      test/avg_mil_loss 0.6701
wandb:       test/ensemble_f1 0.41725
wandb:           train/avg_f1 0.43449
wandb:      train/ensemble_f1 0.43449
wandb:         train/mil_loss 0.59342
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run unique-sweep-40 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/9zm389aw
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_042730-9zm389aw/logs
wandb: Agent Starting Run: yix1ht7p with config:
wandb: 	actor_learning_rate: 2.1764797115068756e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.49104058874771384
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8696594225361571
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_042858-yix1ht7p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-41
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yix1ht7p
wandb: uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▂▅▅▁█▆▂▂▂▆▁▁▄▃▃▃▄▃▄▂▂▃▂▅▄▂▃▄▄▅▄▅▁▄▃▆▂▄▄▅
wandb:      train/ensemble_f1 ▃▃▆▃▅█▃▃▄▆▄▂▄▅▃▄▄▃▃▅▄▅▃▃▃▂▅▅▁▄▅▆▂▆▇▅▃▆▅▆
wandb:         train/mil_loss ▇▆▃▇▆▁▆▄▁▅▂▃▃▃▃▃▂▆█▄▆▄▂▄▇▃▄▁▃▅▃▄▆▄▃▄▅▃▅▆
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 0.89426
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 0.84966
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 0.73187
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.41207
wandb:      train/ensemble_f1 0.41207
wandb:         train/mil_loss 0.74433
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run sleek-sweep-41 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/yix1ht7p
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_042858-yix1ht7p/logs
wandb: Agent Starting Run: 1mz3h5l2 with config:
wandb: 	actor_learning_rate: 4.099992524687914e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.43173854684297974
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9775992033593986
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_043027-1mz3h5l2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-42
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1mz3h5l2
wandb: uploading history steps 146-157, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████
wandb:      eval/avg_mil_loss ██▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▇▇▇█▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▃▄▃▄▇▇▄▆▂▃▁▃▃▄▆▃▄▄▅▄▄▅▅▃▅▆▃▃▁▄▅▄▃▅▃▄▇▃█
wandb:      train/ensemble_f1 ▆▅█▅▅██▄▆▃▂▅▄▁▅▄▅▂▃▄▅▇▅▅▇▇▅▆▆▄▂▄▄▃▄▆▇▇▇▆
wandb:         train/mil_loss ▅▂▄█▇▆▂▅▅▄▅▅▇▂▂▆▄▂▇▃▁▅▂▂▄▃▃▂▄▂▆▃▃▅▄▅▄▄▄▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.65478
wandb: best/eval_avg_mil_loss 0.54773
wandb:  best/eval_ensemble_f1 0.65478
wandb:            eval/avg_f1 0.65478
wandb:      eval/avg_mil_loss 0.53106
wandb:       eval/ensemble_f1 0.65478
wandb:            test/avg_f1 0.5251
wandb:      test/avg_mil_loss 0.63685
wandb:       test/ensemble_f1 0.5251
wandb:           train/avg_f1 0.60423
wandb:      train/ensemble_f1 0.60423
wandb:         train/mil_loss 0.64619
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run happy-sweep-42 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/1mz3h5l2
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_043027-1mz3h5l2/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: u0qxzo2c with config:
wandb: 	actor_learning_rate: 0.00014294139291813788
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.3665639059359528
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.9077733192656688
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_043259-u0qxzo2c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-43
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u0qxzo2c
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▆▅▃▂▂▃▄▃▂▂▃▄▃▇▄▅▂▄▃▄▅▇▃▄▄▄▁▄▃▃█▂▆▆▂▆▄▁▃▂
wandb:      train/ensemble_f1 ▅▂▃▅▄▄▃▅▄▄▅▅▂▅▃▃▄▇▅▄▅▄▆▂▁▅█▃▆▄▆▂▄▄▆▅▄▃▄▃
wandb:         train/mil_loss ▇▇▁▅▇▃▅▄▆▄▇▇▅▄▅▂▄▄▃▄▆█▇▆▆▅▅▅▃▂▂▄▄▄▄▂▃▄▆▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.73434
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.59023
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.39268
wandb:      test/avg_mil_loss 1.34267
wandb:       test/ensemble_f1 0.39268
wandb:           train/avg_f1 0.38738
wandb:      train/ensemble_f1 0.38738
wandb:         train/mil_loss 1.30865
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run fresh-sweep-43 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/u0qxzo2c
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_043259-u0qxzo2c/logs
wandb: Agent Starting Run: c7askvul with config:
wandb: 	actor_learning_rate: 1.6329784439290115e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.7415632142385062
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.8185821759699028
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_043428-c7askvul
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-44
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c7askvul
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ▂▂▂▂▂▃▁▂▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█
wandb:       eval/ensemble_f1 ██████████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▇▅▅▅▂▄▃▆▃▆▄▆█▄▅▄▆▇▄▅▃▆▁▆▅▄▆█▂█▇▅▄▃▃▆▄▄▆
wandb:      train/ensemble_f1 ▄▄▆▆▂▇▃▇▃▃▅▆▅▅▅▃▇▄▆▅▇▄▄▅▃▃▁▆▆▆█▆▅▆▂▃▇▄▅▄
wandb:         train/mil_loss ▂█▅▄▄▅▅█▇▅▅▅█▃▃█▆▅▃▄▃▁▄▃▄▆▂▃▃▇▇▆▆▃▃▇▄▃▂▇
wandb:      train/policy_loss ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▂▇█▁▇▇▇▇▇▇▇▇▇▇
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅█▁▅▅▅▅▅▅
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.66044
wandb: best/eval_avg_mil_loss 0.53265
wandb:  best/eval_ensemble_f1 0.66044
wandb:            eval/avg_f1 0.63535
wandb:      eval/avg_mil_loss 0.53453
wandb:       eval/ensemble_f1 0.63535
wandb:            test/avg_f1 0.60938
wandb:      test/avg_mil_loss 0.60144
wandb:       test/ensemble_f1 0.60938
wandb:           train/avg_f1 0.6157
wandb:      train/ensemble_f1 0.6157
wandb:         train/mil_loss 0.66639
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run pious-sweep-44 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/c7askvul
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_043428-c7askvul/logs
wandb: Agent Starting Run: zdgwqrd1 with config:
wandb: 	actor_learning_rate: 3.1192750039266395e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9432188965714644
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.2949556906998462
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_043600-zdgwqrd1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-45
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zdgwqrd1
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁▅█
wandb: best/eval_avg_mil_loss █▃▁
wandb:  best/eval_ensemble_f1 ▁▅█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅██████████████████
wandb:      eval/avg_mil_loss ████████▇▇▇▇█▇▇██▇█▇▇▇▇▇▇▇▇▇▄▄▄▃▃▃▃▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▅▆▄▂▄▅▄▅▆▅▆▅▅▇▅▇▄▇▆▆█▃▆▄█▇▃▆█▄▅▄▅▃▆▁▅▄
wandb:      train/ensemble_f1 ▃▄▅▃▅▆▁▁▄▄▂▃▄▃▄▃▆▆▃▆▃▃▇▂▄▄▃▄▃▅▄█▇▄▅▄▄▄▄▅
wandb:         train/mil_loss ▄▄▆▆▄▄▃▆▅█▄▆▅█▄▅▆▄▃▄▅▄▄▄▄▅▄▅▄▄▃▃▅▆▄▁▅▅▆▃
wandb:      train/policy_loss ██▇▇▅█▇▇▆▇▇██▇▇▇▇██▇▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▇▇▅█▇▇▇██▇▆▇▇▇█▇▇█▇▅▇▇▇▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.42338
wandb: best/eval_avg_mil_loss 0.74181
wandb:  best/eval_ensemble_f1 0.42338
wandb:            eval/avg_f1 0.42338
wandb:      eval/avg_mil_loss 0.73377
wandb:       eval/ensemble_f1 0.42338
wandb:            test/avg_f1 0.46358
wandb:      test/avg_mil_loss 0.64379
wandb:       test/ensemble_f1 0.46358
wandb:           train/avg_f1 0.45527
wandb:      train/ensemble_f1 0.45527
wandb:         train/mil_loss 0.53435
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run jumping-sweep-45 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/zdgwqrd1
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_043600-zdgwqrd1/logs
wandb: Agent Starting Run: ah7b3q6w with config:
wandb: 	actor_learning_rate: 0.003272542657394785
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.6879380298771878
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.7853524268373885
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_043911-ah7b3q6w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-46
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ah7b3q6w
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▃▃▄▃▃▃▃▃▂▂▂▂▂▂▂▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▃▄▃▆▁▆▅▅▄▆▅▅▅▃▅▆▃▄▅▅▅▇▅▃▅▅▆▅▃█▄▅▄▄▅▃▄▆
wandb:      train/ensemble_f1 ▄▃▄▁▅▆▆▇▅▅▄▆▃▄▄▆▅▆▆▅▆▅▅▅▃▆▅▆▇▅▄▅▃█▅▃▄▄▅▄
wandb:         train/mil_loss ▄▅▅▆▅▁▆▅▅▇▂█▄▅▃▂▃▄▇▆▃▆▅▄▄▅▄▇▄▂▆▅▄▆▄▃▃▇▆▅
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.50997
wandb: best/eval_avg_mil_loss 0.67419
wandb:  best/eval_ensemble_f1 0.50997
wandb:            eval/avg_f1 0.50997
wandb:      eval/avg_mil_loss 0.66331
wandb:       eval/ensemble_f1 0.50997
wandb:            test/avg_f1 0.47917
wandb:      test/avg_mil_loss 0.60146
wandb:       test/ensemble_f1 0.47917
wandb:           train/avg_f1 0.47923
wandb:      train/ensemble_f1 0.47923
wandb:         train/mil_loss 0.64154
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run helpful-sweep-46 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/ah7b3q6w
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_043911-ah7b3q6w/logs
wandb: Agent Starting Run: gvz2o7r7 with config:
wandb: 	actor_learning_rate: 5.4874610155947424e-05
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.4618524709012385
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.1958541401486492
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_044039-gvz2o7r7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-47
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gvz2o7r7
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▆▆▆▆▅▅▅▅▅▅▆▅▅▅▅▅▄▄▄▄▄▂▂▂▂▂▂▂▂▁▁▁▁
wandb:       eval/ensemble_f1 ████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▃▄▃▂▃▃▆▃▇▁▄▆▄▁█▅▂▄█▅▇▃▆▄▁▅▇▅▅▃▇█▂▇▅▁▅▅▇▇
wandb:      train/ensemble_f1 ▄▃▂▅▅▁▆▅▄▃█▂▇▆▇▃▄▅▆▇▅▆▃▅▂▅▄▁▃▂▆█▅▄▅▆▆▆▅▆
wandb:         train/mil_loss ▃▆▄▆▇▆▇▅▇▇▅▁▇▆▅▅▄▆▇▃▅▅▃▆▅▇▇▅▃▆▄▇▃▄▆█▇▄▄▆
wandb:      train/policy_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▁▄▄▇▅▄▃▃▂▄▄▃▄█▂▅▇▆▃
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▁▃▁▄▃▄▇▆▆▅▅▃▃▃▆▅█▃█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.81884
wandb: best/eval_avg_mil_loss 0.57945
wandb:  best/eval_ensemble_f1 0.81884
wandb:            eval/avg_f1 0.80906
wandb:      eval/avg_mil_loss 0.54974
wandb:       eval/ensemble_f1 0.80906
wandb:            test/avg_f1 0.84985
wandb:      test/avg_mil_loss 0.6701
wandb:       test/ensemble_f1 0.84985
wandb:           train/avg_f1 0.85841
wandb:      train/ensemble_f1 0.85841
wandb:         train/mil_loss 0.6232
wandb:      train/policy_loss 0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run solar-sweep-47 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/gvz2o7r7
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_044039-gvz2o7r7/logs
wandb: Agent Starting Run: 4eh8q6nl with config:
wandb: 	actor_learning_rate: 0.003485799937520896
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.29881530539266554
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.15817813128788094
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_044207-4eh8q6nl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-48
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4eh8q6nl
wandb: uploading history steps 92-103, summary
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ███▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▇▁▃▂▃▄▅▅▇▄▇▄▆▅▂▆▃▁▅▄▄▅▄▆▅▇▆█▄▅▇▃▃▃▄▅▄▆▅▄
wandb:      train/ensemble_f1 ▇▁▂▄▄▇▇▄▅█▆█▅█▅▆▅▇▅▄▃▅▆▇▆▆█▆▃▂▄▅▇▃▆▅▄▇▇▅
wandb:         train/mil_loss ▆█▇▆▅▁▆█▃▅▆▆▅▆▄█▄▃▄█▆▅▄▆▇▇▅█▅▅▇▆▅▅▂▅▅▆▄▄
wandb:      train/policy_loss ▃▁▃▃▄▅▆▃▅▂▆▄▄▄▂▆▆▄▅▄▁▄▅▆▅▅▂▇▆▃▆▂▁▃▅▄█▅▅▆
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▄▆▃▆▄▅▄▆▆▆▅▃██▅▅▄▆▆▆▆▆▅▆▃▃▇▄▃▆▆▄▆▅▇▄▁▅▆█
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.34211
wandb: best/eval_avg_mil_loss 0.98138
wandb:  best/eval_ensemble_f1 0.34211
wandb:            eval/avg_f1 0.34211
wandb:      eval/avg_mil_loss 0.96231
wandb:       eval/ensemble_f1 0.34211
wandb:            test/avg_f1 0.29577
wandb:      test/avg_mil_loss 1.08882
wandb:       test/ensemble_f1 0.29577
wandb:           train/avg_f1 0.3283
wandb:      train/ensemble_f1 0.3283
wandb:         train/mil_loss 0.78889
wandb:      train/policy_loss -0.0
wandb:         train/reg_loss 0
wandb:       train/total_loss -0.0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run astral-sweep-48 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/4eh8q6nl
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_044207-4eh8q6nl/logs
wandb: Agent Starting Run: mqjsr51i with config:
wandb: 	actor_learning_rate: 0.00034544387698060377
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.8425047380595515
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.07949954864079833
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_044335-mqjsr51i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-49
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mqjsr51i
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁
wandb: best/eval_avg_mil_loss ▁
wandb:  best/eval_ensemble_f1 ▁
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      eval/avg_mil_loss ████▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▄▅▄▄▄▄▃▄▃▃▃▃▃▂▂▂▂▁▂▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▄▅▅▇▆▃▂▁▅▄▇▃▆▃▅▆▆▄▃▄▅▇▄▆▃▇▃▃▅▄▄▄▇▄▅▇█▃▃▂
wandb:      train/ensemble_f1 ▄▄▅▁▁▄▂▅▃▆▃▆▄▄▃▅▃▃▄▆▂▅▂▅▄▃▄▄▁▄▇▃▆▁▃▃▄▄█▅
wandb:         train/mil_loss ▂▇▆▃▄▆▃▁▇▂▃▄▅▃▂▁▃▃▂▆▃▂▄▂▆▃▄▅▂▃▃█▂▂▁▂▄▂▄▂
wandb:      train/policy_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.3454
wandb: best/eval_avg_mil_loss 1.34276
wandb:  best/eval_ensemble_f1 0.3454
wandb:            eval/avg_f1 0.3454
wandb:      eval/avg_mil_loss 1.3013
wandb:       eval/ensemble_f1 0.3454
wandb:            test/avg_f1 0.36709
wandb:      test/avg_mil_loss 1.0866
wandb:       test/ensemble_f1 0.36709
wandb:           train/avg_f1 0.40574
wandb:      train/ensemble_f1 0.40574
wandb:         train/mil_loss 0.67173
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run glowing-sweep-49 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/mqjsr51i
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_044335-mqjsr51i/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rngfu2o3 with config:
wandb: 	actor_learning_rate: 0.00015855589182689229
wandb: 	batch_size: 128
wandb: 	critic_learning_rate: 0
wandb: 	early_stopping_patience: 100
wandb: 	epochs: 800
wandb: 	epsilon: 0.9245881158934324
wandb: 	hdim: 8
wandb: 	learning_rate: 1e-06
wandb: 	reg_coef: 0.6785391529496676
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /gpfs/work5/0/prjs1491/Attention-based-RL-MIL/wandb/run-20250529_044514-rngfu2o3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-50
wandb: ⭐️ View project at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: 🧹 View sweep at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/sweeps/s3j7ujbq
wandb: 🚀 View run at https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rngfu2o3
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       best/eval_avg_f1 ▁█
wandb: best/eval_avg_mil_loss █▁
wandb:  best/eval_ensemble_f1 ▁█
wandb:            eval/avg_f1 ▁▁▁▁▁▁▁█████████████████████████████████
wandb:      eval/avg_mil_loss █▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁
wandb:       eval/ensemble_f1 ▁▁▁▁▁███████████████████████████████████
wandb:            test/avg_f1 ▁
wandb:      test/avg_mil_loss ▁
wandb:       test/ensemble_f1 ▁
wandb:           train/avg_f1 ▅▄▃▃▅▇▁▄▆▅▄▅▆▇▅▄▆▄▅▃▂▃▃▄▄█▅▅▆▇▃▂▄▃▅▅▃▄▃▇
wandb:      train/ensemble_f1 ▇▅▆▄▄▅▂▄▄▅█▁▇▅▇▅▆▆▆▅▅█▆▆▃▂▄▅▅▃▅▆█▃▃▅▆▇▃▅
wandb:         train/mil_loss ▄▅▅▅▃▃▄▁▄▃▄▄▇▄▄▇▅▅▄▂▂▃█▂▂▂▃▅▁▅▂▂▅▁▆▂▃▂▅▆
wandb:      train/policy_loss ▂▃▂▂▁███████████████████████████████████
wandb:         train/reg_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/total_loss ▂▂▃▃▂▁██████████████████████████████████
wandb:       train/value_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       best/eval_avg_f1 0.71492
wandb: best/eval_avg_mil_loss 0.77064
wandb:  best/eval_ensemble_f1 0.71492
wandb:            eval/avg_f1 0.71492
wandb:      eval/avg_mil_loss 0.74891
wandb:       eval/ensemble_f1 0.71492
wandb:            test/avg_f1 0.65278
wandb:      test/avg_mil_loss 0.5915
wandb:       test/ensemble_f1 0.65278
wandb:           train/avg_f1 0.68003
wandb:      train/ensemble_f1 0.68003
wandb:         train/mil_loss 0.57629
wandb:      train/policy_loss 0
wandb:         train/reg_loss 0
wandb:       train/total_loss 0
wandb:       train/value_loss 0
wandb: 
wandb: 🚀 View run crimson-sweep-50 at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis/runs/rngfu2o3
wandb: ⭐️ View project at: https://wandb.ai/ninabraakman-university-of-amsterdam/MasterThesis
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250529_044514-rngfu2o3/logs
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
